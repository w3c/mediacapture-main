<!DOCTYPE html>
<!--
   To publish this document, see instructions in README
   -->

<html lang="en-us">
<head>
  <link href="getusermedia.css" rel="stylesheet" type="text/css">

  <title>Media Capture and Streams</title>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
  <script class="remove" src=
  "https://www.w3.org/Tools/respec/respec-w3c-common" type="text/javascript">
// &lt;!-- keep this comment --&gt; // 
  </script>
  <script class="remove" src="getusermedia.js" type="text/javascript">
//
    &lt;!-- keep this comment --&gt; // 
  </script>
</head>

<body>
  <section id="abstract">
    <p>This document defines a set of JavaScript APIs that allow local media,
    including audio and video, to be requested from a platform.</p>
  </section>

  <section id="sotd">
    <p>This document is not complete. It is subject to major changes and, while
    early experimentations are encouraged, it is therefore not intended for
    implementation. The API is based on preliminary work done in the
    WHATWG.</p>
  </section>

  <section class="informative" id="intro">
    <h2>Introduction</h2>

    <p>This document defines APIs for requesting access to local multimedia
    devices, such as microphones or video cameras.</p>

    <p>This document also defines the MediaStream API, which provides the means
    to control where multimedia stream data is consumed, and provides some
    control over the devices that produce the media. It also exposes
    information about devices able to capture and render media.</p>
  </section>

  <section id="conformance">
    <p>This specification defines conformance criteria that apply to a single
    product: the <dfn>User Agent</dfn> that implements the interfaces that it
    contains.</p>

    <p>Conformance requirements phrased as algorithms or specific steps may be
    implemented in any manner, so long as the end result is equivalent. (In
    particular, the algorithms defined in this specification are intended to be
    easy to follow, and not intended to be performant.)</p>

    <p>Implementations that use ECMAScript [[ECMA-262]] to implement the APIs
    defined in this specification must implement them in a manner consistent
    with the ECMAScript Bindings defined in the Web IDL specification
    [[!WEBIDL]], as this specification uses that specification and
    terminology.</p>
  </section>

  <section>
    <h2>Terminology</h2>

    <dl>
      <dt><i>HTML Terms:</i></dt>

      <dd>
        <p>The <code><a href=
        "http://dev.w3.org/html5/spec/webappapis.html#eventhandler">EventHandler</a></code>
        interface represents a callback used for event handlers as defined in
        [[!HTML5]].</p>

        <p>The concepts <dfn><a href=
        "http://dev.w3.org/html5/spec/webappapis.html#queue-a-task">queue a
        task</a></dfn> and <dfn><a href=
        "http://dev.w3.org/html5/spec/webappapis.html#fire-a-simple-event">fires
        a simple event</a></dfn> are defined in [[!HTML5]].</p>

        <p>The terms <dfn><a href=
        "http://dev.w3.org/html5/spec/webappapis.html#event-handlers">event
        handlers</a></dfn> and <dfn><a href=
        "http://dev.w3.org/html5/spec/webappapis.html#event-handler-event-type">
        event handler event types</a></dfn> are defined in [[!HTML5]].</p>
      </dd>

      <dt><dfn>source</dfn></dt>

      <dd>
        <p>A source is the "thing" providing the source of a media stream
        track. The source is the broadcaster of the media itself. A source can
        be a physical webcam, microphone, local video or audio file from the
        user's hard drive, network resource, or static image. Note that this
        document describes the use of microphone and camera type sources only,
        the use of other source types is described in other documents.</p>

        <p>An application that has no prior authorization regarding sources is
        only given the number of available sources, their type and any
        relationship to other devices. Additional information about sources can
        become available when applications are authorized to use a source (see
        <a href="#access-control-model"></a>).</p>

        <p>Sources <strong>do not</strong> have constraints â€” tracks have
        constraints. When a source is connected to a track, it must produce
        media that conforms to the constraints present on that track. Multiple
        tracks can be attached to the same source. User Agent processing, such
        as downsampling, MAY be used to ensure that all tracks have appropriate
        media.</p>

        <p>Sources are <a href="#track-detached">detached</a> from a track when
        the track is ended for any reason.</p>

        <p>Sources have constrainable properties which have
        <code><a>capabilities</a></code> and <code><a>settings</a></code>. The
        constrainable properties are "owned" by the source and are common to
        any (multiple) tracks that happen to be using the same source (e.g., if
        two different track objects bound to the same source ask for the same
        capability or setting information, they will get back the same
        answer).</p>
      </dd>

      <dt>Setting (Source Setting)</dt>

      <dd>
        <p>A <a href="#settings">setting</a> refers to the immediate, current
        value of the source's constrainable properties. Settings are always
        read-only.</p>

        <p>A source's settings can change dynamically over time due to
        environmental conditions, sink configurations, or constraint changes. A
        source's settings must always conform to the current set of mandatory
        constraints on all attached tracks. A source that cannot conform to
        mandatory constraints causes affected tracks to become
        <a>overconstrained</a> and therefore <a>muted</a>. A <a>user agent</a>
        attempts to ensure that sources adhere to optional constraints as
        closely as possible, see <a href="#constrainable-interface"></a>.</p>

        <p>Although settings are a property of the source, they are only
        exposed to the application through the tracks attached to the source.
        This is exposed via the <a>ConstrainablePattern</a> interface.</p>
      </dd>

      <dt>Capabilities</dt>

      <dd>
        <p>For each constrainable property, there is a capability that
        describes whether it is supported by the source and if so, the range of
        supported values. As with settings, capabilities are exposed to the
        application via the <a>ConstrainablePattern</a> interface.</p>

        <p>The values of the supported capabilities must be normalized to the
        ranges and enumerated types defined in this specification.</p>

        <p>A <a>getCapabilities()</a> call on a track returns the same
        underlying per-source capabilities for all tracks connected to the
        source.</p>

        <p>Source capabilities are effectively constant. Applications should be
        able to depend on a specific source having the same capabilities for
        any session.</p>

        <div class="note">
          <p>Open Issue: Is "session" the correct term? Should it be "top-level
          browsing context" as defined in HTML spec?</p>
        </div>

        <p>This API is intentionally simplified. Capabilities are not capable
        of describing interactions between different values. For instance, it
        is not possible to accurately describe the capabilities of a camera
        that can produce a high resolution video stream at a low frame rate and
        lower resolutions at a higher frame rate. Capabilities describe the
        complete range of each value. Interactions between constraints are
        exposed by attempting to apply constraints.</p>
      </dd>

      <dt><dfn>Constraints</dfn></dt>

      <dd>
        <p>Constraints provide a general control surface that allows
        applications to both select an appropriate source for a track and, once
        selected, to influence how a source operates.</p>

        <p>Constraints limit the range of operating modes that a source can use
        when providing media for a track. Without provided track constraints,
        implementations are free to select a source's settings from the full
        ranges of its supported capabilities. Implementations may also adjust
        source settings at any time within the bounds imposed by all applied
        constraints.</p>

        <p><a>getUserMedia()</a> uses constraints to help select an appropriate
        source for a track and configure it. Additionally, the
        <a>ConstrainablePattern</a> interface on tracks includes an API for
        dynamically changing the track's constraints at any later time.</p>

        <p>A track will not be connected to a source using
        <a>getUserMedia()</a> if its initial constraints cannot be satisfied.
        However, the ability to meet the constraints on a track can change over
        time, and constraints can be changed. If circumstances change such that
        constraints cannot be met, the <a>ConstrainablePattern</a> interface
        defines an appropriate error to inform the application. <a href=
        "#the-model-sources-sinks-constraints-and-settings"></a> explains how
        constraints interact in more detail.</p>

        <p>In general, user agents will have more flexibility to optimize the
        media streaming experience the fewer constraints are applied, so
        application authors are strongly encouraged to use mandatory
        constraints sparingly.</p>

        <p>For each constrainable property, a constraint exists whose name
        corresponds with the relevant source setting name and capability
        name.</p>
      </dd>

      <dt><code>RTCPeerConnection</code></dt>

      <dd><dfn><code>RTCPeerConnection</code></dfn> is defined in
      [[WEBRTC10]].</dd>
    </dl>
  </section>

  <section id="stream-api">
    <h2>MediaStream API</h2>

    <section>
      <h2>Introduction</h2>

      <p>The two main components in the MediaStream API are the
      <code><a>MediaStreamTrack</a></code> and <code><a>MediaStream</a></code>
      interfaces. The <code><a>MediaStreamTrack</a></code> object represents
      media of a single type that originates from one media source in the User
      Agent, e.g. video produced by a web camera. A
      <code><a>MediaStream</a></code> is used to group several
      <code><a>MediaStreamTrack</a></code> objects into one unit that can be
      recorded or rendered in a media element.</p>

      <p>Each <code><a>MediaStream</a></code> can contain zero or more
      <code><a>MediaStreamTrack</a></code> objects. All tracks in a
      <code><a>MediaStream</a></code> are intended to be synchronized when
      rendered. This is not a hard requirement, since it might not be possible
      to synchronize tracks from sources that have different clocks. Different
      <code><a>MediaStream</a></code> objects do not need to be
      synchronized.</p>

      <p class="note">While the intent is to synchronize tracks, it could be
      better in some circumstances to permit tracks to lose synchronization. In
      particular, when tracks are remotely sourced and real-time [[WEBRTC10]],
      it can be better to allow loss of synchronization than to accumulate
      delays or risk glitches and other artifacts. Implementations are expected
      to understand the implications of choices regarding synchronization of
      playback and the effect that these have on user perception.</p>

      <p>A single <code><a>MediaStreamTrack</a></code> can represent
      multi-channel content, such as stereo or 5.1 audio or stereoscopic video,
      where the channels have a well defined relationship to each other.
      Information about channels might be exposed through other APIs, such as
      [[WEBAUDIO]], but this specification provides no direct access to
      channels.</p>

      <p>A <code><a>MediaStream</a></code> object has an input and an output
      that represent the combined input and output of all the object's tracks.
      The output of the <code><a>MediaStream</a></code> controls how the object
      is rendered, e.g., what is saved if the object is recorded to a file or
      what is displayed if the object is used in a <code>video</code> element.
      A single <code><a>MediaStream</a></code> object can be attached to
      multiple different outputs at the same time.</p>

      <p>A new <code><a>MediaStream</a></code> object can be created from
      existing media streams or tracks using the <code><a href=
      "#dom-mediastream">MediaStream()</a></code> constructor. The constructor
      argument can either be an existing <code><a>MediaStream</a></code>
      object, in which case all the tracks of the given stream are added to the
      new <code><a>MediaStream</a></code> object, or an array of
      <code><a>MediaStreamTrack</a></code> objects. The latter form makes it
      possible to compose a stream from different source streams.</p>

      <p>Both <code><a>MediaStream</a></code> and
      <code><a>MediaStreamTrack</a></code> objects can be cloned. A cloned
      <code><a>MediaStream</a></code> contains clones of all member tracks from
      the original stream. A cloned <code><a>MediaStreamTrack</a></code> has a
      <a href="#constrainable-interface">set of constraints</a> that is
      independent of the instance it is cloned from, which allows media from
      the same source to have different constraints applied for different
      <a>consumer</a>s. The <code>MediaStream</code> object is also used in
      contexts outside <code>getUserMedia</code>, such as [[WEBRTC10]].</p>
    </section>

    <section>
      <h2>MediaStream</h2>

      <p>The <dfn id="dom-mediastream"><code>MediaStream()</code></dfn>
      constructor composes a new stream out of existing tracks. It takes an
      optional argument of type <code><a>MediaStream</a></code> or an array of
      <code><a>MediaStreamTrack</a></code> objects. <dfn id=
      "mediastream-constructor">When the constructor is invoked</dfn>, the User
      Agent must run the following steps:</p>

      <ol>
        <li>
          <p>Let <var>stream</var> be a newly constructed
          <code><a>MediaStream</a></code> object.</p>
        </li>

        <li>
          <p>Initialize <var>stream's</var> <code><a href=
          "#dom-mediastream-id">id</a></code> attribute to a newly generated
          value.</p>
        </li>

        <li>
          <p>If the constructor's argument is present, construct a set of
          tracks, <var>tracks</var> based on the type of argument:</p>

          <ul>
            <li>
              <p>A <code><a>MediaStream</a></code> object:</p>

              <p>Let <var>tracks</var> be a set containing all the
              <code><a>MediaStreamTrack</a></code> objects in the
              <code><a>MediaStream</a></code> <a href="#track-set">track
              set</a>.</p>
            </li>

            <li>
              <p>A sequence of <code><a>MediaStreamTrack</a></code>
              objects:</p>

              <p>Let <var>tracks</var> be a set containing all the
              <code><a>MediaStreamTrack</a></code> objects in the provided
              sequence.</p>
            </li>
          </ul>
        </li>

        <li>
          <p>Run the steps for <code><a href=
          "#widl-MediaStream-addTrack-void-MediaStreamTrack-track">addTrack</a></code>
          on <var>stream</var> for each <code><a>MediaStreamTrack</a></code> in
          <var>tracks</var>.</p>
        </li>

        <li>
          <p>If <var>stream</var>'s <a href="#track-set">track set</a> is empty
          or only contains <a href="#track-ended">ended</a> tracks, set
          <var>stream</var>'s <code><a href="#stream-active">active</a></code>
          attribute to <code>false</code>, otherwise set it to
          <code>true</code>.</p>
        </li>

        <li>
          <p>Return <var>stream</var>.</p>
        </li>
      </ol>

      <p>The tracks of a <code><a>MediaStream</a></code> are stored in a
      <dfn id="track-set">track set</dfn>. The track set MUST contain the
      <code><a>MediaStreamTrack</a></code> objects that correspond to the
      tracks of the stream. The relative order of the tracks in the set is User
      Agent defined and the API will never put any requirements on the order.
      The proper way to find a specific <code><a>MediaStreamTrack</a></code>
      object in the set is to look it up by its <code><a href=
      "#dom-mediastreamtrack-id">id</a></code>.</p>

      <p>An object that reads data from the output of a
      <code><a>MediaStream</a></code> is referred to as a
      <code><a>MediaStream</a></code> <dfn>consumer</dfn>. The list of
      <code><a>MediaStream</a></code> consumers currently include media
      elements (such as <code>&lt;video&gt;</code> and
      <code>&lt;audio&gt;</code>) [[HTML5]], Web Real-Time Communications
      (WebRTC; <code>RTCPeerConnection</code>) [[WEBRTC10]], media recording
      (<code>MediaRecorder</code>) [[mediastream-recording]], image capture
      (<code>ImageCapture</code>) [[image-capture]], and web audio
      (<code>MediaStreamAudioSourceNode</code>) [[WEBAUDIO]].</p>

      <p class="note"><code><a>MediaStream</a></code> consumers must be able to
      handle tracks being added and removed. This behavior is specified per
      consumer.</p>

      <p>A <code><a>MediaStream</a></code> object is said to be <dfn id=
      "stream-active">active</dfn> when it has at least one
      <code><a>MediaStreamTrack</a></code> that has not <a href=
      "#track-ended">ended</a>. A <code><a>MediaStream</a></code> that does not
      have any tracks or only has tracks that are <a href=
      "#track-ended">ended</a> is <dfn id="stream-inactive">inactive</dfn>.</p>

      <p>When a <code><a>MediaStream</a></code> goes from being active to
      inactive, the User Agent MUST queue a task that sets the object's
      <code><a href="#stream-active">active</a></code> attribute to
      <code>false</code> and fire a simple event named <code><a href=
      "#event-mediastream-inactive">inactive</a></code> at the object. When a
      <code><a>MediaStream</a></code> goes from being inactive to active, the
      User Agent MUST queue a task that sets the object's <code><a href=
      "#stream-active">active</a></code> attribute to <code>true</code> and
      fire a simple event named <code><a href=
      "#event-mediastream-active">active</a></code> at the object.</p>

      <p>If the stream's activity status changed due to a user request, the
      <a href="http://www.w3.org/TR/html5/webappapis.html#task-source">task
      source</a> [[!HTML5]] for this <span title="concept-task">task</span> is
      the <a href=
      "http://www.w3.org/TR/html5/webappapis.html#user-interaction-task-source">
      user interaction task source</a> [[!HTML5]]. Otherwise the task source
      for this <span title="concept-task">task</span> is the <a href=
      "http://www.w3.org/TR/html5/webappapis.html#networking-task-source">networking
      task source</a> [[!HTML5]].</p>

      <dl class="idl" title="interface MediaStream : EventTarget">
        <dt>Constructor()</dt>

        <dd>
          <p>See the <a href="#mediastream-constructor">MediaStream constructor
          algorithm</a></p>
        </dd>

        <dt>Constructor(MediaStream stream)</dt>

        <dd>
          <p>See the <a href="#mediastream-constructor">MediaStream constructor
          algorithm</a></p>
        </dd>

        <dt>Constructor(sequence&lt;MediaStreamTrack&gt; tracks)</dt>

        <dd>
          <p>See the <a href="#mediastream-constructor">MediaStream constructor
          algorithm</a></p>
        </dd>

        <dt>readonly attribute DOMString id</dt>

        <dd>
          <p>When a <code><a>MediaStream</a></code> object is created, the User
          Agent MUST generate an identifier string, and MUST initialize the
          object's <code><a href="#dom-mediastream-id">id</a></code> attribute
          to that string. A good practice is to use a UUID [[rfc4122]], which
          is 36 characters long in its canonical form.</p>

          <p>The <dfn id="dom-mediastream-id"><code>id</code></dfn> attribute
          MUST return the value to which it was initialized when the object was
          created.</p>
        </dd>

        <dt>sequence&lt;MediaStreamTrack&gt; getAudioTracks()</dt>

        <dd>
          <p>Returns a sequence of <code><a>MediaStreamTrack</a></code> objects
          representing the audio tracks in this stream.</p>

          <p>The <dfn id=
          "dom-mediastream-getaudiotracks"><code>getAudioTracks()</code></dfn>
          method MUST return a sequence that represents a snapshot of all the
          <code><a>MediaStreamTrack</a></code> objects in this stream's
          <a href="#track-set">track set</a> whose <code><a href=
          "#dom-mediastreamtrack-kind">kind</a></code> is equal to
          "<code>audio</code>". The conversion from the <a href=
          "#track-set">track set</a> to the sequence is user agent defined and
          the order does not have to be stable between calls.</p>
        </dd>

        <dt>sequence&lt;MediaStreamTrack&gt; getVideoTracks()</dt>

        <dd>
          <p>Returns a sequence of <code><a>MediaStreamTrack</a></code> objects
          representing the video tracks in this stream.</p>

          <p>The <dfn id=
          "dom-mediastream-getvideotracks"><code>getVideoTracks()</code></dfn>
          method MUST return a sequence that represents a snapshot of all the
          <code><a>MediaStreamTrack</a></code> objects in this stream's
          <a href="#track-set">track set</a> whose <code><a href=
          "#dom-mediastreamtrack-kind">kind</a></code> is equal to
          "<code>video</code>". The conversion from the <a href=
          "#track-set">track set</a> to the sequence is user agent defined and
          the order does not have to be stable between calls.</p>
        </dd>

        <dt>sequence&lt;MediaStreamTrack&gt; getTracks()</dt>

        <dd>
          <p>Returns a sequence of <code><a>MediaStreamTrack</a></code> objects
          representing all the tracks in this stream.</p>

          <p>The <dfn id=
          "dom-mediastream-gettracks"><code>getTracks()</code></dfn> method
          MUST return a sequence that represents a snapshot of all the
          <code><a>MediaStreamTrack</a></code> objects in this stream's
          <a href="#track-set">track set</a>, regardless of <code><a href=
          "#dom-mediastreamtrack-kind">kind</a></code>. The conversion from the
          <a href="#track-set">track set</a> to the sequence is User Agent
          defined and the order does not have to be stable between calls.</p>
        </dd>

        <dt>MediaStreamTrack? getTrackById(DOMString trackId)</dt>

        <dd>
          <p>The <dfn id=
          "dom-mediastream-gettrackbyid"><code>getTrackById()</code></dfn>
          method MUST return either a <code><a>MediaStreamTrack</a></code>
          object from this stream's <a href="#track-set">track set</a> whose
          <code><a href="#dom-mediastreamtrack-id">id</a></code> is equal to
          <var>trackId</var>, or null, if no such track exists.</p>
        </dd>

        <dt>void addTrack(MediaStreamTrack track)</dt>

        <dd>
          <p>Adds the given <code><a>MediaStreamTrack</a></code> to this
          <code><a>MediaStream</a></code>.</p>

          <p>When the <dfn id=
          "dom-mediastream-addtrack"><code>addTrack()</code></dfn> method is
          invoked, the User Agent MUST run the following steps:</p>

          <ol>
            <li>
              <p>Let <var>track</var> be the
              <code><a>MediaStreamTrack</a></code> argument and
              <var>stream</var> this <code><a>MediaStream</a></code>
              object.</p>
            </li>

            <li>
              <p>If <var>track</var> is already in <var>stream's</var> <a href=
              "#track-set">track set</a>, then abort these steps.</p>
            </li>

            <li>
              <p>Add <var>track</var> to <var>stream</var>'s <a href=
              "#track-set">track set</a>.</p>
            </li>
          </ol>
        </dd>

        <dt>void removeTrack(MediaStreamTrack track)</dt>

        <dd>
          <p>Removes the given <code><a>MediaStreamTrack</a></code> object from
          this <code><a>MediaStream</a></code>.</p>

          <p>When the <dfn id=
          "dom-mediastream-removetrack"><code>removeTrack()</code></dfn> method
          is invoked, the User Agent MUST remove the
          <code><a>MediaStreamTrack</a></code> object, indicated by the
          method's argument, from the stream's <a href="#track-set">track
          set</a>, if present.</p>
        </dd>

        <dt>MediaStream clone()</dt>

        <dd>
          <p>Clones the given <code><a>MediaStream</a></code> and all its
          tracks.</p>

          <p>When the <dfn id=
          "dom-mediastream-clone"><code>MediaStream.clone()</code></dfn> method
          is invoked, the User Agent MUST run the following steps:</p>

          <ol>
            <li>
              <p>Let <var>streamClone</var> be a newly constructed
              <code><a>MediaStream</a></code> object.</p>
            </li>

            <li>
              <p>Initialize <var>streamClone</var>'s <code><a href=
              "#dom-mediastream-id">id</a></code> attribute to a newly
              generated value.</p>
            </li>

            <li>
              <p>Let <var>clonedTracks</var> be a list that contains the result
              of running <code><a href=
              "#dom-mediastreamtrack-clone">MediaStreamTrack.clone()</a></code>
              on all the tracks in the stream on which this method was
              called.</p>
            </li>

            <li>
              <p>Let <var>clonedTracks</var> be <var>streamClone</var>'s
              <a href="#track-set">track set</a>.</p>
            </li>

            <li>Return <var>streamClone</var>.</li>
          </ol>
        </dd>

        <dt>readonly attribute boolean active</dt>

        <dd>
          <p>This attribute is true if the <code><a>MediaStream</a></code> is
          <a href="#stream-active">active</a> and false otherwise.</p>
        </dd>

        <dt>attribute EventHandler onactive</dt>

        <dd>
          <p>This event handler, of type <code><a href=
          "#event-mediastream-active">active</a></code>, is executed when the
          MediaStream becomes active.</p>
        </dd>

        <dt>attribute EventHandler oninactive</dt>

        <dd>
          <p>This event handler, of type <code><a href=
          "#event-mediastream-inactive">inactive</a></code>, is executed when
          the MediaStream becomes inactive.</p>
        </dd>

        <dt>attribute EventHandler onaddtrack</dt>

        <dd>
          <p>This event handler, of type <code><a href=
          "#event-mediastream-addtrack">addtrack</a></code>, is executed when a
          <code><a>MediaStreamTrack</a></code> is added to the MediaStream.</p>
        </dd>

        <dt>attribute EventHandler onremovetrack</dt>

        <dd>
          <p>This event handler, of type <code><a href=
          "#event-mediastream-removetrack">removetrack</a></code>, is executed
          when a <code><a>MediaStreamTrack</a></code> is removed from the
          MediaStream.</p>
        </dd>
      </dl>
    </section>

    <section>
      <h2>MediaStreamTrack</h2>

      <p>A <code><a>MediaStreamTrack</a></code> object represents a media
      source in the User Agent. Several <code><a>MediaStreamTrack</a></code>
      objects can represent the same media source, e.g., when the user chooses
      the same camera in the UI shown by two consecutive calls to
      <code><a>getUserMedia()</a></code> .</p>

      <p>The data from a <code><a>MediaStreamTrack</a></code> object does not
      necessarily have a canonical binary form; for example, it could just be
      "the video currently coming from the user's video camera". This allows
      User Agents to manipulate media in whatever fashion is most suitable on
      the user's platform.</p>

      <p>A script can indicate that a track no longer needs its source with the
      <code><a href=
      "#dom-mediastreamtrack-stop">MediaStreamTrack.stop()</a></code> method.
      When all tracks using a source have been stopped, the given permission
      for that source is revoked and the source is <dfn id=
      "source-stopped">stopped</dfn>. If the data is being generated from a
      live source (e.g., a microphone or camera), then the User Agent SHOULD
      remove any active "on-air" indicator for that source. An implementation
      may use a per source reference count to keep track of source usage, but
      the specifics are out of scope for this specification.</p>

      <p>If there is no stored permission to use that source, the User Agent
      SHOULD also remove the "permission granted" indicator for the source.</p>

      <section>
        <h3>Life-cycle and Media Flow</h3>

        <h4>Life-cycle</h4>

        <p>A <code><a>MediaStreamTrack</a></code> has two states in its
        life-cycle: <code>live</code> and <code>ended</code>. A newly created
        <code><a>MediaStreamTrack</a></code> can be in either state depending
        on how it was created. For example, cloning an ended track results in a
        new ended track. The current state is reflected by the object's
        <code><a href="#dom-mediastreamtrack-readystate">readyState</a></code>
        attribute.</p>

        <p>In the <code>live</code> state, the track is active and media is
        available for use by consumers (but may be replaced by
        zero-information-content if the <code><a>MediaStreamTrack</a></code> is
        <a href="#track-muted">muted</a> or <a href=
        "#track-enabled">disabled</a>, see below).</p>

        <p>A muted or disabled <code><a>MediaStreamTrack</a></code> renders
        either silence (audio), black frames (video), or a
        zero-information-content equivalent. For example, a video element
        sourced by a muted or disabled <code><a>MediaStreamTrack</a></code>
        (contained within a <code><a>MediaStream</a></code> ), is playing but
        the rendered content is the muted output. When all tracks connected to
        a source are muted or disabled, the "on-air" or "recording" indicator
        for that source can be turned off; when the track is no longer muted or
        disabled, it MUST be turned back on.</p>

        <p>The muted/unmuted state of a track reflects whether the source
        provides any media at this moment. The enabled/disabled state is under
        application control and determines whether the track outputs media (to
        its consumers). Hence, media from the source only flows when a
        <code><a>MediaStreamTrack</a></code> object is both unmuted and
        enabled.</p>

        <p>A <code><a>MediaStreamTrack</a></code> is <a href=
        "#track-muted">muted</a> when the source is temporarily unable to
        provide the track with data. A track can be muted by a user. Often this
        action is outside the control of the application. This could be as a
        result of the user hitting a hardware switch or toggling a control in
        the operating system / browser chrome. A track can also be muted by the
        User Agent.</p>

        <p>Applications are able to <a href="#track-enabled">enable</a> or
        disable a <code><a>MediaStreamTrack</a></code> to prevent it from
        rendering media from the source. A muted track will however, regardless
        of the enabled state, render silence and blackness. A disabled track is
        logically equivalent to a muted track, from a consumer point of
        view.</p>

        <p>For a newly created <code><a>MediaStreamTrack</a></code> object, the
        following applies. The track is always enabled unless stated otherwise
        (for example when cloned) and the muted state reflects the state of the
        source at the time the track is created.</p>

        <p>A <code><a>MediaStreamTrack</a></code> object is said to
        <em>end</em> when the source of the track is disconnected or
        exhausted.</p>

        <p>A <code><a>MediaStreamTrack</a></code> can be <dfn id=
        "track-detached">detached</dfn> from its source. It means that the
        track is no longer dependent on the source for media data. If no other
        <code><a>MediaStreamTrack</a></code> is using the same source, the
        source will be <a href="#source-stopped">stopped</a>.
        <code><a>MediaStreamTrack</a></code> attributes such as <code><a href=
        "#dom-mediastreamtrack-kind">kind</a></code> and <code><a href=
        "#dom-mediastreamtrack-label">label</a></code> MUST NOT change values
        when the source is detached.</p>

        <p>When a <code><a>MediaStreamTrack</a></code> object ends for any
        reason (e.g., because the user rescinds the permission for the page to
        use the local camera, or because the application invoked the
        <code><a href="#dom-mediastreamtrack-stop">stop()</a></code> method on
        the <code><a>MediaStreamTrack</a></code> object, or because the User
        Agent has instructed the track to end for any reason) it is said to be
        <dfn id="track-ended">ended</dfn>.</p>

        <p>When a <code><a>MediaStreamTrack</a></code> <var>track</var> ends
        for any reason other than the <code><a href=
        "#dom-mediastreamtrack-stop">stop()</a></code> method being invoked,
        the User Agent MUST queue a task that runs the following steps:</p>

        <ol>
          <li>
            <p>If the <var>track's</var> <code><a href=
            "#dom-mediastreamtrack-readystate">readyState</a></code> attribute
            has the value <code>ended</code> already, then abort these
            steps.</p>
          </li>

          <li>
            <p>Set <var>track's</var> <code><a href=
            "#dom-mediastreamtrack-readystate">readyState</a></code> attribute
            to <code>ended</code>.</p>
          </li>

          <li>
            <p><a href="#track-detached">Detach</a> <var>track's</var>
            source.</p>
          </li>

          <li>
            <p>Fire a simple event named <code><a href=
            "#event-mediastreamtrack-ended">ended</a></code> at the object.</p>
          </li>
        </ol>

        <p>If the end of the stream was reached due to a user request, the
        event source for this event is the user interaction event source.</p>

        <h4>Media Flow</h4>

        <p>There are two concepts related to the media flow for a
        <code>live</code> <code><a>MediaStreamTrack</a></code> : muted / not
        muted, and enabled / disabled.</p>

        <p><dfn id="track-muted">Muted</dfn> refers to the input to the
        <code><a>MediaStreamTrack</a></code>. If live samples are not made
        available to the <code><a>MediaStreamTrack</a></code> it is muted.</p>

        <p>Muted is out of control for the application, but can be observed by
        the application by reading the <code><a href=
        "#dom-mediastreamtrack-muted">muted</a></code> attribute and listening
        to the associated events <code><a href=
        "#event-mediastreamtrack-mute">mute</a></code> and <code><a href=
        "#event-mediastreamtrack-unmute">unmute</a></code>. There can be
        several reasons for a <code><a>MediaStreamTrack</a></code> to be muted:
        the user pushing a physical mute button on the microphone, the user
        toggling a control in the operating system, the user clicking a mute
        button in the browser chrome, the User Agent (on behalf of the user)
        mutes, etc.</p>

        <p><dfn id="track-enabled">Enabled/disabled</dfn> on the other hand is
        available to application to control (and observe) via the
        <code><a href="#dom-mediastreamtrack-enabled">enabled</a></code>
        attribute.</p>

        <p>The result for the consumer is the same in the meaning that whenever
        <code><a>MediaStreamTrack</a></code> is muted or disabled (or both) the
        consumer gets zero-information-content, which means silence for audio
        and black frames for video. In other words, media from the source only
        flows when a <code><a>MediaStreamTrack</a></code> object is both
        unmuted and enabled. For example, a video element sourced by a muted or
        disabled <code><a>MediaStreamTrack</a></code> (contained in a
        <code><a>MediaStream</a></code> ), is playing but rendering
        blackness.</p>

        <p>For a newly created <code><a>MediaStreamTrack</a></code> object, the
        following applies: the track is always enabled unless stated otherwise
        (for example when cloned) and the muted state reflects the state of the
        source at the time the track is created.</p>
      </section>

      <section>
        <h3>Tracks and Constraints</h3>

        <p>Constraints are set on tracks and may affect sources.</p>

        <p>Whether <code><a>Constraints</a></code> were provided at track
        initialization time or need to be established later at runtime, the
        APIs defined in the <a>ConstrainablePattern</a> Interface allow the
        retrieval and manipulation of the constraints currently established on
        a track.</p>

        <p>Each track maintains an internal version of the
        <code><a>Constraints</a></code> structure, namely a mandatory set of
        constraints (no duplicates) and an optional ordered list of individual
        constraint objects (may contain duplicates). The internal stored
        constraint structure is exposed to the application by the
        <code><a>constraints</a></code> attribute, and may be modified by the
        <code><a>applyConstraints()</a></code> method.</p>

        <p>When <code><a>applyConstraints()</a></code> is called, a User Agent
        MUST queue a task to evaluate those changes when the task queue is next
        serviced.</p>

        <p>If the <code><a>MediaStreamError</a></code> event named
        <code><a>overconstrained</a></code> is thrown, the track MUST be muted
        until either new satisfiable constraints are applied or the existing
        constraints become satisfiable.</p>
      </section>

      <section id="media-stream-track-interface-definition">
        <h3>Interface Definition</h3>

        <dl class="idl" title="interface MediaStreamTrack : EventTarget">
          <dt>readonly attribute DOMString kind</dt>

          <dd>
            <p>The <dfn id=
            "dom-mediastreamtrack-kind"><code>MediaStreamTrack.kind</code></dfn>
            attribute MUST return the string "<code>audio</code>" if the object
            represents an audio track or "<code>video</code>" if object
            represents a video track.</p>
          </dd>

          <dt>readonly attribute DOMString id</dt>

          <dd>
            <p>Unless a <code><a>MediaStreamTrack</a></code> object is created
            as a part of a special purpose algorithm that specifies how the
            track id must be initialized, the User Agent MUST generate an
            identifier string and initialize the object's <code><a href=
            "#dom-mediastreamtrack-id">id</a></code> attribute to that string.
            See <code><a href="#dom-mediastream-id">MediaStream.id</a></code>
            for guidelines on how to generate such an identifier.</p>

            <p>An example of an algorithm that specifies how the track id must
            be initialized is the algorithm to represent an incoming network
            component with a <code><a>MediaStreamTrack</a></code> object.
            [[WEBRTC10]]</p>

            <p><dfn id=
            "dom-mediastreamtrack-id"><code>MediaStreamTrack.id</code></dfn>
            attribute MUST return the value to which it was initialized when
            the object was created.</p>
          </dd>

          <dt>readonly attribute DOMString label</dt>

          <dd>
            <p>User Agents MAY label audio and video sources (e.g., "Internal
            microphone" or "External USB Webcam"). The <dfn id=
            "dom-mediastreamtrack-label"><code>MediaStreamTrack.label</code></dfn>
            attribute MUST return the label of the object's corresponding
            source, if any. If the corresponding source has or had no label,
            the attribute MUST instead return the empty string.</p>
          </dd>

          <dt>attribute boolean enabled</dt>

          <dd>
            <p>The <dfn id=
            "dom-mediastreamtrack-enabled"><code>MediaStreamTrack.enabled</code></dfn>
            attribute controls the <code><a href=
            "#track-enabled">enabled</a></code> state for the object.</p>

            <p>On getting, the attribute MUST return the value to which it was
            last set. On setting, it MUST be set to the new value, regardless
            of whether the <code><a>MediaStreamTrack</a></code> object has been
            <a href="#track-detached">detached</a> from its source or not.</p>

            <p class="note">Thus, after a <code><a>MediaStreamTrack</a></code>
            is detached from its source, its <code><a href=
            "#dom-mediastreamtrack-enabled">enabled</a></code> attribute still
            changes value when set; it just doesn't do anything with that new
            value.</p>
          </dd>

          <dt>readonly attribute boolean muted</dt>

          <dd>
            <p>The <dfn id=
            "dom-mediastreamtrack-muted"><code>MediaStreamTrack.muted</code></dfn>
            attribute MUST return <code>true</code> if the track is <a href=
            "#track-muted">muted</a>, and <code>false</code> otherwise.</p>
          </dd>

          <dt>attribute EventHandler onmute</dt>

          <dd>
            <p>This event handler, of type <code><a href=
            "#event-mediastreamtrack-mute">mute</a></code>, is executed when
            the <code>MediaStreamTrack</code> source is temporarily unable to
            provide data.</p>
          </dd>

          <dt>attribute EventHandler onunmute</dt>

          <dd>
            <p>This event handler, of type <code><a href=
            "#event-mediastreamtrack-unmute">unmute</a></code>, is executed
            when the <code>MediaStreamTrack</code> source is live again after
            having been temporarily unable to provide data.</p>
          </dd>

          <dt>readonly attribute boolean _readonly</dt>

          <dd>
            <p>If the track (audio or video) source is a local microphone or
            camera that is shared so that constraints applied to the track
            cannot modify the source's settings, the <dfn id=
            "dom-mediastreamtrack-readonly"><code>readonly</code></dfn>
            attribute MUST return the value <code>true</code>. Otherwise, it
            must return the value <code>false</code>.</p>
          </dd>

          <dt>readonly attribute boolean remote</dt>

          <dd>
            <p>If the track is sourced by a non-local source, the <dfn id=
            "dom-mediastreamtrack-remote"><code>remote</code></dfn> attribute
            MUST return the value <code>true</code>. Otherwise, it must return
            the value <code>false</code>.</p>
          </dd>

          <dt>readonly attribute MediaStreamTrackState readyState</dt>

          <dd>
            <p>The <dfn id=
            "dom-mediastreamtrack-readystate"><code>readyState</code></dfn>
            attribute represents the state of the track. It MUST return the
            value as most recently set by the User Agent.</p>
          </dd>

          <dt>attribute EventHandler onended</dt>

          <dd>
            <p>This event handler, of type <code><a href=
            "#event-mediastreamtrack-ended">ended</a></code>, is executed when
            the <code>MediaStreamTrack</code> source will no longer provide any
            data, either due to a user action (revoked permission, removal of
            capture device) or due to an error.</p>
          </dd>

          <dt>MediaStreamTrack clone()</dt>

          <dd>
            <p>Clones the given <code><a>MediaStreamTrack</a></code>.</p>

            <p>When the <dfn id=
            "dom-mediastreamtrack-clone"><code>MediaStreamTrack.clone()</code></dfn>
            method is invoked, the User Agent MUST run the following steps:</p>

            <ol>
              <li>
                <p>Let <var>trackClone</var> be a newly constructed
                <code><a>MediaStreamTrack</a></code> object.</p>
              </li>

              <li>
                <p>Initialize <var>trackClone</var>'s <code><a href=
                "#dom-mediastreamtrack-id">id</a></code> attribute to a newly
                generated value.</p>
              </li>

              <li>
                <p>Let <var>trackClone</var> inherit this track's underlying
                source, <code><a href=
                "#dom-mediastreamtrack-kind">kind</a></code>, <code><a href=
                "#dom-mediastreamtrack-label">label</a></code>, <code><a href=
                "#dom-mediastreamtrack-readystate">readyState</a></code>, and
                <code><a href=
                "#dom-mediastreamtrack-enabled">enabled</a></code> attributes,
                as well as its currently active constraints.</p>
              </li>

              <li>
                <p>Return <var>trackClone</var>.</p>
              </li>
            </ol>
          </dd>

          <dt>void stop()</dt>

          <dd>
            <p>When a <code><a>MediaStreamTrack</a></code> object's <dfn id=
            "dom-mediastreamtrack-stop"><code>stop()</code></dfn> method is
            invoked, the User Agent MUST run following steps:</p>

            <ol>
              <li>
                <p>Let <var>track</var> be the current
                <code><a>MediaStreamTrack</a></code> object.</p>
              </li>

              <li>
                <p>If <var>track</var> is sourced by a non-local source, then
                abort these steps.</p>
              </li>

              <li>
                <p>Set <var>track's</var> <code><a href=
                "#dom-mediastreamtrack-readystate">readyState</a></code>
                attribute to <code>ended</code>.</p>
              </li>

              <li>
                <p><a href="#track-detached">Detach</a> <var>track's</var>
                source.</p>
              </li>
            </ol>

            <p>The task source for the <span title="concept-task">tasks</span>
            queued for the <code><a href=
            "#dom-mediastreamtrack-stop">stop()</a></code> method is the DOM
            manipulation task source.</p>
          </dd>

          <dt>MediaTrackCapabilities getCapabilities()</dt>

          <dd>
            <p>See <a href="#constrainable-interface">ConstrainablePattern
            Interface</a> for the definition of this method.</p>
          </dd>

          <dt>MediaTrackConstraints getConstraints()</dt>

          <dd>
            <p>See <a href="#constrainable-interface">ConstrainablePattern
            Interface</a> for the definition of this method.</p>
          </dd>

          <dt>MediaTrackSettings getSettings()</dt>

          <dd>
            <p>See <a href="#constrainable-interface">ConstrainablePattern
            Interface</a> for the definition of this method.</p>
          </dd>

          <dt>Promise&lt;void&gt; applyConstraints()</dt>

          <dd>
            <dl class="parameters">
              <dt>MediaTrackConstraints constraints</dt>

              <dd>
                <p>A new constraint structure to apply to this object.</p>
              </dd>
            </dl>See <a href="#constrainable-interface">ConstrainablePattern
            Interface</a> for the definition of this method.
          </dd>

          <dt>attribute EventHandler onoverconstrained</dt>

          <dd>
            <p>See <a href="#constrainable-interface">ConstrainablePattern
            Interface</a> for the definition of this event handler.</p>
          </dd>
        </dl>

        <dl class="idl" title="enum MediaStreamTrackState">
          <dt>live</dt>

          <dd>
            <p>The track is active (the track's underlying media source is
            making a best-effort attempt to provide data in real time).</p>

            <p>The output of a track in the <code>live</code> state can be
            switched on and off with the <code><a href=
            "#dom-mediastreamtrack-enabled">enabled</a></code> attribute.</p>
          </dd>

          <dt>ended</dt>

          <dd>
            <p>The track has <a href="#track-ended">ended</a> (the track's
            underlying media source is no longer providing data, and will never
            provide more data for this track). Once a track enters this state,
            it never exits it.</p>

            <p>For example, a video track in a <code><a>MediaStream</a></code>
            ends when the user unplugs the USB web camera that acts as the
            track's media source.</p>
          </dd>
        </dl>
      </section>

      <section>
        <h2>Track Source Types</h2>

        <dl class="idl" title="enum SourceTypeEnum">
          <dt>camera</dt>

          <dd>
            <p>A valid source type only for video
            <code><a>MediaStreamTrack</a></code> s. The source is a local
            video-producing camera source.</p>
          </dd>

          <dt>microphone</dt>

          <dd>
            <p>A valid source type only for audio
            <code><a>MediaStreamTrack</a></code> s. The source is a local
            audio-producing microphone source.</p>
          </dd>
        </dl>
      </section>

      <section id="media-track-supported-constraints">
        <h2>MediaTrackSupportedConstraints</h2>

        <p><code><a>MediaTrackSupportedConstraints</a></code> represents the
        list of constraints recognized by a User Agent for controlling the
        <a>Capabilities</a> of a <code><a>MediaStreamTrack</a></code>
        object.</p>

        <p>Future specification can extend the MediaTrackSupportedConstraints
        dictionary by defining a partial dictionary with dictionary members of
        type boolean and an identifier that is a Property Name registered in
        the [[!RTCWEB-CONSTRAINTS]] registry.</p>

        <dl class="idl" title="dictionary MediaTrackSupportedConstraints">
          <dt>boolean width</dt>

          <dd />

          <dt>boolean height</dt>

          <dd />

          <dt>boolean aspectRatio</dt>

          <dd />

          <dt>boolean frameRate</dt>

          <dd />

          <dt>boolean facingMode</dt>

          <dd />

          <dt>boolean volume</dt>

          <dd />

          <dt>boolean sampleRate</dt>

          <dd />

          <dt>boolean sampleSize</dt>

          <dd />

          <dt>boolean echoCancellation</dt>

          <dd />

          <dt>boolean deviceId</dt>

          <dd />

          <dt>boolean groupId</dt>

          <dd />
        </dl>
      </section>

      <section id="media-track-capabilities">
        <h2>MediaTrackCapabilities</h2>

        <p><code><a>MediaTrackCapabilities</a></code> represents the
        <a>Capabilities</a> of a <code><a>MediaStreamTrack</a></code>
        object.</p>

        <p>Future specification can extend the MediaTrackCapabilities
        dictionary by defining a partial dictionary with dictionary members of
        appropriate type and an identifier that is a Property Name registered
        in the [[!RTCWEB-CONSTRAINTS]] registry.</p>

        <dl class="idl" title="dictionary MediaTrackCapabilities">
          <dt>(long or LongRange) width</dt>

          <dd />

          <dt>(long or LongRange) height</dt>

          <dd />

          <dt>(double or DoubleRange) aspectRatio</dt>

          <dd />

          <dt>(double or DoubleRange) frameRate</dt>

          <dd />

          <dt>DOMString facingMode</dt>

          <dd />

          <dt>(double or DoubleRange) volume</dt>

          <dd />

          <dt>(long or LongRange) sampleRate</dt>

          <dd />

          <dt>(long or LongRange) sampleSize</dt>

          <dd />

          <dt>sequence&lt;boolean&gt; echoCancellation</dt>

          <dd />

          <dt>DOMString deviceId</dt>

          <dd />

          <dt>DOMString groupId</dt>

          <dd />
        </dl>
      </section>

      <section id="media-track-constraints">
        <h2>MediaTrackConstraints</h2>

        <dl class="idl" title=
        "dictionary MediaTrackConstraints : MediaTrackConstraintSet">
          <dt>sequence&lt;MediaTrackConstraintSet&gt; advanced</dt>

          <dd>
            <p>See <a href="#constraints">Constraints and ConstraintSet</a> for
            the definition of this element.</p>
          </dd>
        </dl>

        <p>Future specification can extend the MediaTrackConstraintSet
        dictionary by defining a partial dictionary with dictionary members of
        appropriate type and an identifier that is a Property Name registered
        in the [[!RTCWEB-CONSTRAINTS]] registry.</p>

        <dl class="idl" title="dictionary MediaTrackConstraintSet">
          <dt>ConstrainLong width</dt>

          <dd />

          <dt>ConstrainLong height</dt>

          <dd />

          <dt>ConstrainDouble aspectRatio</dt>

          <dd />

          <dt>ConstrainDouble frameRate</dt>

          <dd />

          <dt>ConstrainDOMString facingMode</dt>

          <dd />

          <dt>ConstrainDouble volume</dt>

          <dd />

          <dt>ConstrainLong sampleRate</dt>

          <dd />

          <dt>ConstrainLong sampleSize</dt>

          <dd />

          <dt>ConstrainBoolean echoCancellation</dt>

          <dd />

          <dt>ConstrainDOMString deviceId</dt>

          <dd />

          <dt>ConstrainDOMString groupId</dt>

          <dd />
        </dl>
      </section>

      <section id="media-track-settings">
        <h2>MediaTrackSettings</h2>

        <p><code><a>MediaTrackSettings</a></code> represents the
        <a>Settings</a> of a <code><a>MediaStreamTrack</a></code> object.</p>

        <p>Future specification can extend the MediaTrackSettings dictionary by
        defining a partial dictionary with dictionary members of appropriate
        type and an identifier that is a Property Name registered in the
        [[!RTCWEB-CONSTRAINTS]] registry.</p>

        <dl class="idl" title="dictionary MediaTrackSettings">
          <dt>long width</dt>

          <dd />

          <dt>long height</dt>

          <dd />

          <dt>double aspectRatio</dt>

          <dd />

          <dt>double frameRate</dt>

          <dd />

          <dt>DOMString facingMode</dt>

          <dd />

          <dt>double volume</dt>

          <dd />

          <dt>long sampleRate</dt>

          <dd />

          <dt>long sampleSize</dt>

          <dd />

          <dt>boolean echoCancellation</dt>

          <dd />

          <dt>DOMString deviceId</dt>

          <dd />

          <dt>DOMString groupId</dt>

          <dd />
        </dl>
      </section>
    </section>

    <section>
      <h3>MediaStreamTrackEvent</h3>

      <p>The <code><a href="#event-mediastream-addtrack">addtrack</a></code>
      and <code title="event-MediaStreamTracklist-removetrack"><a href=
      "#event-mediastream-removetrack">removetrack</a></code> events use the
      <code><a>MediaStreamTrackEvent</a></code> interface.</p>

      <p><dfn title="Fire a track event">Firing a track event named
      <var>e</var></dfn> with a <code><a>MediaStreamTrack</a></code>
      <var>track</var> means that an event with the name <var>e</var>, which
      does not bubble (except where otherwise stated) and is not cancelable
      (except where otherwise stated), and which uses the
      <code><a>MediaStreamTrackEvent</a></code> interface with the
      <code><a href="#dom-mediastreamtrackevent-track">track</a></code>
      attribute set to <var>track</var>, MUST be created and dispatched at the
      given target.</p>

      <dl class="idl" data-merge="MediaStreamTrackEventInit" title=
      "interface MediaStreamTrackEvent : Event">
        <dt>Constructor(DOMString type, MediaStreamTrackEventInit
        eventInitDict)</dt>

        <dd>
          <p>Constructs a new <code><a>MediaStreamTrackEvent</a></code>.</p>
        </dd>

        <dt>readonly attribute MediaStreamTrack track</dt>

        <dd>
          <p>The <dfn id=
          "dom-mediastreamtrackevent-track"><code>track</code></dfn> attribute
          represents the <code><a>MediaStreamTrack</a></code> object associated
          with the event.</p>
        </dd>
      </dl>

      <dl class="idl" title="dictionary MediaStreamTrackEventInit : EventInit">
        <dt>MediaStreamTrack track = null</dt>
      </dl>
    </section>
  </section>

  <section class="informative">
    <h2>The model: sources, sinks, constraints, and settings</h2>

    <p>Browsers provide a media pipeline from sources to sinks. In a browser,
    sinks are the &lt;img&gt;, &lt;video&gt;, and &lt;audio&gt; tags.
    Traditional sources include streamed content, files, and web resources. The
    media produced by these sources typically does not change over time - these
    sources can be considered to be static.</p>

    <p>The sinks that display these sources to the user (the actual tags
    themselves) have a variety of controls for manipulating the source content.
    For example, an &lt;img&gt; tag scales down a huge source image of
    1600x1200 pixels to fit in a rectangle defined with
    <code>width="400"</code> and <code>height="300"</code>.</p>

    <p>The getUserMedia API adds dynamic sources such as microphones and
    cameras - the characteristics of these sources can change in response to
    application needs. These sources can be considered to be dynamic in nature.
    A &lt;video&gt; element that displays media from a dynamic source can
    either perform scaling or it can feed back information along the media
    pipeline and have the source produce content more suitable for display.</p>

    <div class="note">
      <p><strong>Note:</strong> This sort of feedback loop is obviously just
      enabling an "optimization", but it's a non-trivial gain. This
      optimization can save battery, allow for less network congestion,
      etc...</p>
    </div>

    <p>Note that <code>MediaStream</code> sinks (such as
    <code>&lt;video&gt;</code>, <code>&lt;audio&gt;</code>, and even
    <code>RTCPeerConnection</code>) will continue to have mechanisms to further
    transform the source stream beyond that which the <a>Settings</a>,
    <a>Capabilities</a>, and <a>Constraints</a> described in this specification
    offer. (The sink transformation options, including those of
    <code>RTCPeerConnection</code>, are outside the scope of this
    specification.)</p>

    <p>The act of changing or applying a track constraint may affect the
    <code><a>settings</a></code> of all tracks sharing that source and
    consequently all down-level sinks that are using that source. Many sinks
    may be able to take these changes in stride, such as the
    <code>&lt;video&gt;</code> element or <code>RTCPeerConnection</code>.
    Others like the Recorder API may fail as a result of a source setting
    change.</p>

    <p>The <code>RTCPeerConnection</code> is an interesting object because it
    acts simultaneously as both a sink <strong>and</strong> a source for
    over-the-network streams. As a sink, it has source transformational
    capabilities (e.g., lowering bit-rates, scaling-up / down resolutions, and
    adjusting frame-rates), and as a source it could have its own settings
    changed by a track source (though in this specification sources with the
    <code><a>remote</a></code> attribute set to true do not consider the
    current constraints applied to a track).</p>

    <p>To illustrate how changes to a given source impact various sinks,
    consider the following example. This example only uses width and height,
    but the same principles apply to all of the <a>Settings</a> exposed in this
    specification. In the first figure a home client has obtained a video
    source from its local video camera. The source's width and height settings
    are 800 pixels and 600 pixels, respectively. Three
    <code><a>MediaStream</a></code> objects on the home client contain tracks
    that use this same <code><a>deviceId</a></code>. The three media streams
    are connected to three different sinks: a <code>&lt;video&gt;</code>
    element (A), another <code>&lt;video&gt;</code> element (B), and a peer
    connection (C). The peer connection is streaming the source video to a
    remote client. On the remote client there are two media streams with tracks
    that use the peer connection as a source. These two media streams are
    connected to two <code>&lt;video&gt;</code> element sinks (Y and
    Z).</p><img alt=
    "Changing media stream source effects: before the requested change" src=
    "images/change_states_before.png">

    <p>Note that at this moment, all of the sinks on the home client must apply
    a transformation to the original source's provided dimension settings. B is
    scaling the video down, A is scaling the video up (resulting in loss of
    quality), and C is also scaling the video up slightly for sending over the
    network. On the remote client, sink Y is scaling the video <em>way</em>
    down, while sink Z is not applying any scaling.</p>

    <p>Using the <a>ConstrainablePattern</a> interface, one of the tracks
    requests a higher resolution (1920 by 1200 pixels) from the home client's
    video source.</p><img alt=
    "Changing media stream source effects: after the requested change" src=
    "images/change_states_after.png">

    <p>Note that the source change immediately affects all of the tracks and
    sinks on the home client, but does not impact any of the sinks (or sources)
    on the remote client. With the increase in the home client source video's
    dimensions, sink A no longer has to perform any scaling, while sink B must
    scale down even further than before. Sink C (the peer connection) must now
    scale down the video in order to keep the transmission constant to the
    remote client.</p>

    <p>While not shown, an equally valid settings change request could be
    client's side). In addition to impacting sink Y and Z in the same manner as
    A, B and C were impacted earlier, it could lead to re-negotiation with the
    peer connection on the home client in order to alter the transformation
    that it is applying to the home client's video source. Such a change is NOT
    REQUIRED to change anything related to sink A or B or the home client's
    video source.</p>

    <p>Note that this specification does not define a mechanism by which a
    change to the remote client's video source could automatically trigger a
    change to the home client's video source. Implementations may choose to
    make such source-to-sink optimizations as long as they only do so within
    the constraints established by the application, as the next example
    demonstrates.</p>

    <p>It is fairly obvious that changes to a given source will impact sink
    consumers. However, in some situations changes to a given sink may also
    cause mplementations to adjust a source's settings. This is illustrated in
    the following figures. In the first figure below, the home client's video
    source is sending a video stream sized at 1920 by 1200 pixels. The video
    source is also unconstrained, such that the exact source dimensions are
    flexible as far as the application is concerned. Two
    <code><a>MediaStream</a></code> objects contain tracks with the same
    <code><a>deviceId</a></code>, and those <code><a>MediaStream</a></code> s
    are connected to two different <code>&lt;video&gt;</code> element sinks A
    and B. Sink A has been sized to <code>width="1920"</code> and
    <code>height="1200"</code> and is displaying the source's video content
    without any transformations. Sink B has been sized smaller and, as a
    result, is scaling the video down to fit its rectangle of 320 pixels across
    by 200 pixels down.</p><img alt=
    "Changing media stream sinks may affect sources: before the requested change"
    src="images/change_states_before2.png">

    <p>When the application changes sink A to a smaller dimension (from 1920 to
    1024 pixels wide and from 1200 to 768 pixels tall), the browser's media
    pipeline may recognize that none of its sinks require the higher source
    resolution, and needless work is being done both on the part of the source
    and sink A. In such a case and without any other constraints forcing the
    source to continue producing the higher resolution video, the media
    pipeline MAY change the source resolution:</p><img alt=
    "Changing media stream sinks may affect sources: after the requested change"
    src="images/change_states_after2.png">

    <p>In the above figure, the home client's video source resolution was
    changed to the greater of that from sink A and B in order to optimize
    playback. While not shown above, the same behavior could apply to peer
    connections and other sinks.</p>

    <p>It is possible that <a>constraints</a> can be applied to a track which a
    source is unable to satisfy, either because the source itself cannot
    satisfy the constraint or because the source is already satisfying a
    conflicting constraint. When this happens, the promise returned from
    <code><a>applyConstraints()</a></code> will be rejected, without applying
    any of the new constraints. Since no change in constraints occurs in this
    case, there is also no required change to the source itself as a result of
    this condition. Here is an example of this behavior.</p>

    <p>In this example, two media streams each have a video track that share
    the same source. The first track initially has no constraints applied. It
    is connected to sink N. Sink N has a resolution of 800 by 600 pixels and is
    scaling down the source's resolution of 1024 by 768 to fit. The other track
    has a mandatory constraint forcing off the source's fill light; it is
    connected to sink P. Sink P has a width and height equal to that of the
    source.</p>

    <p><img alt="Overconstrained application" src=
    "images/overconstrained_apply.png"></p>

    <p>Now, the first track adds a mandatory constraint that the fill light
    should be forced on. At this point, both mandatory constraints cannot be
    satisfied by the source (the fill light cannot be simultaneously on and off
    at the same time). Since this state was caused by the first track's attempt
    to apply a conflicting constraint, the constraint application fails and
    there is no change in the source's settings nor to the constraints on
    either track.</p>

    <p>Let's look at a slightly different situation starting from the same
    point. In this case, instead of the first track attempting to apply a
    conflicting constraint, the user physically locks the camera into a mode
    where the fill light is on. At this point the source can no longer satisfy
    the second track's mandatory constraint that the fill light be off. The
    second track is transitioned into the muted state and receives an
    <a>overconstrained</a> event. At the same time, the source notes that its
    remaining active sink only requires a resolution of 800 by 600 and so it
    adjusts its resolution down to match (this is an optional optimization that
    the User Agent is allowed to make given the situation).</p>

    <p><img alt="Overconstrained occurrence" src=
    "images/overconstrained_occurrence.png"></p>

    <p>At this point, it is the responsibility of the application to address
    the problem that led to the overconstrained situation, perhaps by removing
    the fill light mandatory constraint on the second track or by closing the
    second track altogether and informing the user.</p>
  </section>

  <section>
    <h2>MediaStreams as Media Elements</h2>

    <p>A <code>MediaStream</code> may be assigned to media elements as defined
    in <a href=
    "http://www.w3.org/TR/html5/embedded-content-0.html#media-elements">HTML5</a>
    [[HTML5]] A <code>MediaStream</code> is not preloadable or seekable and
    represents a simple, potentially infinite, linear media timeline. The
    timeline starts at 0 and increments linearly in real time as long as the
    <code>MediaStream</code> is playing. The timeline does not increment when
    the <code>MediaStream</code> is paused.</p>

    <section>
      <h3>Direct Assignment to Media Elements</h3>

      <p>User Agents that support this specification MUST support the following
      partial interface, which allows a MediaStream to be assigned directly to
      a media element.</p>

      <dl class="idl" title="partial interface HTMLMediaElement">
        <dt>attribute MediaStream? srcObject</dt>

        <dd>
          <p>Holds the MediaStream that provides media for this element. This
          attribute overrides both the <code>src</code> attribute and any
          &lt;source&gt; elements. Specifically, if <code>srcObject</code> is
          specified, the User Agent MUST use it as the source of media, even if
          the <code>src</code> attribute is also set or &lt;source&gt; children
          are present. If the value of <code>srcObject</code> is replaced or
          set to null the User Agent MUST re-run the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
          media element load algorithm</a></p>
        </dd>
      </dl>

    </section>

    <section>
      <h3>Loading and Playing a MediaStream in a Media Element</h3>

      <p>The User Agent runs the <a href=
      "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
      media element load algorithm</a> to obtain media for the media element to
      display. As defined in the [[HTML5]] specification, this algorithm has
      two basic phases: <a href=
      "http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-algorithm">
      resource selection algorithm</a> chooses the resource to play and
      resolves its URI. Then the <a href=
      "http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-resource">
      resource fetch phase</a> loads the resource. Both these phases are
      potentially simplified when using a MediaStream. First of all,
      <code>srcObject</code> takes priority over other means of specifying the
      resource, and it provides the object itself rather than a URI. Therefore,
      there is no need to run the resource selection algorithm. Secondly, when
      the User Agent reaches the resource fetch algorithm with a MediaStream,
      the MediaStream is a local object so there's nothing to fetch. Therefore,
      the following modifications/restrictions to the <a href=
      "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
      media element load algorithm</a> apply:</p>

      <ul>
        <li>
          <p>Whenever the User Agent runs the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
          media element load algorithm</a>, if <code>srcObject</code> is
          specified, the User Agent must immediately go to the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-resource">
          resource fetch phase</a> of the algorithm.</p>
        </li>

        <li>
          <p>Whenever the User Agent runs the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
          media element load algorithm</a>, and reaches the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-resource">
          resource fetch phase</a> of this algorithm, if it determines that the
          media resource in question is a MediaStream, it MUST immediately
          abort the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-algorithm">
          resource selection algorithm</a>, and set the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-readystate">
          <code>media.readyState</code></a> to HAVE_NOTHING if the
          <code>MediaStream</code> is inactive, or HAVE_ENOUGH_DATA if it is
          active.</p>
        </li>

        <li>
          <p>For each <code><a>MediaStreamTrack</a></code> in the
          <code><a>MediaStream</a></code> , including those that are added
          after the User Agent enters the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
          media element load algorithm</a>, the User Agent MUST create a
          corresponding <code><a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#audiotrack">AudioTrack</a></code>
          or <code><a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#videotrack">VideoTrack</a></code>
          as defined in [[HTML5]]. Since the order in the
          <code><a>MediaStream</a></code> 's <a href="#track-set">track set</a>
          is undefined, no requirements are put how the <code><a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#audiotracklist">AudioTrackList</a></code>
          and <code><a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#videotracklist">VideoTrackList</a></code>
          are ordered.</p>

          <p>The properties of the <code>AudioTrack</code> and
          <code>VideoTrack</code> objects MUST be initialized as follows.
          Let</p>

          <ul>
            <li>
              <p><code>AudioTrack.id</code> and <code>VideoTrack.id</code> have
              the value of the corresponding <code><a href=
              "#dom-mediastreamtrack-id">MediaStreamTrack.id</a></code>
              attribute</p>
            </li>

            <li>
              <p><code>AudioTrack.kind</code> and <code>VideoTrack.kind</code>
              be <code>"main"</code></p>
            </li>

            <li>
              <p><code>AudioTrack.label</code> and
              <code>VideoTrack.label</code> have the value of the corresponding
              <code><a href=
              "#dom-mediastreamtrack-label">MediaStreamTrack.label</a></code>
              attribute</p>
            </li>

            <li>
              <p><code>AudioTrack.language</code> and
              <code>VideoTrack.language</code> be the empty string</p>
            </li>
          </ul>

          <p>Let the media resource, represented by the
          <code><a>MediaStream</a></code> object, indicate to the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
          media element load algorithm</a> that all audio tracks and all live
          video tracks (represented by a <code><a>MediaStreamTrack</a></code>
          with the <code><a>readyState</a></code> attribute set to
          <code>live</code>) should be enabled. This allows the media element
          load algorithm to set <code>AudioTrack.enabled</code>,
          <code>VideoTrack.selected</code> and
          <code>VideoTrackList.selectedIndex</code> accordingly.</p>

          <p>(Note that since the MediaStream is potentially endless, the User
          Agent does not exit the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
          media element load algorithm</a> until the MediaStream moves from the
          active to the <a href="#stream-inactive">inactive</a> state.)</p>
        </li>

        <li>
          <p>If a <code><a>MediaStreamTrack</a></code> is removed from a
          <code><a>MediaStream</a></code>, played by a media element, the
          corresponding <code>AudioTrack</code> or <code>VideoTrack</code> MUST
          be removed as well.</p>
        </li>

        <li>
          <p>The User Agent MUST NOT buffer data from a MediaStream. When
          playing, the User Agent MUST always play the current data from the
          stream.</p>
        </li>

        <li>
          <p>When the MediaStream state moves from the active to the <a href=
          "#stream-inactive">inactive</a> state, the User Agent MUST raise an
          <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#event-media-ended">
          ended</a> event on the media element and set its <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-ended">ended</a>
          attribute to <code>true</code>. Note that once <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-ended">ended</a>
          equals <code>true</code> the media element will not play media even
          if new Tracks are added to the MediaStream (causing it to return to
          the active state) unless <code>autoplay</code> is <code>true</code>
          or the JavaScript restarts the element, e.g., by calling <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-play">play()</a>.</p>
        </li>
      </ul>
    </section>

    <section>
      <h3>Media Element Attributes when Playing a MediaStream</h3>

      <p>The nature of the <code>MediaStream</code> places certain restrictions
      on the behavior and attribute values of the associated media element and
      on the operations that can be performed on it, as shown below:</p>

      <table class="simple">
        <caption>
          Legal values for the properties of a media element bound to a
          MediaStream
        </caption>

        <thead>
          <tr>
            <th scope="col">Attribute Name</th>

            <th scope="col">Attribute Type</th>

            <th scope="col">Valid Values When Using a MediaStream</th>

            <th scope="col">Additional considerations</th>
          </tr>
        </thead>

        <tbody>
          <tr>
            <td><a class="externalDFN" href=
            "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-currentsrc">
            <code>currentSrc</code></a></td>

            <td><code>DOMString</code></td>

            <td>the empty string</td>

            <td>When <code>srcObject</code> is specified the User Agent MUST
            set this to the empty string.</td>
          </tr>

          <tr>
            <td><a class="externalDFN" href=
            "http://www.w3.org/TR/html5/embedded-content-0.html#attr-media-preload">
            <code>preload</code></a></td>

            <td><code>DOMString</code></td>

            <td><code>none</code></td>

            <td>A MediaStream cannot be preloaded.</td>
          </tr>

          <tr>
            <td><a class="externalDFN" href=
            "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-buffered">
            <code>buffered</code></a></td>

            <td><a class="externalDFN" href=
            "http://www.w3.org/TR/html5/embedded-content-0.html#timeranges"><code>
            TimeRanges</code></a></td>

            <td><code>buffered.length</code> MUST return <code>0</code>.</td>

            <td>A MediaStream cannot be preloaded. Therefore, the amount
            buffered is always an empty TimeRange.</td>
          </tr>

          <tr>
            <td><a class="externalDFN" href=
            "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-networkstate">
            <code>networkState</code></a></td>

            <td><code>unsigned short</code></td>

            <td>NETWORK_IDLE</td>

            <td>The media element does not fetch the MediaStream so there is no
            network traffic.</td>
          </tr>

          <tr>
            <td><a class="externalDFN" href=
            "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-readystate">
            <code>readyState</code></a></td>

            <td><code>unsigned short</code></td>

            <td>HAVE_NOTHING, HAVE_ENOUGH_DATA</td>

            <td>A <code><a>MediaStream</a></code> may be created before there
            is any data available, for example when a stream is received from a
            remote peer. The value of the <code>readyState</code> of the media
            element MUST be HAVE_NOTHING before the first media arrives and
            HAVE_ENOUGH_DATA once the first media has arrived.</td>
          </tr>

          <tr>
            <td><a class="externalDFN" href=
            "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-currenttime">
            <code>currentTime</code></a></td>

            <td><code>double</code></td>

            <td>Any non-negative integer. The initial value is 0 and the values
            increments linearly in real time whenever the stream is
            playing.</td>

            <td>The value is the current stream position, in seconds. On any
            attempt to set this attribute, the User Agent must throw an
            <code>InvalidStateError</code> exception.</td>
          </tr>

          <tr>
            <td><a class="externalDFN" href=
            "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-duration">
            <code>duration</code></a></td>

            <td><code>unrestricted double</code></td>

            <td>Infinity</td>

            <td>A MediaStream does not have a pre-defined duration.</td>
          </tr>

          <tr>
            <td><a class="externalDFN" href=
            "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-seeking">
            <code>seeking</code></a></td>

            <td><code>boolean</code></td>

            <td>false</td>

            <td>A MediaStream is not seekable. Therefore, this attribute MUST
            always have the value <code>false</code>.</td>
          </tr>

          <tr>
            <td><a class="externalDFN" href=
            "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-defaultplaybackrate">
            <code>defaultPlaybackRate</code></a></td>

            <td><code>double</code></td>

            <td>1.0</td>

            <td>A MediaStream is not seekable. Therefore, this attribute MUST
            always have the value <code>1.0</code> and any attempt to alter it
            MUST fail.</td>
          </tr>

          <tr>
            <td><a class="externalDFN" href=
            "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-playbackrate">
            <code>playbackRate</code></a></td>

            <td><code>double</code></td>

            <td>1.0</td>

            <td>A MediaStream is not seekable. Therefore, this attribute MUST
            always have the value <code>1.0</code> and any attempt to alter it
            MUST fail.</td>
          </tr>

          <tr>
            <td><a class="externalDFN" href=
            "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-played">
            <code>played</code></a></td>

            <td><a class="externalDFN" href=
            "http://www.w3.org/TR/html5/embedded-content-0.html#timeranges"><code>
            TimeRanges</code></a></td>

            <td><code>played.length</code> MUST return <code>1</code>.<br>
            <code>played.start(0)</code> MUST return <code>0</code>.<br>
            <code>played.end(0)</code> MUST return the last known <a class=
            "externalDFN" href=
            "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-currenttime">
            <code>currentTime</code></a> .</td>

            <td>A MediaStream's timeline always consists of a single range,
            starting at 0 and extending up to the currentTime.</td>
          </tr>

          <tr>
            <td><a class="externalDFN" href=
            "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-seekable">
            <code>seekable</code></a></td>

            <td><a class="externalDFN" href=
            "http://www.w3.org/TR/html5/embedded-content-0.html#timeranges"><code>
            TimeRanges</code></a></td>

            <td><code>seekable.length</code> MUST return <code>0</code>.</td>

            <td>A MediaStream is not seekable.</td>
          </tr>

          <tr>
            <td><a class="externalDFN" href=
            "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-loop">
            <code>loop</code></a></td>

            <td><code>boolean</code></td>

            <td>true, false</td>

            <td>Setting the <code>loop</code> attribute has no effect since a
            <code><a>MediaStream</a></code> has no defined end and therefore
            cannot be looped.</td>
          </tr>
        </tbody>
      </table>
    </section>
  </section>

  <section>
    <h2>Error Handling</h2>

    <p>All promises in this specification, when they are rejected, are rejected
    with an object that implements the <code><a>MediaStreamError</a></code>
    interface.</p>

    <section>
      <h3>MediaStreamError</h3>

      <p>All errors defined in this specification implement the following
      interface:</p>

      <dl class="idl" title="[NoInterfaceObject] interface MediaStreamError">
        <dt>readonly attribute DOMString name</dt>

        <dd>
          <p>The name of the error</p>
        </dd>

        <dt>readonly attribute DOMString? message</dt>

        <dd>
          <p>A User Agent-dependent string offering extra human-readable
          information about the error.</p>
        </dd>

        <dt>readonly attribute DOMString? constraintName</dt>

        <dd>
          <p>This attribute is only used for some types of errors. For
          <code><a>MediaStreamError</a></code> with a name of
          <code>ConstraintNotSatisfiedError</code> or of
          <code>OverconstrainedError</code>, this attribute MUST be set to the
          name of the constraint that caused the error.</p>
        </dd>
      </dl>

      <div class="note">
        We use MediaStreamError rather than deriving from Error until the
        situation with adding additional information into an error has been
        clarified.
      </div>

      <p>The following interface is defined for cases when a MediaStreamError
      is raised as an event:</p>

      <dl class="idl" data-merge="MediaStreamErrorEventInit" title=
      "interface MediaStreamErrorEvent : Event">
        <dt>Constructor(DOMString type, MediaStreamErrorEventInit
        eventInitDict)</dt>

        <dd>
          <p>Constructs a new <code><a>MediaStreamErrorEvent</a></code>.</p>
        </dd>

        <dt>readonly attribute MediaStreamError? error</dt>

        <dd>
          <p>The <code><a>MediaStreamError</a></code> describing the error that
          triggered the event (if any).</p>
        </dd>
      </dl>

      <dl class="idl" title="dictionary MediaStreamErrorEventInit : EventInit">
        <dt>MediaStreamError? error = null</dt>

        <dd>
          <p>The <code><a>MediaStreamError</a></code> describing the error
          associated with the event (if any)</p>
        </dd>
      </dl>
    </section>

    <section>
      <h3>Error names</h3>

      <p>The table below lists the error names defined in this
      specification.</p>

      <table>
        <caption>
          <code><a>MediaStreamError</a></code> names
        </caption>

        <thead>
          <tr>
            <th>Name</th>

            <th>Description</th>

            <th>Note</th>
          </tr>
        </thead>

        <tbody>
          <tr>
            <th><code><dfn>NotSupportedError</dfn></code></th>

            <td>The operation is not supported.</td>

            <td>Same as defined in [[DOM4]]</td>
          </tr>

          <tr>
            <th><code><dfn>PermissionDeniedError</dfn></code></th>

            <td>The user did not grant permission for the operation.</td>

            <td></td>
          </tr>

          <tr>
            <th><code><dfn>ConstraintNotSatisfiedError</dfn></code></th>

            <td>One of the mandatory <a>Constraints</a> could not be
            satisfied.</td>

            <td>The <code>constraintName</code> attribute gets set to the name
            of the constraint that caused the error</td>
          </tr>

          <tr>
            <th><code><dfn>OverconstrainedError</dfn></code></th>

            <td>Due to changes in the environment, one or more mandatory
            constraints can no longer be satisfied.</td>

            <td>The <code>constraintName</code> attribute gets set to the name
            of the constraint that caused the error</td>
          </tr>

          <tr>
            <th><code><dfn>NotFoundError</dfn></code></th>

            <td>The object can not be found here.</td>

            <td>Same as defined in [[DOM4]]</td>
          </tr>

          <tr>
            <th><code><dfn>AbortError</dfn></code></th>

            <td>The operation was aborted.</td>

            <td>Same as defined in [[DOM4]]</td>
          </tr>

          <tr>
            <th><code><dfn>SourceUnavailableError</dfn></code></th>

            <td>The source of the MediaStream could not be accessed due to a
            hardware error (e.g. lock from another process).</td>

            <td></td>
          </tr>
        </tbody>
      </table>
    </section>
  </section>

  <section class="informative">
    <h2>Event summary</h2>

    <p>The following event fires on <code><a>MediaStream</a></code>
    objects:</p>

    <table>
      <tr>
        <th>Event name</th>

        <th>Interface</th>

        <th>Fired when...</th>
      </tr>

      <tbody>
        <tr>
          <td><code id="event-mediastream-active">active</code></td>

          <td><code>Event</code></td>

          <td>The <code><a>MediaStream</a></code> became active (see <a href=
          "#stream-inactive">inactive</a>).</td>
        </tr>

        <tr>
          <td><code id="event-mediastream-inactive">inactive</code></td>

          <td><code>Event</code></td>

          <td>The <code><a>MediaStream</a></code> became <a href=
          "#stream-inactive">inactive</a>.</td>
        </tr>

        <tr>
          <td><dfn id=
          "event-mediastream-addtrack"><code>addtrack</code></dfn></td>

          <td><code><a>MediaStreamTrackEvent</a></code></td>

          <td>A new <code><a>MediaStreamTrack</a></code> has been added to this
          stream. Note that this event is not fired when the script directly
          modifies the tracks of a <code><a>MediaStream</a></code>.</td>
        </tr>

        <tr>
          <td><dfn id=
          "event-mediastream-removetrack"><code>removetrack</code></dfn></td>

          <td><code><a>MediaStreamTrackEvent</a></code></td>

          <td>A <code><a>MediaStreamTrack</a></code> has been removed from this
          stream. Note that this event is not fired when the script directly
          modifies the tracks of a <code><a>MediaStream</a></code>.</td>
        </tr>
      </tbody>
    </table>

    <p>The following event fires on <code><a>MediaStreamTrack</a></code>
    objects:</p>

    <table>
      <tr>
        <th>Event name</th>

        <th>Interface</th>

        <th>Fired when...</th>
      </tr>

      <tbody>
        <tr>
          <td><dfn id=
          "event-mediastreamtrack-mute"><code>mute</code></dfn></td>

          <td><code>Event</code></td>

          <td>The <code><a>MediaStreamTrack</a></code> object's source is
          temporarily unable to provide data.</td>
        </tr>

        <tr>
          <td><dfn id=
          "event-mediastreamtrack-unmute"><code>unmute</code></dfn></td>

          <td><code>Event</code></td>

          <td>The <code><a>MediaStreamTrack</a></code> object's source is live
          again after having been temporarily unable to provide data.</td>
        </tr>

        <tr>
          <td><dfn id=
          "event-mediastreamtrack-overconstrained"><code>overconstrained</code></dfn></td>

          <td><code><a>MediaStreamErrorEvent</a></code></td>

          <td>
            <p>This error event fires for each affected track (when multiple
            tracks share the same source) after the user agent has evaluated
            the current constraints against a given
            <code><a>deviceId</a></code> and is not able to configure the
            source within the limitations established by the union of imposed
            constraints.</p>

            <p>Due to being over-constrained, the User Agent must mute each
            affected track.</p>

            <p>The affected track(s) will remain <a href=
            "#track-muted">muted</a> until the application adjusts the
            constraints to accommodate the source's current effective
            capabilities.</p>
          </td>
        </tr>

        <tr>
          <td><code id="event-mediastreamtrack-ended">ended</code></td>

          <td><code><a>MediaStreamErrorEvent</a></code></td>

          <td>
            <p>The <code><a>MediaStreamTrack</a></code> object's source will no
            longer provide any data, either because the user revoked the
            permissions, or because the source device has been ejected, or
            because the remote peer permanently stopped sending data.</p>

            <p>When the end of MediaStreamTrack is the result of an error, the
            <code>error</code> attribute of the event object is set to describe
            the said error.</p>
          </td>
        </tr>
      </tbody>
    </table>

    <p>The following event fires on <code><a>MediaDevices</a></code>
    objects:</p>

    <table>
      <tr>
        <th>Event name</th>

        <th>Interface</th>

        <th>Fired when...</th>
      </tr>

      <tbody>
        <tr>
          <td><dfn id=
          "event-mediadevices-devicechange"><code>devicechange</code></dfn></td>

          <td><code>Event</code></td>

          <td>The set of media devices, available to the User Agent, has
          changed. The current list devices can be retrieved with the
          <code><a href=
          "#dom-mediadevices-enumeratedevices">enumerateDevices()</a></code>
          method.</td>
        </tr>
      </tbody>
    </table>
  </section>

  <section id="enumerating-devices">
    <h2>Enumerating Local Media Devices</h2>

    <p>This section describes an API that the script can use to query the User
    Agent about connected media input and output devices (for example a web
    camera or a headset).</p>

    <section>
      <h3>NavigatorUserMedia</h3>

      <dl class="idl" title="[NoInterfaceObject] interface NavigatorUserMedia">
        <dt>readonly attribute MediaDevices mediaDevices</dt>

        <dd>
          <p>Returns the <code>MediaDevices</code> object associated with this
          <code>Navigator</code> object.</p>
        </dd>
      </dl>
      <div class="idl" title="Navigator implements NavigatorUserMedia">
    </section>

    <section>
      <h3>MediaDevices</h3>

      <p>The <code>MediaDevices</code> object which is the entry point to the
      API used to examine and get access to media devices available to the User
      Agent.</p>

      <p>When a new media input or output device is made available, the user
      agent MUST queue a task fires a simple event named <code><a href=
      "#event-mediadevices-devicechange">devicechange</a></code> at the
      <code><a>MediaDevices</a></code> object.</p>

      <dl class="idl" title="interface MediaDevices : EventTarget">
        <dt>attribute EventHandler ondevicechange</dt>

        <dd>
          <p>This event handler, of type <code><a href=
          "#event-mediadevices-devicechange">devicechange</a></code>, is
          executed when the set of media devices available to the user agent
          has changed.</p>
        </dd>

        <dt>Promise&lt;sequence&lt;MediaDeviceInfo&gt;&gt; enumerateDevices
        ()</dt>

        <dd>
          <p>Collects information about the User Agents available media input
          and output devices.</p>

          <p>Returns a promise. The promise will be fulfilled with a sequence
          of <code><a>MediaDeviceInfo</a></code> dictionaries representing the
          User Agent's available media input and output devices if enumeration
          is successful.</p>

          <p>Camera and microphone sources <em class="rfc2119">should</em> be
          enumerable. Specifications that add additional types of source will
          provide recommendations about whether the source type should be
          enumerable.</p>

          <p>When the <dfn id=
          "dom-mediadevices-enumeratedevices"><code>enumerateDevices()</code></dfn>
          method is called, the User Agent must run the following steps:</p>

          <ol>
            <li>
              <p>Let <var>p</var> be a new promise.</p>
            </li>

            <li>
              <p>Run the following steps asynchronously:</p>

              <ol>
                <li>
                  <p>Let <var>resultList</var> be an empty list.</p>
                </li>

                <li>
                  <p>If this method has been called previously within this
                  application session, let <var>oldList</var> be the list of
                  <code><a>MediaDeviceInfo</a></code> objects that was produced
                  at that call (<var>resultList</var>); otherwise, let
                  <var>oldList</var> be an empty list.</p>
                </li>

                <li>
                  <p>Probe the User Agent for available media devices, and run
                  the following sub steps for each discovered device,
                  <var>device</var>:</p>

                  <ol>
                    <li>
                      <p>If <var>device</var> is represented by a
                      <code><a>MediaDeviceInfo</a></code> object in
                      <var>oldList</var>, append that object to
                      <var>resultList</var>, abort these steps and continue
                      with the next device (if any).</p>
                    </li>

                    <li>
                      <p>Let <var>deviceInfo</var> be a new
                      <code><a>MediaDeviceInfo</a></code> object to represent
                      <var>device</var>.</p>
                    </li>

                    <li>
                      <p>If <var>device</var> belongs to the same physical
                      device as a device, already represented in
                      <var>oldList</var> or <var>resultList</var>, initialize
                      <var>deviceInfo</var>'s <code><a href=
                      "#widl-MediaDeviceInfo-groupId">groupId</a></code> member
                      to the <code><a href=
                      "#widl-MediaDeviceInfo-groupId">groupId</a></code> value
                      of the existing <code><a>MediaDeviceInfo</a></code>
                      object. Otherwise, let <var>deviceInfo</var>'s
                      <code><a href=
                      "#widl-MediaDeviceInfo-groupId">groupId</a></code> member
                      be a newly generated unique identifier.</p>
                    </li>

                    <li>
                      <p>Append <var>deviceInfo</var> to
                      <var>resultList</var>.</p>
                    </li>
                  </ol>
                </li>

                <li>
                  <p>If none of the local devices are attached to an active
                  <code><a>MediaStreamTrack</a></code> in the current browsing
                  context, and if no <a href="stored-permissions">persistent
                  permission</a> to access these local devices have been
                  granted to the page's origin, let <var>filteredList</var> be
                  a copy of <var>resultList</var>, and all its elements, where
                  the <code><a href=
                  "#widl-MediaDeviceInfo-label">label</a></code> member is the
                  empty string.</p>
                </li>

                <li>
                  <p>If <var>filteredList</var> is a non-empty list, then
                  resolve <var>p</var> with <var>filteredList</var>. Otherwise,
                  resolve <var>p</var> with <var>resultList</var>.</p>
                </li>
              </ol>
            </li>

            <li>
              <p>Return <var>p</var>.</p>
            </li>
          </ol>
        </dd>
      </dl>

      <section>
        <h2>Access control model</h2>

        <p>The algorithm described above means that the access to media device
        information depends on whether or not permission has been granted to
        the page's origin to use media devices.</p>

        <p>If no such access has been granted, the
        <code><a>MediaDeviceInfo</a></code> dictionary will contain the
        deviceId, kind, and groupId.</p>

        <p>If access has been granted for a media device, the
        <code><a>MediaDeviceInfo</a></code> dictionary will contain the
        deviceId, kind, label, and groupId.</p>
      </section>
    </section>

    <section>
      <h2>Device Info</h2>

      <dl class="idl" title="interface MediaDeviceInfo">
        <dt>readonly attribute DOMString deviceId</dt>

        <dd>
          <p>A unique identifier for the represented device.</p>

          <p>All enumerable devices have an identifier that MUST be unique to
          the application and persistent across sessions. Unique and stable
          identifiers let the application save, identify the availability of,
          and directly request specific sources.</p>

          <p>This identifier MUST be un-guessable by other applications to
          prevent the identifier being used to correlate the same user across
          different applications.</p>

          <p>Since <code>deviceId</code> persists across sessions and to reduce
          its potential as a fingerprinting mechanism, <code>deviceId</code> is
          to be treated as other persistent storage mechanisms such as cookies
          [[COOKIES]]. User agents <em class="rfc2119">should</em> reset
          per-application device identifiers when other persistent storages are
          cleared.</p>
        </dd>

        <dt>readonly attribute MediaDeviceKind kind</dt>

        <dd>
          <p>Describes the kind of the represented device.</p>
        </dd>

        <dt>readonly attribute DOMString label</dt>

        <dd>
          <p>A label describing this device (for example "External USB
          Webcam"). If the device has no associated label, then this attribute
          MUST return the empty string.</p>
        </dd>

        <dt>readonly attribute DOMString groupId</dt>

        <dd>
          <p>Returns the group identifier of the represented device. Two
          devices have the same group identifier if they belong to the same
          physical device; for example a monitor with a built in camera and
          microphone.</p>
        </dd>
      </dl>

      <dl class="idl" title="enum MediaDeviceKind">
        <dt>audioinput</dt>

        <dd>
          <p>Represents an audio input device; for example a microphone.</p>
        </dd>

        <dt>audiooutput</dt>

        <dd>
          <p>Represents an audio output device; for example a pair of
          headphones.</p>
        </dd>

        <dt>videoinput</dt>

        <dd>
          <p>Represents a video input device; for example a webcam.</p>
        </dd>
      </dl>
    </section>
  </section>

  <section id="local-content">
    <h2>Obtaining local multimedia content</h2>

    <p>This section extends <code><a>NavigatorUserMedia</a></code> and
    <code><a>MediaDevices</a></code> with APIs to request permission to access
    media input devices available to the User Agent.</p>

    <p>When on an insecure origin [[mixed-content]], user agents are encouraged
    to warn about usage of <code>MediaDevices.getUserMedia</code>,
    <code>navigator.getUserMedia</code>, and any prefixed variants in their
    developer tools, error logs, etc. It is explicitly permitted for user
    agents to remove these APIs entirely when on an insecure origin, as long as
    they remove all of them at once (e.g., they should not leave just the
    prefixed version available on insecure origins.)</p>

    <section>
      <h3>NavigatorUserMedia Interface Extensions</h3>

      <div class="note">
        The definition of getUserMedia() in this section reflects two major
        changes from the method definition that has existed here for many
        months.

        <p>First, the official definition for the getUserMedia() method, and
        the one which developers are encouraged to use, is now at <a href=
        "#dom-mediadevices-getusermedia">MediaDevices.getUserMedia()</a>. This
        decision reflected consensus as long as the original API remained
        available here under the Navigator object for backwards compatibility
        reasons, since the working group acknowledges that early users of these
        APIs have been encouraged to define getUserMedia as "var getUserMedia =
        navigator.getUserMedia || navigator.webkitGetUserMedia ||
        navigator.mozGetUserMedia;" in order for their code to be functional
        both before and after official implementations of getUserMedia() in
        popular browsers. To ensure functional equivalence, the getUserMedia()
        method here is defined in terms of the method under MediaDevices.</p>

        <p>Second, the decision to change all other callback-based methods in
        the specification to be based on Promises instead required that the
        Navigator.getUserMedia() definition reflect this in its use of the
        MediaDevices.getUserMedia() method. Because Navigator.getUserMedia() is
        now the only callback-based method remaining in the specification,
        there is ongoing discussion as to a) whether it still belongs in the
        specification, and b) if it does, whether its syntax should remain
        callback-based or change in some way to use Promises. Input on these
        questions is encouraged, particularly from developers actively using
        today's implementations of this functionality.</p>

        <p>Note that the other methods that changed from a callback-based
        syntax to a Promises-based syntax were not considered to have been
        implemented widely enough in any form to have to consider legacy
        usage.</p>
      </div>

      <dl class="idl" title="partial interface NavigatorUserMedia">
        <dt>void getUserMedia(MediaStreamConstraints constraints,
        NavigatorUserMediaSuccessCallback successCallback,
        NavigatorUserMediaErrorCallback errorCallback)</dt>

        <dd>
          <p>Prompts the user for permission to use their Web cam or other
          video or audio input.</p>

          <p>The <var>constraints</var> argument is a dictionary of type
          <code><a>MediaStreamConstraints</a></code>.</p>

          <p>The <var>successCallback</var> will be invoked with a suitable
          <code><a>MediaStream</a></code> object as its argument if the user
          accepts valid tracks as described in <a href=
          "#dom-mediadevices-getusermedia">MediaDevices.getUserMedia()</a>.</p>

          <p>The <var>errorCallback</var> will be invoked if there is a failure
          in finding valid tracks or if the user denies permission, as
          described in <a href=
          "#dom-mediadevices-getusermedia">MediaDevices.getUserMedia()</a>.</p>

          <p>When the <code id=
          "dom-navigatorusermedia-getusermedia">getUserMedia()</code> method is
          called, the User Agent MUST run the following steps:</p>

          <ol>
            <li>
              <p>Let <var>constraints</var> be the method's first argument.</p>
            </li>

            <li>
              <p>Let <var>successCallback</var> be the callback indicated by
              the method's second argument.</p>
            </li>

            <li>
              <p>Let <var>errorCallback</var> be the callback indicated by the
              method's third argument.</p>
            </li>

            <li>
              <p>Invoke <a href=
              "#dom-mediadevices-getusermedia">MediaDevices.getUserMedia()</a>
              with <var>constraints</var> as the argument, and let <var>p</var>
              be the resulting promise.</p>
            </li>

            <li>
              <p>Upon fulfillment of <var>p</var> with value <var>stream</var>,
              run the following step:</p>

              <ol>
                <li>
                  <p>Invoke <var>successCallback</var> with <var>stream</var>
                  as the argument.</p>
                </li>
              </ol>
            </li>

            <li>
              <p>Upon rejection of <var>p</var> with reason <var>r</var>, run
              the following step:</p>

              <ol>
                <li>
                  <p>Invoke <var>errorCallback</var> with <var>r</var> as the
                  argument.</p>
                </li>
              </ol>
            </li>
          </ol>
        </dd>
      </dl>
    </section>

    <section>
      <h3>MediaDevices Interface Extensions</h3>

      <div class="note">
        The definition of getUserMedia() in this section reflects two major
        changes from the method definition that has existed under
        NavigatorUserMedia for many months.

        <p>First, the official definition for the getUserMedia() method, and
        the one which developers are encouraged to use, is now the one defined
        here under MediaDevices. This decision reflected consensus as long as
        the original API remained available at <a href=
        "#dom-navigatorusermedia-getusermedia">NavigatorUserMedia.getUserMedia()</a>
        under the Navigator object for backwards compatibility reasons, since
        the working group acknowledges that early users of these APIs have been
        encouraged to define getUserMedia as "var getUserMedia =
        navigator.getUserMedia || navigator.webkitGetUserMedia ||
        navigator.mozGetUserMedia;" in order for their code to be functional
        both before and after official implementations of getUserMedia() in
        popular browsers. To ensure functional equivalence, the getUserMedia()
        method under NavigatorUserMedia is defined in terms of the method
        here.</p>

        <p>Second, the method defined here is Promises-based, while the one
        defined under NavigatorUserMedia is currently still callback-based.
        Developers expecting to find getUserMedia() defined under
        NavigatorUserMedia are strongly encouraged to read the detailed Note
        given there.</p>
      </div>

      <p>The <code>getSupportedConstraints</code> method is provided to allow
      the application to determine which constraints the User Agent
      recognizes.</p>

      <dl class="idl" title="partial interface MediaDevices">
        <dt>MediaTrackSupportedConstraints getSupportedConstraints()</dt>

        <dd>
          <p>Returns a dictionary whose members are the constrainable
          properties known to the User Agent. A supported constrainable
          property MUST be represented by a member whose name is the constraint
          name and whose value is <code>true</code>. Any constrainable
          properties not supported by the User Agent MUST not be present in the
          returned dictionary. The values returned represent what the browser
          implements and will not change during a session.</p>
        </dd>

        <dt>Promise&lt;MediaStream&gt; getUserMedia( MediaStreamConstraints
        constraints)</dt>

        <dd>
          <p>Prompts the user for permission to use their Web cam or other
          video or audio input.</p>

          <p>The <var>constraints</var> argument is a dictionary of type
          <code><a>MediaStreamConstraints</a></code>.</p>

          <p>Returns a promise. The promise will be fulfilled with a suitable
          <code><a>MediaStream</a></code> object if the user accepts valid
          tracks as described below.</p>

          <p>The promise will be rejected if there is a failure in finding
          valid tracks or if the user denies permission, as described
          below.</p>

          <p>When the <dfn id=
          "dom-mediadevices-getusermedia"><code>getUserMedia()</code></dfn>
          method is called, the User Agent MUST run the following steps:</p>

          <ol>
            <li>
              <p>Let <var>p</var> be a new promise.</p>
            </li>

            <li>
              <p>Let <var>constraints</var> be the method's first argument.</p>
            </li>

            <li>
              <p>Run the following steps asynchronously:</p>

              <ol>
                <li>
                  <p>Let <var>requestedMediaTypes</var> be the set of media
                  types in <var>constraints</var> with either a dictionary
                  value or a value of "true".</p>
                </li>

                <li>
                  <p>If <var>requestedMediaTypes</var> is the empty set, let
                  <var>error</var> be a new
                  <code><a>MediaStreamError</a></code> object whose
                  <code><a>name</a></code> attribute has the value
                  <code>NotSupportedError</code> and jump to the step labeled
                  <em>Error Task</em> below.</p>
                </li>

                <li>
                  <p>Let <var>finalSet</var> be an (initially) empty set.</p>
                </li><!-- we could throw an exception instead (that's
   why the method doesn't return until later: so that we can add an
   exception here, or for /options/ below, without changing the
   algorithm) -->
                <!--
            <li>
              <p>For each member of the <code><a>MediaStreamOptions</a></code>
              dictionary create a local representation and set it to false.</p>
            </li>

            <li>
              <p>For each property in <var>options</var> that is present and
              set to true, let the corresponding local representation be
              true.</p>
            </li>

            <li>
              <p>If none of the local representations of the
              <code><a>MediaStreamOptions</a></code> dictionary members is set
              to true, then throw a <code>NOT_SUPPORTED_ERR</code> exception
              and abort these steps.</p>
            </li>
-->

                <li>
                  <p>For each media type <var>T</var> in
                  <var>requestedMediaTypes</var>,</p>

                  <ol>
                    <li>
                      <p>For each possible source for that media type,
                      construct an unconstrained MediaStreamTrack with that
                      source as its source.</p>

                      <p>Call this set of tracks the
                      <var>candidateSet</var>.</p>
                    </li>

                    <li>If the value of the <var>T</var> entry of
                    <var>constraints</var> is "true", set CS to the empty
                    constraint set (no constraint). Otherwise, continue with
                    <var>CS</var> set to the value of the <var>T</var> entry of
                    <var>constraints</var>.</li>

                    <li>
                      <p>Run the <code><a>SelectSettings</a></code> algorithm
                      on each track in <var>CandidateSet</var> with
                      <var>CS</var> as the constraint set. If the algorithm
                      does not return <code>undefined</code>, add the track to
                      <var>finalSet</var>. This eliminates devices unable to
                      satisfy the constraints, by verifying that at least one
                      settings dictionary exists that satisfies the
                      constraints.</p>
                    </li>
                  </ol>

                  <p>If <var>finalSet</var> is the empty set, let
                  <var>error</var> be a new
                  <code><a>MediaStreamError</a></code> object whose
                  <code><a>name</a></code> attribute has the value
                  <code>NotFoundError</code> and jump to the step labeled
                  <em>Error Task</em> below.</p>
                </li>

                <li>
                  <p>Optionally, e.g., based on a previously-established user
                  preference, for security reasons, or due to platform
                  limitations, jump to the step labeled <em>Permission
                  Failure</em> below.</p>
                </li>

                <li>
                  <p>Prompt the user in a User Agent specific manner for
                  permission to provide the entry script's origin with a
                  <code><a>MediaStream</a></code> object representing a media
                  stream.</p>

                  <p>The provided media MUST include precisely one track of
                  each media type in requestedMediaTypes from the
                  <var>finalSet</var>. The decision of which tracks to choose
                  from the <var>finalSet</var> is completely up to the user
                  agent and may be determined by asking the user. Once
                  selected, the source of a
                  <code><a>MediaStreamTrack</a></code> MUST not change.</p>

                  <p>The user agent MAY use the value of the computed "fitness
                  distance" from the <a>SelectSettings</a> algorithm, or any
                  other internally-available information about the devices, as
                  an input to the selection algorithm.</p>

                  <p>User Agents are encouraged to default to using the user's
                  primary or system default camera and/or microphone (when
                  possible) to generate the media stream. User Agents MAY allow
                  users to use any media source, including pre-recorded media
                  files.</p>

                  <p>If the user grants permission to use local recording
                  devices, User Agents are encouraged to include a prominent
                  indicator that the devices are "hot" (i.e. an "on-air" or
                  "recording" indicator), as well as a "device accessible"
                  indicator indicating that the page has been granted access to
                  the source.</p>

                  <p>If the user denies permission, jump to the step labeled
                  <em>Permission Failure</em> below. If the user never
                  responds, this algorithm stalls on this step.</p>

                  <p>If the user grants permission but a hardware error such as
                  an OS/program/webpage lock prevents access, jump to the step
                  labeled <em>Unavailable Failure</em> below.</p>

                  <p>If the user grants permission but device access fails for
                  any reason other than those listed above, jump to the step
                  labeled <em>General Failure</em> below.</p>
                </li>

                <li>
                  <p>Let <var>stream</var> be the
                  <code><a>MediaStream</a></code> object for which the user
                  granted permission.</p>
                </li>

                <li>
                  <p>Run the <code>ApplyConstraints()</code> algorithm on all
                  tracks in <var>stream</var> with the appropriate
                  constraints.</p>
                </li>

                <li>
                  <p>Resolve <var>p</var> with <var>stream</var>.</p>
                </li>

                <li>
                  <p>Abort these steps.</p>
                </li>

                <li>
                  <p><em>Permission Failure</em>: Let <var>error</var> be a new
                  <code><a>MediaStreamError</a></code> object whose
                  <code><a>name</a></code> attribute has the value
                  <code>PermissionDeniedError</code> and jump to the step
                  labeled <em>Error Task</em> below.</p>
                </li>

                <li>
                  <p><em>Constraint Failure</em>: Let <var>error</var> be a new
                  <code><a>MediaStreamError</a></code> object whose
                  <code><a>name</a></code> attribute has the value
                  <code>ConstraintNotSatisfiedError</code> and whose
                  <code><a href=
                  "#widl-MediaStreamError-constraintName">constraintName</a></code>
                  attribute is set to the name of the constraint that caused
                  the error.</p>
                </li>

                <li>
                  <p><em>Unavailable Failure</em>: Let <var>error</var> be a
                  new <code><a>MediaStreamError</a></code> object whose
                  <code><a>name</a></code> attribute has the value
                  <code>SourceUnavailableError</code> and jump to the step
                  labeled <em>Error Task</em> below.</p>
                </li>

                <li>
                  <p><em>General Failure</em>: Let <var>error</var> be a new
                  <code><a>MediaStreamError</a></code> object whose
                  <code><a>name</a></code> attribute has the value
                  <code>AbortError</code> and jump to the step labeled
                  <em>Error Task</em> below.</p>
                </li>

                <li>
                  <p><em>Error Task:</em> Reject <var>p</var> with
                  <var>error</var>.</p>
                </li>
              </ol>
            </li>

            <li>
              <p>Return <var>p</var>.</p>
            </li>
          </ol>
        </dd>
      </dl>

      <div class="note">
        <p>In the algorithm above, constraints are checked twice - once at
        device selection, and once after access approval. Time may have passed
        between those checks, so it is concievable that the selected device is
        no longer suitable. In this case, a SourceUnavailable error will
        result.</p>
      </div>
    </section>

    <section>
      <h2>MediaStreamConstraints</h2>

      <p>The <code>MediaStreamConstraints</code> dictionary is used to instruct
      the User Agent what sort of <a>MediaStreamTrack</a>s to include in the
      <a>MediaStream</a> returned by <a>getUserMedia()</a>.</p>

      <dl class="idl" title="dictionary MediaStreamConstraints">
        <!--        <dt>boolean audio</dt>

        <dd>
          <p>Set to true if an audio track is requested, default is false</p>
        </dd>

        <dt>boolean video</dt>

        <dd>
          <p>Set to true if a video track is requested, default is false</p>
        </dd>
-->

        <dt>(boolean or MediaTrackConstraints) video = false</dt>

        <dd>
          <p>If <code>true</code>, it requests that the returned
          <a>MediaStream</a> contain a video track. If a <a>Constraints</a>
          structure is provided, it further specifies the nature and settings
          of the video Track. If <code>false</code>, the <a>MediaStream</a>
          MUST not contain a video Track.</p>
        </dd>

        <dt>(boolean or MediaTrackConstraints) audio = false</dt>

        <dd>
          <p>If <code>true</code>, it requests that the returned
          <a>MediaStream</a> contain an audio track. If a <a>Constraints</a>
          structure is provided, it further specifies the nature and settings
          of the audio Track. If <code>false</code>, the <a>MediaStream</a>
          MUST not contain an audio Track.</p>
        </dd>
      </dl>
    </section>

    <section>
      <h2>NavigatorUserMediaSuccessCallback</h2>

      <dl class="idl" title=
      "callback NavigatorUserMediaSuccessCallback = void">
        <dt>MediaStream stream</dt>

        <dd>
          <p class="issue">Add explanation of handleEvent</p>
        </dd>
      </dl>
    </section>

    <section>
      <h2>NavigatorUserMediaErrorCallback</h2>

      <dl class="idl" title="callback NavigatorUserMediaErrorCallback = void">
        <dt>MediaStreamError error</dt>

        <dd>
          <p class="issue">Add explanation of handleEvent</p>
        </dd>
      </dl>
    </section>

    <section>
      <h2>Implementation Suggestions</h2>

      <div class="practice">
        <span class="practicelab" id="resource-reservation">Resource
        reservation</span>

        <p class="practicedesc">The User Agent is encouraged to reserve
        resources when it has determined that a given call to <a href=
        "#dom-mediadevices-getusermedia">getUserMedia()</a> will be successful.
        It is preferable to reserve the resource prior to resolving the
        returned promise. Subsequent calls to <a href=
        "#dom-mediadevices-getusermedia">getUserMedia()</a> (in this page or
        any other) should treat the resource that was previously allocated, as
        well as resources held by other applications, as busy. Resources marked
        as busy should not be provided as sources to the current web page,
        unless specified by the user. Optionally, the user agent may choose to
        provide a stream sourced from a busy source but only to a page whose
        origin matches the owner of the original stream that is keeping the
        source busy.</p>

        <p class="practicedesc">This document recommends that in the permission
        grant dialog or device selection interface (if one is present), the
        user be allowed to select any available hardware as a source for the
        stream requested by the page (provided the resource is able to fulfill
        any specified mandatory constraints). Although not specifically
        recommended as best practice, note that some User Agents may support
        the ability to substitute a video or audio source with local files and
        other media. A file picker may be used to provide this functionality to
        the user.</p>

        <p class="practicedesc">This document also recommends that the user be
        shown all resources that are currently busy as a result of prior calls
        to <a href="#dom-mediadevices-getusermedia">getUserMedia()</a> (in this
        page or any other page that is still alive) and be allowed to terminate
        that stream and utilize the resource for the current page instead. If
        possible in the current operating environment, it is also suggested
        that resources currently held by other applications be presented and
        treated in the same manner. If the user chooses this option, the track
        corresponding to the resource that was provided to the page whose
        stream was affected must be removed.</p>
      </div>

      <div class="practice">
        <span id="stored-permissions" class="practicelab">Stored
        Permissions</span>

        <p class="practicedesc">When permission is requested for a device, the
        User Agent may choose to store that permission, if granted, for later
        use by the same origin, so that the user does not need to grant
        permission again at a later time. Such storing MUST only be done when
        the page is secure (served over HTTPS and having no mixed content). It
        is a User Agent choice whether it offers functionality to store
        permission to each device separately, all devices of a given class, or
        all devices; the choice needs to be apparent to the user, and
        permission must have been granted for the entire set whose permission
        is being stored, e.g., to store permission to use all cameras the user
        must have given permission to use all cameras and not just one.</p>

        <p class="practicedesc">When permission is not stored, permission
        should last only until such time as all MediaStreamTracks sourced from
        that device have been stopped.</p>
      </div>

      <div class="practice">
        <span class="practicelab" id="handling-devices">Handling multiple
        devices</span>

        <p class="practicedesc">A <a>MediaStream</a> may contain more than one
        video and audio track. This makes it possible to include video from two
        or more webcams in a single stream object, for example. However, the
        current API does not allow a page to express a need for multiple video
        streams from independent sources.</p>

        <p class="practicedesc">It is recommended for multiple calls to
        <a href="#dom-mediadevices-getusermedia">getUserMedia()</a> from the
        same page be allowed as a way for pages to request multiple discrete
        video and/or audio streams.</p>

        <p class="practicedesc">Note also that if multiple <a href=
        "#dom-mediadevices-getusermedia">getUserMedia()</a> calls are done by a
        page, the order in which they request resources, and the order in which
        they complete, is not constrained by this specification.</p>

        <p class="practicedesc">A single call to <a href=
        "#dom-mediadevices-getusermedia">getUserMedia()</a> will always return
        a stream with either zero or one audio tracks, and either zero or one
        video tracks. If a script calls <a href=
        "#dom-mediadevices-getusermedia">getUserMedia()</a> multiple times
        before reaching a stable state, this document advises the UI designer
        that the permission dialogs should be merged, so that the user can give
        permission for the use of multiple cameras and/or media sources in one
        dialog interaction. The constraints on each getUserMedia call can be
        used to decide which stream gets which media sources.</p>
      </div>
    </section>
  </section>

  <section id="constrainable-interface">
    <h2>Constrainable Pattern</h2>

    <p>The Constrainable pattern allows applications to inspect and adjust the
    properties of objects implementing it. It is broken out as a separate set
    of definitions so that it can be referred to by other specifications. The
    core concept is the Capability, which consists of a constrainable property
    of an object and the set of its possible values, which may be specified
    either as a range or as an enumeration. For example, a camera might be
    capable of framerates (a property) between 20 and 50 frames per second (a
    range) and may be able to be positioned (a property) facing towards the
    user, away from the user, or to the left or right of the user (an
    enumerated set). The application can examine a constrainable property's
    supported Capabilities via the <code>getCapabilities()</code> accessor.</p>

    <p>The application can select the (range of) values it wants for an
    object's Capabilities by means of basic and/or advanced ConstraintSets and
    the <code>applyConstraints()</code> method. A ConstraintSet consists of the
    names of one or more properties of the object plus the desired value (or a
    range of desired values) for each property. Each of those property/value
    pairs can be considered to be an individual constraint. For example, the
    application may set a ConstraintSet containing two constraints, the first
    stating that the framerate of a camera be between 30 and 40 frames per
    second (a range) and the second that the camera should be facing the user
    (a specific value). How the individual constraints interact depends on
    whether and how they are given in the basic Constraint structure, which is
    a ConstraintSet with an additional 'advanced' property, or whether they are
    in a ConstraintSet in the advanced list. The behavior is as follows: all
    'min', 'max', and 'exact' constraints in the basic Constraint structure are
    together treated as the 'required' set, and if it is not possible to
    satisfy simultaneously all of those individual constraints for the
    indicated property names, the User Agent MUST reject the returned promise.
    Otherwise, it must apply the required constraints. Next, it will consider
    any ConstraintSets given in the 'advanced' list, in the order in which they
    are specified, and will try to satisfy/apply each complete ConstraintSet
    (i.e., all constraints in the ConstraintSet together), but will skip a
    ConstraintSet if and only if it cannot satisfy/apply it in its entirety.
    Next, the User Agent MUST attempt to apply, individually, any 'ideal'
    constraints or a constraint given as a bare value for the property. Of
    these properties, it MUST satisfy the largest number that it can, in any
    order. Finally, the User Agent MUST resolve the returned promise.</p>

    <div class="note">
      Any constraint provided via this API will only be considered if the given
      constrainable property is supported by the browser. JavaScript
      application code is expected to first check, via
      <code>getSupportedConstraints()</code>, that all the named properties
      that are used are supported by the browser. The reason for this is that
      WebIDL drops any unsupported names from the dictionary holding the
      constraints, so the browser does not see them and the unsupported names
      end up being silently ignored. This will cause confusing programming
      errors as the JavaScript code will be setting constraints but the browser
      will be ignoring them. Browsers that support (recognize) the name of a
      required constraint but cannot satisfy it will generate an error, while
      browsers that do not support the constrainable property will not generate
      an error.
    </div>

    <p>The following examples may help to understand how constraints work. The
    first shows a basic Constraint structure. Three constraints are given, each
    of which the User Agent will attempt to satisfy individually. Depending
    upon the resolutions available for this camera, it is possible that not all
    three constraints can be satisfied at the same time. If so, the User Agent
    will satisfy two if it can, or only one if not even two constraints can be
    satisfied together. Note that if not all three can be satisfied
    simultaneously, it is possible that there is more than one combination of
    two constraints that could be satisfied. If so, the user agent will
    choose.</p>
    <pre class="example highlight">
var supports = navigator.mediaDevices.getSupportedConstraints();
if(!supports["aspectRatio"]) {
  // Treat like an error.
}
 var constraints =
  {
    width: 1280,
    height: 720,
    aspectRatio: 1.5
  };
</pre>

    <p>This next example adds a small bit of complexity. The ideal values are
    still given for width and height, but this time with minimum requirements
    on each as well that must be satisfied. If it cannot satisfy either the
    width or height minimum it will reject the promise. Otherwise, it will try
    to satisfy the width, height, and aspectRatio target values as well and
    then resolve the promise.</p>
    <pre class="example highlight">
var supports = navigator.mediaDevices.getSupportedConstraints();
if(!supports["aspectRatio"]) {
  // Treat like an error.
}
 var constraints =
  {
    width: {min: 640, ideal: 1280},
    height: {min: 480, ideal: 720},
    aspectRatio: 1.5
  };
</pre>

    <p>This example illustrates the full control possible with the Constraints
    structure by adding the 'advanced' property. In this case, the User Agent
    behaves the same way with respect to the required constraints, but before
    attempting to satisfy the ideal values it will process the 'advanced' list.
    In this example the 'advanced' list contains two ConstraintSets. The first
    specifies width and height constraints, and the second specifies an
    aspectRatio constraint. Note that in the advanced list, these bare values
    are treated as 'exact' values. This example represents the following: "I
    need my video to be at least 640 pixels wide and at least 480 pixels high.
    My preference is for precisely 1920x1280, but if you can't give me that,
    give me an aspectRatio of 4x3 if at all possible. If even that is not
    possible, give me a resolution as close to 1280x720 as possible."</p>
    <pre class="example highlight">
var supports = navigator.mediaDevices.getSupportedConstraints();
if(!supports["width"] || !supports["height"]) {
  // Treat like an error.
}
 var constraints =
  {
    width: {min: 640, ideal: 1280},
    height: {min: 480, ideal: 720},
    advanced: [{width: 1920, height: 1280},
               {aspectRatio: 1.3333333333}]
  };
</pre>

    <p>The ordering of advanced ConstraintSets is significant. In the preceding
    example it is impossible to satisfy both the 1920x1280 ConstraintSet and
    the 4x3 aspect ratio ConstraintSet at the same time. Since the 1920x1280
    occurs first in the list, the User Agent will attempt to satisfy it first.
    Application authors can therefore implement a backoff strategy by
    specifying multiple optional ConstraintSets for the same property. For
    example, an application might specify three optional ConstraintSets, the
    first asking for a framerate greater than 500, the second asking for a
    framerate greater than 400, and the third asking for one greater than 300.
    If the User Agent is capable of setting a framerate greater than 500, it
    will (and the subsequent two ConstraintSets will be trivially satisfied).
    However, if the User Agent cannot set the framerate above 500, it will skip
    that ConstraintSet and attempt to set the framerate above 400. If that
    fails, it will then try to set it above 300. If the User Agent cannot
    satisfy any of the three ConstraintSets, it will set the framerate to any
    value it can get. If the developer wanted to insist on 300 as a lower
    bound, he could provide that as a 'min' value in the basic ConstraintSet.
    In that case, the User Agent would fail altogether if it couldn't get a
    value over 300, but would choose a value over 500 if possible, then try for
    a value over 400.</p>

    <p>Note that, unlike basic constraints, the constraints within a
    ConstraintSet in the advanced list must be satisfied together or skipped
    together. Thus, {width: 1920, height: 1280} is a request for that specific
    resolution, not a request for that width or that height. One can think of
    the basic constraints as requesting an or (non-exclusive) of the individual
    constraints, while each advanced ConstraintSet is requesting an and of the
    individual constraints in the ConstraintSet. An application may inspect the
    full set of Constraints currently in effect via the
    <code>getConstraints()</code> accessor.</p>

    <p>The specific value that the User Agent chooses for a constrainable
    property is referred to as a Setting. For example, if the application
    applies a ConstraintSet specifying that the framerate must be at least 30
    frames per second, and no greater than 40, the Setting can be any
    intermediate value, e.g., 32, 35, or 37 frames per second. The application
    can query the current settings of the object's constrainable properties via
    the <code><a>getSettings()</a></code> accessor.</p>

    <section>
      <h2>Interface Definition</h2>

      <p>Due to the limitations of the interface definition language used in
      this specification, it is not possible for other interfaces to inherit or
      implement ConstrainablePattern. Therefore the WebIDL definitions given
      are only templates to be copied. Each interface that wishes to make use
      of the functionality defined here will have to provide its own copy of
      the WebIDL for the functions and interfaces given here. However it can
      refer to the semantics defined here, which will not change. See <a href=
      "#media-stream-track-interface-definition">MediaStreamTrack Interface
      Definition</a> for an example of this.</p>

      <dl class="idl" title=
      "[NoInterfaceObject] interface ConstrainablePattern">
        <dt>Capabilities getCapabilities()</dt>

        <dd>
          <p>The <dfn>getCapabilities()</dfn> method returns the dictionary of
          the names of the constrainable properties that the object
          supports.</p>

          <div class="note">
            <p>It is possible that the underlying hardware may not exactly map
            to the range defined in the registry entry. Where this is possible,
            the entry SHOULD define how to translate and scale the hardware's
            setting onto the values defined in the entry. For example, suppose
            that a registry entry defines a hypothetical fluxCapacitance
            property that ranges from -10 (min) to 10 (max), but there are
            common hardware devices that support only values of "off" "medium"
            and "full". The registry entry might specify that for such
            hardware, the user agent should map the range value of -10 to
            "off", 10 to "full", and 0 to "medium". It might also indicate that
            given a ConstraintSet imposing a strict value of 3, the User Agent
            should attempt to set the value of "medium" on the hardware, and
            and that <code><a>getSettings()</a></code> should return a
            fluxCapacitance of 0, since that is the value defined as
            corresponding to "medium".</p>
          </div>
        </dd>

        <dt>Constraints getConstraints()</dt>

        <dd>
          <p>The <dfn>getConstraints</dfn> method returns the Constraints that
          were the argument to the most recent successful call of
          <code>applyConstraints()</code>, maintaining the order in which they
          were specified. Note that some of the optional ConstraintSets
          returned may not be currently satisfied. To check which
          ConstraintSets are currently in effect, the application should use
          <code>getSettings</code>.</p>
        </dd>

        <dt>Settings getSettings()</dt>

        <dd>
          <p>The <dfn>getSettings()</dfn> method returns the current settings
          of all the constrainable properties of the object, whether they are
          platform defaults or have been set by
          <code>applyConstraints()</code>. Note that the actual setting of a
          property MUST be a single value.</p>
        </dd>

        <dt>Promise&lt;void&gt; applyConstraints()</dt>

        <dd>
          <dl class="parameters">
            <dt>Constraints constraints</dt>

            <dd>
              <p>A new constraint structure to apply to this object.</p>
            </dd>
          </dl>

          <p>The <dfn>applyConstraints()</dfn> algorithm for applying
          constraints is stated below. Here are some preliminary definitions
          that are used in the statement of the algorithm:</p>

          <p>We use the term <dfn>settings dictionary</dfn> for the set of
          values that might be applied as settings to the object.</p>

          <p>We define the <dfn>fitness distance</dfn> between a <a>settings
          dictionary</a> and a constraint set <var>CS</var> as the sum, for
          each constraint provided for a constraint name in <var>CS</var>, of
          the following values:</p>

          <ol>
            <li>
              <p>If the constraint is not supported by the browser, the fitness
              distance is 0.</p>
            </li>

            <li>
              <p>If the constraint is required ('min', 'max', or 'exact'), and
              the <a>settings dictionary</a>'s value for the constraint does
              not satisfy the constraint, the fitness distance is positive
              infinity.</p>
            </li>

            <li>If no ideal value is specified, the fitness distance is 0.</li>

            <li>For all positive numeric non-required constraints (such as
            height, width, frameRate, aspectRatio, sampleRate and sampleSize),
            the fitness distance is the result of the formula
              <pre>
(actual == ideal) ? 0 : |actual -
                  ideal|/max(|actual|,|ideal|)
</pre>
            </li>

            <li>For all string and enum non-required constraints (sourceId,
            groupId, facingMode, echoCancellation), the fitness distance is the
            result of the formula
              <pre>
(actual == ideal) ? 0 : 1
</pre>
            </li>
          </ol>

          <p>More definitions:</p>

          <ul>
            <li>We refer to each element of a ConstraintSet (other than the
            special term 'advanced') as a 'constraint' since it is intended to
            constrain the acceptable settings for the given property from the
            full list or range given in the corresponding Capability of the
            ConstrainablePattern object to a value that is within the range or
            list of values it specifies.</li>

            <li>We refer to the "effective Capability" C of an object O as the
            possibly proper subset of the possible values of C (as returned by
            getCapabilities) taking into consideration environmental
            limitations and/or restrictions placed by other constraints. For
            example given a ConstraintSet that constrains the aspectRatio,
            height, and width properties, the values assigned to any two of the
            properties limit the effective Capability of the third. The set of
            effective Capabilities may be platform dependent. For example, on a
            resource-limited device it may not be possible to set properties P1
            and P2 both to 'high', while on another less limited device, this
            may be possible.</li>

            <li>A settings dictionary, which is a set of values for the
            constrainable properties of an object O, satisfies ConstraintSet CS
            if the fitness distance between the set and CS is less than
            infinity.</li>

            <li>A set of ConstraintSets CS1...CSn (n &gt;= 1) can be satisfied
            by an object O if it is possible to find a settings dictionary of O
            that satisfies CS1...CSn simultaneously.</li>

            <li>To apply a set of ConstraintSets CS1...CSn to object O is to
            choose such a sequence of values that satisfy CS1...CSn and assign
            them as the settings for the properties of O.</li>
          </ul>

          <p>We define the <dfn>SelectSettings</dfn> algorithm as follows:</p>

          <ol>
            <li>Each <a title="constraints">constraint</a> specifies one or
            more values (or a range of values) for its property. A property MAY
            appear more than once in the list of 'advanced' ConstraintSets. If
            an empty object or list has been given as the value for a
            constraint, it MUST be interpreted as if the constraint were not
            specified (in other words, an empty constraint == no constraint).
              <p>

              <p>Note that unknown properties are discarded by WebIDL, which
              means that unknown/unsupported required constraints will silently
              disappear. To avoid this being a surprise, application authors
              are expected to first use the
              <code>getSupportedConstraints()</code> method as shown in the
              Examples below.</p>
            </li>

            <li>Let <var>object</var> be the
            <code><a>ConstrainablePattern</a></code> object on which this
            algorithm is applied. Let <var>copy</var> be an unconstrained copy
            of <var>object</var> (i.e., <var>copy</var> should behave as if it
            were <var>object</var> with all ConstraintSets removed.)</li>

            <li>
              <p>For every possible <a>settings dictionary</a> of
              <var>copy</var> compute its <a>fitness distance, treating bare
              values of properties as ideal values</a>. Let
              <var>candidates</var> be the set of <a title=
              "settings dictionary">settings dictionaries</a> for which the
              <a>fitness distance</a> is finite.</p>
            </li>

            <li>
              <p>If <var>candidates</var> is empty, return
              <code>undefined</code> as the result of the function.</p>
            </li>

            <li>Iterate over the 'advanced' ConstraintSets in
            <var>newConstraints</var> in the order in which they were
            specified. For each ConstraintSet:

              <ol>
                <li>
                  <p>compute the fitness distance between it and each settings
                  dictionary in <var>candidates</var>, treating bare values of
                  properties as exact.</p>
                </li>

                <li>
                  <p>If the fitness distance is finite for one or more settings
                  dictionaries in <var>candidates</var>, keep those settings
                  dictionaries in <var>candidates</var>, discarding others.</p>

                  <p>If the fitness distance is infinite for all settings
                  dictionaries in <var>candidates</var>, ignore this
                  ConstraintSet.</p>
                </li>
              </ol>
            </li>

            <li>
              <p>Select one settings dictionary from the list of possible
              settings, and return this as the result of the
              <code>SelectSettings()</code> algorithm. The UA SHOULD use the
              one with the smallest <code>fitness distance</code>, as
              calculated in step 3.</p>
            </li>
          </ol>

          <p>When <code>applyConstraints</code> is called, the User Agent MUST
          run the following steps:</p>

          <ol>
            <li>
              <p>Let <var>p</var> be a new promise.</p>
            </li>

            <li>
              <p>Let <var>newContraints</var> be the argument to this
              function.</p>
            </li>

            <li>
              <p>Run the following steps asynchronously:</p>

              <ol>
                <li>
                  <p>Let <var>successfulSettings</var> be the result of running
                  the <a>SelectSettings</a> algorithm with
                  <var>newConstraints</var> as the constraint set.</p>
                </li>

                <li>
                  <p>If <var>successfulSettings</var> is
                  <code>undefined</code>, reject <var>p</var> with a new
                  <code>MediaStreamError</code> with name
                  <code>ConstraintNotSatisfied</code> and
                  <code>constraintName</code> set to any of the required
                  constraints that could not be satisfied, and abort these
                  steps. <var>existingConstraints</var> remain in effect in
                  this case.</p>
                </li>

                <li>In a single operation, remove
                <var>existingConstraints</var> from <var>object</var>, apply
                <var>newConstraints</var>, and apply
                <var>successfulSettings</var> as the current settings.</li>

                <li>Finally, resolve <var>p</var>. From this point on until
                applyConstraints() is called successfully again,
                getConstraints() <em class="rfc2119" title="must">must</em>
                return the <var>newConstraints</var> that were passed as an
                argument to this call.
                  <p>
                </li>
              </ol>
            </li>

            <li>
              <p>Return <var>p</var>.</p>
            </li>
          </ol>

          <div class="note">
            <p>Any implementation that has the same result as the algorithm
            above is an allowed implementation. For instance, the
            implementation may choose to keep track of the maximum and minimum
            values for a setting that are OK under the constraints considered,
            rather than keeping track of all possible values for the
            setting.</p>
          </div>

          <div class="note">
            <p>When picking a settings dictionary, the UA can use any
            information available to it. Examples of such information may be
            whether the selection is done as part of device selection in
            getUserMedia, whether the energy usage of the camera varies between
            the settings dictionaries, or whether using a settings dictionary
            will cause the device driver to apply resampling.</p>
          </div>

          <p>The User Agent MAY choose new settings for the constrainable
          properties of the object at any time. When it does so it MUST attempt
          to satisfy the current Constraints, in the manner described in the
          algorithm above.</p>
        </dd>

        <dt>attribute EventHandler onoverconstrained</dt>

        <dd>
          This event handler, of type <code><a>overconstrained</a></code>, is
          executed when the User Agent is no longer able to satisfy the
          <var>requiredConstraints</var> from the currently valid Constraints.
          <p>

          <p>When executed, the event handler is passed a
          <code>MediaStreamErrorEvent</code> as parameter, which references a
          <code>MediaStreamError</code> whose <code>name</code> is
          <code>OverconstrainedError</code>, and whose
          <code>constraintName</code> attribute is set to one of the
          <var>requiredConstraints</var> that can no longer be satisfied. The
          <code>message</code> attribute of the MediaStreamError SHOULD contain
          a string that is useful for debugging. The conditions under which
          this error might occur are platform and application-specific. For
          example, the user might physically manipulate a camera in a way that
          makes it impossible to provide a resolution that satisfies the
          constraints. The User Agent MAY take other actions as a result of the
          overconstrained situation.</p>
          <p>
        </dd>
      </dl>

      <p>An example of Constraints that could be passed into
      <code><a>applyConstraints()</a></code> or returned as a value of
      <code><a>constraints</a></code> is below. It uses the properties defined
      in <a href="#sec-track-properties">the Track property registry</a>.</p>
      <pre class="example highlight">
var supports = navigator.mediaDevices.getSupportedConstraints();
if(!supports["facingMode"]) {
  // Treat like an error.
}
var constraints = {
  width: {
    min: 640
  },
  height: {
    min: 480
  },
  advanced: [{
      width: 650
    }, {
      width: {
        min: 650
      }
    }, {
      frameRate: 60
    }, {
      width: {
        max: 800
      }
    }, {
      facingMode: "user"
    }]
};
</pre>

      <p>Here is another example, specifically for a video track where I must
      have a particular camera and have separate preferences for the width and
      height:</p>
      <pre class="example highlight">
var supports = navigator.mediaDevices.getSupportedConstraints();
if(!supports["deviceId"]) {
  // Treat like an error.
}
var constraints = {
  deviceId: {exact: "20983-20o198-109283-098-09812"},
  advanced: [{
      width: {
        min: 800,
        max: 1200
      }
    }, {
      height: {
        min: 600
      }
    }]
};
</pre>

      <p>And here's one for an audio track:</p>
      <pre class="example highlight">
var supports = navigator.mediaDevices.getSupportedConstraints();
if(!supports["deviceId"] || !supports["volume"]) {
  // Treat like an error.
}
var constraints = {
  advanced: [{
      deviceId: "64815-wi3c89-1839dk-x82-392aa"
    }, {
      volume: 0.5
    }]
};
</pre>

      <p>Here's an example of use of ideal:</p>
      <pre class="example highlight">
var supports = navigator.mediaDevices.getSupportedConstraints();
if(!supports["aspectRatio"] || !supports["facingMode"]) {
  // Treat like an error.
}
var gotten = navigator.mediaDevices.getUserMedia({
  video: {
    width: {min: 320, ideal: 1280, max: 1920},
    height: {min: 240, ideal: 720, max: 1080},
    framerate: 30,     // Shorthand for ideal.
    // facingMode: "environment" would be optional.
    facingMode: {exact: "environment"}
  }});
</pre>

      <p>Here's an example of "I want 720p, but I can accept up to 1080p and
      down to VGA.":</p>
      <pre class="example highlight">
var supports = navigator.mediaDevices.getSupportedConstraints();
if(!supports["width"] || !supports["height"]) {
  // Treat like an error.
}
var gotten = navigator.mediaDevices.getUserMedia({video: {
  width: {min: 640, ideal: 1280, max: 1920},
  height: {min: 480, ideal: 720, max: 1080},
}});
</pre>

      <p>Here's an example of "I want a front-facing camera and it must be
      VGA.":</p>
      <pre class="example highlight">
var supports = navigator.mediaDevices.getSupportedConstraints();
if(!supports["width"] || !supports["height"] || !supports["facingMode"]) {
  // Treat like an error.
}
var gotten = navigator.mediaDevices.getUserMedia({video: {
  facingMode: {exact: "user"},
  width: {exact: 640},
  height: {exact: 480}
}});
</pre>
    </section>

    <section id="registry">
      <h2>The Property Registry</h2>

      <p>There is a single <a href="#sec-iana">IANA registry</a> that defines
      the constrainable properties of all objects that implement the
      Constrainable pattern. The registry entries MUST contain the name of each
      property along with its set of legal values. The registry entries for
      MediaStreamTrack are defined <a href="#sec-track-properties">below</a>.
      The syntax for the specification of the set of legal values depends on
      the type of the values. In addition to the standard atomic types
      (boolean, long, double, DOMString), legal values include lists of any of
      the atomic types, plus min-max ranges, as defined below.</p>

      <p>List values MUST be interpreted as disjunctions. For example, if a
      property 'facingMode' for a camera is defined as having legal values
      ["left", "right", "user", "environment"], this means that 'facingMode'
      can have the values "left", "right", "environment", and "user". Similarly
      <a>Constraints</a> restricting 'facingMode' to ["user", "left", "right"]
      would mean that the User Agent should select a camera (or point the
      camera, if that is possible) so that "facingMode" is either "user",
      "left", or "right". This Constraint would thus request that the camera
      not be facing away from the user, but would allow the User Agent to allow
      the user to choose other directions.</p>

      <dl class="idl" title="dictionary DoubleRange">
        <dt>double max</dt>

        <dd>
          <p>The maximum legal value of this property.</p>
        </dd>

        <dt>double min</dt>

        <dd>
          <p>The minimum value of this Property.</p>
        </dd>
      </dl>

      <dl class="idl" title="dictionary ConstrainDoubleRange : DoubleRange">
        <dt>double exact</dt>

        <dd>
          <p>The exact required value for this property.</p>
        </dd>

        <dt>double ideal</dt>

        <dd>
          <p>The ideal (target) value for this property.</p>
        </dd>
      </dl>

      <dl class="idl" title="dictionary LongRange">
        <dt>long max</dt>

        <dd>
          <p>The maximum legal value of this property.</p>
        </dd>

        <dt>long min</dt>

        <dd>
          <p>The minimum value of this property.</p>
        </dd>
      </dl>

      <dl class="idl" title="dictionary ConstrainLongRange : LongRange">
        <dt>long exact</dt>

        <dd>
          <p>The exact required value for this property.</p>
        </dd>

        <dt>long ideal</dt>

        <dd>
          <p>The ideal (target) value for this property.</p>
        </dd>
      </dl>

      <dl class="idl" title="dictionary ConstrainBooleanParameters">
        <dt>boolean exact</dt>

        <dd>
          <p>The exact required value for this property.</p>
        </dd>

        <dt>boolean ideal</dt>

        <dd>
          <p>The ideal (target) value for this property.</p>
        </dd>
      </dl>

      <dl class="idl" title="dictionary ConstrainDOMStringParameters">
        <dt>(DOMString or sequence&lt;DOMString&gt;) exact</dt>

        <dd>
          <p>The exact required value for this property.</p>
        </dd>

        <dt>(DOMString or sequence&lt;DOMString&gt;) ideal</dt>

        <dd>
          <p>The ideal (target) value for this property.</p>
        </dd>
      </dl>
      <dl class="idl" title=
      "typedef (long or ConstrainLongRange) ConstrainLong">
      <dl class="idl" title=
      "typedef (double or ConstrainDoubleRange) ConstrainDouble">
      <dl class="idl" title=
      "typedef (boolean or ConstrainBooleanParameters) ConstrainBoolean">
      <dl class="idl" title=
      "typedef (DOMString or sequence&lt;DOMString&gt; or ConstrainDOMStringParameters) ConstrainDOMString">
    </section>

    <section id="capabilities">
      <h3>Capabilities</h3>

      <p><dfn>Capabilities</dfn> is a dictionary containing one or more
      key-value pairs, where each key MUST be a constrainable property defined
      in the registry, and each value MUST be a subset of the set of values
      defined for that property in the registry. The exact syntax of the value
      expression depends on the type of the property, and its type is as
      defined in the Values column of the registry. The Capabilities dictionary
      specifies the subset of the constrainable properties and values from the
      registry that the User Agent supports. Note that a User Agent MAY support
      only a subset of the properties that are defined in the registry, and MAY
      support a subset of the set values for those properties that it does
      support. Note that Capabilities are returned from the User Agent to the
      application, and cannot be specified by the application. However, the
      application can control the Settings that the User Agent chooses for
      constrainable properties by means of Constraints.</p>

      <p>An example of a Capabilities dictionary is shown below. This example
      is not very realistic in that a browser would actually be required to
      support more constrainable properties than just these.</p>
      <pre class="example highlight">
{
  frameRate: {
    min: 1.0,
    max: 60.0
  },
  facingMode: ["user", "environment"]
}
</pre>

      <p>The next example below points out that capabilities for range values
      provide ranges for individual constrainable properties, not combinations.
      This is particularly relevant for video width and height, since the
      ranges for width and height are reported separately. In the example, if
      the User Agent can only provide 640x480 and 800x600 resolutions the
      relevant capabilities returned would be:</p>
      <pre class="example highlight">
{
  width: {
    min: 640,
    max: 800
  },
  height: {
    min: 480,
    max: 600
  },
  aspectRatio: {
    min: 1.3333333333,
    max: 1.3333333333
  }
}
</pre>

      <p>Note in the example above that the aspectRatio would make clear that
      arbitrary combination of widths and heights are not possible, although it
      would still suggest that more than two resolutions were available.</p>
    </section>

    <section>
      <h3>Settings</h3>

      <p><dfn>Settings</dfn> is a dictionary containing one or more key-value
      pairs. It MUST contain each key returned in
      <code>getCapabilities()</code>. There MUST be a single value for each key
      and the value MUST be a member of the set defined for that property by
      <code>getCapabilities()</code>. The <code>Settings</code> dictionary
      contains the actual values that the User Agent has chosen for the
      object's constrainable properties. The exact syntax of the value depends
      on the type of the property.</p>

      <p>A conforming User Agent MUST support all the constrainable properties
      defined in this specification.</p>

      <p>An example of a Settings dictionary is shown below. This example is
      not very realistic in that a browser would actually be required to
      support more constrainable properties than just these.</p>
      <pre class="example highlight">
{
  frameRate: 30.0,
  facingMode: "user"
}
</pre>
    </section>

    <section id="constraints">
      <h3><dfn>Constraints and ConstraintSet</dfn></h3>

      <p>Due to the limitations of WebIDL, interfaces implementing the
      Constrainable Pattern cannot simply subclass Constraints and
      ConstraintSet as they are defined here. Instead they must provide their
      own definitions that follow this pattern. See <a href=
      "#media-track-constraints">MediaTrackConstraints</a> for an example of
      this.</p>

      <dl class="idl" title="dictionary ConstraintSet"></dl>

      <p>Each member of a ConstraintSet corresponds to a constrainable property
      and specifies a subset of the property's legal Capability values.
      Applying a ConstraintSet instructs the User Agent to restrict the
      settings of the corresponding constrainable properties to the specified
      values or ranges of values. A given property MAY occur both in the basic
      Constraints set and in the advanced ConstraintSets list, and MAY occur at
      most once in each ConstraintSet in the advanced list.</p>

      <dl class="idl" title="dictionary Constraints : ConstraintSet">
        <dt>sequence&lt;ConstraintSet&gt; advanced</dt>

        <dd>
          <p>The list of ConstraintSets that the User Agent MUST attempt to
          satisfy, in order, skipping only those that cannot be satisfied. The
          order of these ConstraintSets is significant. In particular, when
          they are passed as an argument to <code>applyConstraints</code>, the
          User Agent MUST try to satisfy them in the order that is specified.
          Thus if optional ConstraintSets C1 and C2 can be satisfied
          individually, but not together, then whichever of C1 and C2 is first
          in this list will be satisfied, and the other will not. The User
          Agent MUST attempt to satisfy all optional ConstraintSets in the
          list, even if some cannot be satisfied. Thus, in the preceding
          example, if optional constraint C3 is specified after C1 and C2, the
          User Agent will attempt to satisfy C3 even though C2 cannot be
          satisfied. Note that a given property name may occur only once in
          each ConstraintSet but may occur in more than one ConstraintSet.</p>
        </dd>
      </dl>
    </section>
  </section>

  <section>
    <h2>Examples</h2>

    <div>
      <p>This sample code exposes a button. When clicked, the button is
      disabled and the user is prompted to offer a stream. The user can cause
      the button to be re-enabled by providing a stream (e.g., giving the page
      access to the local camera) and then disabling the stream (e.g., revoking
      that access).</p>
      <pre class="example highlight">
&lt;input type="button" value="Start" onclick="start()" id="startBtn"&gt;
&lt;script&gt;
 var startBtn = document.getElementById('startBtn');

 function start() {
     navigator.mediaDevices.getUserMedia({
         audio: true,
         video: true
     }).then(gotStream).catch(logError);
     startBtn.disabled = true;
 }

 function gotStream(stream) {
     stream.oninactive = function () {
         startBtn.disabled = false;
     };
 }

 function logError(error) {
     log(error.name + ": " + error.message);
 }
&lt;/script&gt;
</pre>
    </div><!-- Put back when we define MediaStreamRecorder
    <div>

      <p>This example allows people to record a short audio message and upload
      it to the server. This example even shows rudimentary error handling.</p>

      <pre class="example highlight">
&lt;input type="button" value="Start" onclick="msgRecord()" id="recBtn"&gt;
&lt;input type="button" value="Stop" onclick="msgStop()" id="stopBtn" disabled&gt;
&lt;p id="status"&gt;To start recording, press the Start button.&lt;/p&gt;
&lt;script&gt;
 var recBtn = document.getElementById('recBtn');
 var stopBtn = document.getElementById('stopBtn');

 function report(s) {
     document.getElementById('status').textContent = s;
 }

 function msgRecord() {
     report('Attempting to access microphone...');
     navigator.getUserMedia({
         audio: true
     }, gotStream, noStream);
     recBtn.disabled = true;
 }
 var msgStream, msgStreamRecorder;

 function gotStream(stream) {
     report('Recording... To stop, press the Stop button.');
     msgStream = stream;
     msgStreamRecorder = stream.record();
     stopBtn.disabled = false;
     stream.oninactive = function () {
         msgStop();
     }
 }

 function msgStop() {
     report('Creating file...');
     stopBtn.disabled = true;
     msgStream.oninactive = null;
     msgStream.stop();
     msgStreamRecorder.getRecordedData(msgSave);
 }

 function msgSave(blob) {
     report('Uploading file...');
     var x = new XMLHttpRequest();
     x.open('POST', 'uploadMessage');
     x.send(blob);
     x.onload = function () {
         report('Done! To record a new message, press the Start button.');
         recBtn.disabled = false;
     };
     x.onerror = function () {
         report('Failed to upload message. To try recording a message again, press the Start button.');
         recBtn.disabled = false;
     };
 }

 function noStream() {
     report('Could not obtain access to your microphone. To try again, press the Start button.');
     recBtn.disabled = false;
 }
&lt;/script&gt;
</pre>
    </div>-->

    <div>
      <p>This example allows people to take photos of themselves from the local
      video camera. Note that the Image Capture specification [[image-capture]]
      provides a simpler way to accomplish this.</p>
      <pre class="example highlight">
&lt;article&gt;
 &lt;style scoped&gt;
  video { transform: scaleX(-1); }
  p { text-align: center; }
 &lt;/style&gt;
 &lt;h1&gt;Snapshot Kiosk&lt;/h1&gt;
 &lt;section id="splash"&gt;
  &lt;p id="errorMessage"&gt;Loading...&lt;/p&gt;
 &lt;/section&gt;
 &lt;section id="app" hidden&gt;
  &lt;p&gt;&lt;video id="monitor" autoplay&gt;&lt;/video&gt; &lt;canvas id="photo"&gt;&lt;/canvas&gt;
  &lt;p&gt;&lt;input type=button value="&amp;#x1F4F7;" onclick="snapshot()"&gt;
 &lt;/section&gt;
 &lt;script&gt;
 var video = document.getElementById('monitor');
 var canvas = document.getElementById('photo');

 navigator.mediaDevices.getUserMedia({
     video: true
 }).then(function (stream) {
     video.srcObject = stream;
     stream.oninactive = noStream;
     video.onloadedmetadata = function () {
         canvas.width = video.videoWidth;
         canvas.height = video.videoHeight;
         document.getElementById('splash').hidden = true;
         document.getElementById('app').hidden = false;
     };
 }).catch(function (reason) {
     document.getElementById('errorMessage').textContent = 'No camera available.';
 });

 function snapshot() {
     canvas.getContext('2d').drawImage(video, 0, 0);
 }
 &lt;/script&gt;
&lt;/article&gt;
</pre>
    </div>
  </section>

  <section>
    <h1>Privacy and Security Considerations</h1>

    <p>This section is non-normative; it specifies no new behavior, but instead
    summarizes information already present in other parts of the
    specification.</p>

    <p>This document extends the Web platform with the ability to manage input
    devices for media - in this iteration, microphones, and cameras. It also
    allows the manipulation of audio output devices (speakers and
    headphones).</p>

    <p>Without authorization (to the "drive-by web"), it offers the ability to
    tell how many devices there are of each class. The identifiers for the
    devices are designed to not be useful for a fingerprint that can track the
    user between origins, but the number of devices adds to the fingerprint
    surface. It recommends to treat the per-origin persistent identifier
    <code>deviceId</code> as other persistent storages (e.g. cookies) are
    treated.</p>

    <p>When authorization is given, this document describes how to get access
    to, and use, media data from the devices mentioned. This data may be
    sensitive; advice is given that indicators should be supplied to indicate
    that devices are in use, but both the nature of authorization and the
    indicators of in-use devices are platform decisions.</p>

    <p>Authorization may be given on a case-by-case basis, or be persistent. In
    the case of a case-by-case authorization, it is important that the user be
    able to say "no" in a way that prevents the UI from blocking user
    interaction until permission is given - either by offering a way to say a
    "persistent NO" or by not using a modal permissions dialog.</p>

    <p>It is possible to use constraints so that the failure of a getUserMedia
    call will return information about devices on the system without prompting
    the user, which increases the surface available for fingerprinting. The
    User Agent should consider limiting the rate at which failed getUserMedia
    calls are allowed in order to limit this additional surface.</p>

    <p>In the case of persistent authorization, it is important that it is easy
    to find the list of granted permissions and revoke permissions that the
    user wishes to revoke.</p>

    <p>Once permission has been granted, the User Agent should make two things
    readily apparent to the user:</p>

    <ul>
      <li>That the page has access to the devices for which permission is
      given</li>

      <li>Whether or not any of the devices are presently recording ("on air")
      indicator</li>
    </ul>
    <p>

    <div class="note">
      <p>Developers of sites with persistent permissions should be careful that
      these permissions not be abused.</p>

      <p>In particular, they should not make it possible to automatically send
      audio or video streams from authorized media devices to an end point that
      a third party can select.</p>

      <p>Indeed, if a site offered URLs such as
      <code>https://webrtc.example.org/?call=<var>user</var></code> that would
      automatically set up calls and transmit audio/video to
      <code><var>user</var></code>, it would be open for instance to the
      following abuse:</p>

      <p>Users who have granted permanent permissions to
      <code>https://webrtc.example.org/</code> could be tricked to send their
      audio/video streams to an attacker <code>EvilSpy</code> by following a
      link or being redirected to
      <code>https://webrtc.example.org/?user=EvilSpy</code>.</p>
    </div>
  </section>

  <section>
    <h1 id="sec-iana">IANA Registrations</h1>

    <section>
      <h2 id="sec-track-properties">Track Constrainable Property
      Registrations</h2>

      <p>IANA is requested to register the following constrainable properties
      as specified in [[!RTCWEB-CONSTRAINTS]]:</p>

      <p>The following constrainable properties are defined to apply to both
      video and audio <code><a>MediaStreamTrack</a></code> objects:</p>

      <table class="simple">
        <thead>
          <tr>
            <th>Property Name</th>

            <th>Values</th>

            <th>Notes</th>
          </tr>
        </thead>

        <tbody>
          <tr id="def-constraint-sourceType">
            <td><dfn>sourceType</dfn></td>

            <td><code><a>SourceTypeEnum</a></code></td>

            <td>The type of the source of the <a>MediaStreamTrack</a>. Note
            that the setting of this property is uniquely determined by the
            source that is attached to the Track. In particular,
            <a>getCapabilities()</a> will return only a single value for
            sourceType. This property can therefore be used for initial media
            selection with <a>getUserMedia()</a>. However, it is not useful for
            subsequent media control with <a>applyConstraints()</a>, since any
            attempt to set a different value will result in an unsatisfiable
            <a>ConstraintSet</a>.</td>
          </tr>

          <tr id="def-constraint-deviceId">
            <td><dfn>deviceId</dfn></td>

            <td>DOMString</td>

            <td>The application-unique identifier for the source of the
            <a>MediaStreamTrack</a>. The same identifier MUST be valid between
            sessions of this application, but MUST also be different for other
            applications. Some sort of GUID is recommended for the identifier.
            Note that the setting of this property is uniquely determined by
            the source that is attached to the Track. In particular,
            <a>getCapabilities()</a> will return only a single value for
            deviceId. This property can therefore be used for initial media
            selection with <a>getUserMedia()</a>. However, it is not useful for
            subsequent media control with <a>applyConstraints()</a>, since any
            attempt to set a different value will result in an unsatisfiable
            <a>ConstraintSet</a>.</td>
          </tr>

          <tr id="def-constraint-groupId">
            <td><dfn>groupId</dfn></td>

            <td>DOMString</td>

            <td>The group identifier for the source of the
            <a>MediaStreamTrack</a>. Two devices have the same group identifier
            if they belong to the same physical device; for example, the audio
            input and output devices representing the speaker and microphone of
            the same headset would have the same groupId.</td>
          </tr>
        </tbody>
      </table>

      <p>The following constrainable properties are defined to apply only to
      video <code><a>MediaStreamTrack</a></code> objects:</p>

      <table class="simple">
        <thead>
          <tr>
            <th>Property Name</th>

            <th>Values</th>

            <th>Notes</th>
          </tr>
        </thead>

        <tbody>
          <tr id="def-constraint-width">
            <td><dfn>width</dfn></td>

            <td><code><a>ConstrainLong</a></code></td>

            <td>The width or width range, in pixels. As a capability, the range
            should span the video source's pre-set width values with min being
            the smallest width and max being the largest width.</td>
          </tr>

          <tr id="def-constraint-height">
            <td><dfn>height</dfn></td>

            <td><code><a>ConstrainLong</a></code></td>

            <td>The height or height range, in pixels. As a capability, the
            range should span the video source's pre-set height values with min
            being the smallest height and max being the largest height.</td>
          </tr>

          <tr id="def-constraint-frameRate">
            <td><dfn>frameRate</dfn></td>

            <td><code><a>ConstrainDouble</a></code></td>

            <td>The exact frame rate (frames per second) or frame rate range.
            If this frame rate cannot be determined (e.g. the source does not
            natively provide a frame rate, or the frame rate cannot be
            determined from the source stream), then this value MUST refer to
            the User Agent's vsync display rate.</td>
          </tr>

          <tr id="def-constraint-aspect">
            <td><dfn>aspectRatio</dfn></td>

            <td><code><a>ConstrainDouble</a></code></td>

            <td>The exact aspect ratio (width in pixels divided by height in
            pixels, represented as a double rounded to the tenth decimal place)
            or aspect ratio range.</td>
          </tr>

          <tr id="def-constraint-facingMode">
            <td><dfn>facingMode</dfn></td>

            <td><code><a>ConstrainDOMString</a></code></td>

            <td>This string (or each string, when a list) should be one of the
            members of <code><a>VideoFacingModeEnum</a></code>. The members
            describe the directions that the camera can face, as seen from the
            user's perspective. Note that <code><a>getConstraints</a></code>
            may not return exactly the same string for strings not in this
            enum. This preserves the possibility of using a future version of
            WebIDL enum for this property.</td>
          </tr>
        </tbody>
      </table>

      <dl class="idl" title="enum VideoFacingModeEnum">
        <dt>user</dt>

        <dd>
          <p>The source is facing toward the user (a self-view camera).</p>
        </dd>

        <dt>environment</dt>

        <dd>
          <p>The source is facing away from the user (viewing the
          environment).</p>
        </dd>

        <dt>left</dt>

        <dd>
          <p>The source is facing to the left of the user.</p>
        </dd>

        <dt>right</dt>

        <dd>
          <p>The source is facing to the right of the user.</p>
        </dd>
      </dl>

      <p>Below is an illustration of the video facing modes in relation to the
      user.<br>
      <img alt="Illustration of video facing modes in relation to user" src=
      "images/camera-names-exp.svg" style="width:40%"></p>

      <p>The following constrainable properties are defined to apply only to
      audio <code><a>MediaStreamTrack</a></code> objects:</p>

      <table class="simple">
        <thead>
          <tr>
            <th>Property Name</th>

            <th>Values</th>

            <th>Notes</th>
          </tr>
        </thead>

        <tbody>
          <tr id="def-constraint-volume">
            <td>volume</td>

            <td><code><a>ConstrainDouble</a></code></td>

            <td>The volume or volume range, as a multiplier of the linear audio
            sample values. A volume of 0.0 is silence, while a volume of 1.0 is
            the maximum supported volume. A volume of 0.5 will result in an
            approximately 6 dB<sub>SPL</sub> change in the sound pressure level
            from the maximum volume. Note that any ConstraintSet that specifies
            values outside of this range of 0 to 1 can never be satisfied.</td>
          </tr>

          <tr id="def-constraint-sampleRate">
            <td>sampleRate</td>

            <td><code><a>ConstrainLong</a></code></td>

            <td>The sample rate in samples per second for the audio data.</td>
          </tr>

          <tr id="def-constraint-sampleSize">
            <td>sampleSize</td>

            <td><code><a>ConstrainLong</a></code></td>

            <td>The linear sample size in bits. This constraint can only be
            satisfied for audio devices that produce linear samples.</td>
          </tr>

          <tr id="def-constraint-echoCancellation">
            <td>echoCancellation</td>

            <td><code>boolean</code></td>

            <td>When one or more audio streams is being played in the processes
            of various microphones, it is often desirable to attempt to remove
            the sound being played from the input signals recorded by the
            microphones. This is referred to as echo cancellation. There are
            cases where it is not needed and it is desirable to turn it off so
            that no audio artifacts are introduced. This allows applications to
            control this behavior.</td>
          </tr>
        </tbody>
      </table>
    </section>
  </section>

  <section>
    <h2>Change Log</h2>

    <p>This section will be removed before publication.</p>

    <h2>Changes since February 2, 2015</h2>

    <ol>
      <li>Added getUserMedia() implementation suggestion as discussed in issue
      #67</li>

      <li>Issue 139: Clarified in SelectSettings algorithm that an empty
      constraint is to be treated as no constraint.</li>

      <li>Issue 128: Clarified in SelectSettings that bare values mean exact in
      the advanced array and ideal otherwise.</li>

      <li>[PR#37/Bug 26654] Webidl in Constrainable</li>

      <li>[Issue #141] MediaDeviceInfo.label and .groupId should not be
      nullable</li>

      <li>[PR #150] Update text for how constraint dictionaries get
      extended</li>
    </ol>

    <h2>Changes since October 27, 2014</h2>

    <ol>
      <li>Bug 26953: Added more detail to the definition of volume.</li>

      <li>Clarified in section 4.1 that synchronization is only an intention
      because some tracks cannot be synchronized.</li>

      <li>Introduced and made consistent use of the term 'constrainable
      property' everywhere we refer to a property which can have Capabilities,
      Constraints, and Settings.</li>

      <li>Changed constraint definition text using concepts and some direct
      text from PR 61.</li>
      <!-- put some random merge tag and put your change log entry after
        that. This reduces the odds of merge conflicts when we merge the pull
        request -->
      <!-- merge tag A -->
      <!-- merge tag B -->

      <li>Bug 113 (old 25771): Explanation of constraints in GUM call. Rewrote
      algorithm with separate SelectSettings step, used both in GUM and in
      applyConstraints.</li><!-- merge tag C -->
      <!-- merge tag D -->
      <!-- merge tag E -->
      <!-- merge tag F -->
      <!-- merge tag G -->
      <!-- merge tag H -->
      <!-- merge tag I -->
      <!-- merge tag J -->
      <!-- merge tag H -->
      <!-- merge tag K -->
      <!-- merge tag L -->
      <!-- merge tag M -->
      <!-- merge tag N -->
      <!-- merge tag O -->
      <!-- merge tag P -->
      <!-- merge tag R -->
      <!-- merge tag S -->
      <!-- merge tag T -->
      <!-- merge tag Q -->
      <!-- merge tag U -->
      <!-- merge tag V -->
      <!-- merge tag W -->
    </ol>

    <h2>Changes since September 24, 2014</h2>

    <ol>
      <li>Bug 25809: Added note warning about abuse of call-me URLs.</li>

      <li>Bug 26918: Added note on clearing deviceId when clearing
      cookies.</li>

      <li>Bug 25777: Added example of capabilities when only two video sizes
      are available.</li>

      <li>Bug 26654: Added ConstrainBoolean.</li>

      <li>Bug 26810: All callback-based methods have been converted to use
      Promises, except for the version of getUserMedia() defined under
      NavigatorUserMedia.</li>
    </ol>

    <h2>Changes since September 9, 2014</h2>

    <ol>
      <li>Bug 22214: How long do permissions persist?</li>

      <li>Define algorithm for processing non-required constraints.</li>

      <li>Bug 24933: deviceId is not registered as constraints, so apps can't
      choose device based on the device enumeration</li>

      <li>Bug 25609: MediaStreamErrorEvent is incomplete</li>
    </ol>

    <h2>Changes since August 17, 2014</h2>

    <ol>
      <li>Bug 25988: Need a list of MediaStreamError "name" values</li>

      <li>Bug 26623: Use commonest spelling of "cancellation"</li>

      <li>Bug 25767: Missing Ref to Image Capture spec</li>

      <li>Bug 22271: Terminology section should not have conformance
      requirements</li>
    </ol>

    <h2>Changes since July 4, 2014</h2>

    <ol>
      <li>Bug 22251: Added new NotFoundError, AbortError, SourceUnavailable
      errors to gUM call.</li>

      <li>Bug 25786: User Agent allowance of files to be substituted for any
      input device is now permitted but not listed as best practice, i.e., no
      longer specifically recommended.</li>
    </ol>

    <h2>Changes since June 19, 2014</h2>

    <ol>
      <li>Bug 22354: Added privacy and security section.</li>

      <li>Bug 25784: "on air" indication is underspecified - separated "access
      granted" and "on air" indicators.</li>

      <li>Bug 26192: add onoverconstrained to MediaStreamTrack</li>

      <li>Bug 25776: add groupID to MediaTrackConstraintSet</li>

      <li>Bug 25780: Clarify step 3 of MediaStream.clone</li>

      <li>Bug 25804: Change 'remote' attribute definition</li>

      <li>Bug 25650: In getUserMedia algorithm if user denies permission spec
      is wrongly redirecting to Constraint Failure.</li>

      <li>Bug 25605: Definition of MediaStreamTrackEvent is not complete</li>

      <li>Bug 25651: All the links in spec should redirect to specified
      contents without failure.</li>

      <li>Bug 25725: getUserMedia constraints should be non-nullable</li>

      <li>Bug 25763: does the ID really have to be exactly 36 char long?</li>

      <li>Bug 24934: invalid definition for the "seekable" attribute when
      MediaStream is set to srcObject.</li>

      <li>Removed MediaStreamTrack new state (sourceType none removed as a
      consequence) (as discussed in bug 25787).</li>

      <li>Bug 25801: Remove getNativeSettings()</li>
    </ol>

    <h2>Changes since May 7, 2014</h2>

    <ol>
      <li>Clarified that skipping of optional/advanced ConstraintSets is only
      permitted if they cannot be satisfied, not merely because the User Agent
      wishes to.</li>

      <li>Bug 25855: Clarification about conformance requirements phrased as
      algorithms</li>

      <li>Bug 25803: Mark section entitled "The model: sources, sinks,
      constraints, and settings" as non-normative</li>

      <li>Bug 24015: Add callback to indicate when available media devices
      change (introduced Navigator.mediaDevices)</li>

      <li>Bug 25860: make sure we have a bug to have a getTracks that gives you
      all the tracks</li>

      <li>Bug 25884: applied constraint syntax consensus as realized in June 9
      WG email from Peter Thatcher.</li>

      <li>Moved getSupportedConstraints() method to MediaDevices object.</li>

      <li>Added stricter requirements on the getSupportedConstraints() return
      value.</li>

      <li>Added issue note in Constrainable Pattern section that ideal is not
      yet defined.</li>

      <li>Added issue note for applyConstraints that how multiple
      unorderedConstraints are to be satisfied together is not yet
      defined.</li>

      <li>Added informative notes that WebIDL discards unknown required
      properties and that application authors need to use the
      <code>getSupportedConstraints()</code> method.</li>

      <li>Cleaned up the MediaStream API intro section (mainly MediaStream
      behavior that have moved to MediaStreamTrack).</li>

      <li>The concept of MediaStreamTrack with a detachable source is now used
      throughout the spec (removed language saying that a MST could be
      disassociated from its track).</li>

      <li>Moved peerIdentity related text to WebRTC.</li>
    </ol>

    <h2>Changes since March 21, 2014</h2>

    <ol>
      <li>New webIDL for Constrainable and Constraints.</li>

      <li>Bug 24931: changed MediaError to MediaStreamError.</li>

      <li>Bug 23817: Redundant TOC headers 8.1 &amp; 9.1</li>

      <li>Bug 25230: readyState attribute must be inherited while cloning a
      MediaStreamTrack</li>

      <li>Bug 25249: Source should be detached when a MediaStreamTrack stops
      for any reason other than stop</li>

      <li>Updated Event Summary section to match the spec regarding
      MediaStreamTrack.stop() (as discussed in bug 25248)</li>

      <li>Made the MediaStream() constructor behave like addTrack() WRT adding
      ended tracks (as discussed in bug 25250).</li>

      <li>Bug 25262: MediaStream Constructor algorithm must also check for
      MediaStreamTracks "ended" state while initializing "active" state.</li>

      <li>Bug 25276: Initialization for VideoTrack.selected attribute is
      missing while specifying steps for "Loading and Playing a MediaStream in
      a Media Element"</li>

      <li>Changed syntax of constraints to use 'require' and 'advanced' and
      support non-required, non-advanced constraints.</li>

      <li>Bug 25360: MediaStreamTrack should not be considered as ended just
      because remote peer stopped sending data.</li>

      <li>Bug 25275: VideoTrackList.selectedIndex initialization conflicts with
      HTML5 spec, "if no track is selected".</li>

      <li>Removed mentioning of MediaStream received from other peer (as
      discussed in bug 25361).</li>

      <li>Bug 22263: Clarify synchronization of tracks in a MediaStream</li>

      <li>Bug 25441: Overconstrained muted state should not link with
      MediaStreamTrack.readyState</li>
    </ol>

    <h2>Changes since February 18, 2014</h2>

    <ol>
      <li>Bug 24928: Remove MediaStream state check from addTrack()
      algorithm.</li>

      <li>Bug 24930: Remove MediaStream state check from the removeTrack()
      algorithm.</li>

      <li>Added native settings to tracks.</li>

      <li>Removed videoMediaStreamTrack and audioMediaStreamTrack since they
      are no longer necessary.</li>
    </ol>

    <h2>Changes since December 25, 2013</h2>

    <ol>
      <li>Make optional constraints a list of ConstraintSets. Make
      ConstraintSet an object.</li>

      <li>Remove noaccess, move peerIdentity</li>

      <li>Add constraints for sampleRate, sampleSize, and
      echoCancellation.</li>

      <li>Aligned text in remainder of document with Constrainable
      changes.</li>

      <li>Removed statements that constraints are not applied to read-only
      sources</li>
    </ol>

    <h2>Changes since November 5, 2013</h2>

    <ol>
      <li>ACTION-25: Switch mediastream.inactive to mediastream.active.</li>

      <li>ACTION-26: Rewrite stop to only detach the track's source.</li>

      <li>Bug 22338: Arbitrary changing of tracks.</li>

      <li>Bug 23125: Use double rather than float.</li>

      <li>Bug 22712: VideoFacingMode enum needs an illustration.</li>

      <li>Moved constraints into a separate Constrainable interface.</li>

      <li>Created a separate section on error handling.</li>
    </ol>

    <h2>Changes since October 17, 2013</h2>

    <ol>
      <li>Bug 23263: Add output device enumeration to GetSources</li>

      <li>Introduced the Constrainable interface.</li>

      <li>Change consensus note on constraints in IANA section.</li>

      <li>Removed createObjectURL.</li>

      <li>Bug 22209: Should not use MUST requirements on values provided by the
      developer.</li>
    </ol>

    <h2>Changes since August 24, 2013</h2>

    <ol>
      <li>Bug 22269: Renamed getSourceInfos() to getSources() and made the
      result async.</li>

      <li>Bug 22229: Editorial input</li>

      <li>Bug 22243: Clarify readonly track</li>

      <li>Bug 22259: Disabled mediastreamtrack and state of media element</li>

      <li>Bug 22226: Remove check of same source from MediaStream constructor
      algorithm</li>

      <li>Replaced ended with inactive for MediaStream (resolves bug
      21618).</li>

      <li>Bug 22264: MediaStream.ended set to true on creation</li>

      <li>Bug 22272: Permission revocation via MediaStreamTrack.stop()</li>

      <li>Bug 22248: Relationship between MediaStreamTrack and HTML5
      VideoTrack/AudioTrack after MediaStream assignment</li>

      <li>Bug 22247: Setting loop attribute on a media element reading from a
      MediaStream</li>
    </ol>

    <h2>Changes since July 4, 2013</h2>

    <ol>
      <li>Bug 21967: Added paragraph on MediaStreamTrack enabled state and
      updated cloning algorithm.</li>

      <li>Bug 22210: Make getUserMedia() algorithm use all numbered items.</li>

      <li>Bug 22250: Fixed accidentally overridden error.</li>

      <li>Bug 22211: Added async error when no valid media type is
      requested.</li>

      <li>Bug 22216: Made NavigatorUserMediaError extend DOMError.</li>

      <li>Bug 22249: Throw on attempts to set currentTime on media elements
      playing MediaStream objects.</li>

      <li>Bug 22246: Made media.buffered have length 0.</li>

      <li>Bug 22692: Updated media element to use HAVE_NOTHING state before
      media arrives on the played MediaStream and HAVE_ENOUGH_DATA as soon as
      media arrives.</li>
    </ol>

    <h2>May 29, 2013</h2>

    <ol>
      <li>Bug 22252: fixed usage of MUST in MediaStream() constructor
      description.</li>

      <li>Bug 22215: made MediaStream.ended readonly.</li>

      <li>Bug 21967: clarified MediaStreamTrack.enabled state initial
      value.</li>

      <li>Added aspectRatio constraint, capability, and state.</li>

      <li>Updated usage of MediaStreams in media elements.</li>
    </ol>

    <h2>May 15, 2013</h2>

    <ol>
      <li>Added explanatory section for constraints, capabilities, and
      states.</li>

      <li>Added VideoFacingModeEnum (including left and right options).</li>

      <li>Added getSourceInfos() and SourceInfo dictionary.</li>

      <li>Added isolated streams.</li>
    </ol>

    <h2>April 29, 2013</h2>

    <ol>
      <li>Removed remaining photo APIs and references (since we have a separate
      Image Capture Spec).</li>
    </ol>

    <h2>March 20, 2013</h2>

    <ol>
      <li>Added readonly and remote attributes to MediaStreamTrack</li>

      <li>Removed getConstraint(), setConstraint(), appendConstraint(), and
      prependConstraint().</li>

      <li>Added source states. Added states() method on tracks. Moved
      sourceType and sourceId to be states.</li>

      <li>Added source capabilities. Added capabilities() method on
      tracks.</li>

      <li>Added clarifying text about MediaStreamTrack lifecycle and
      mediaflow.</li>

      <li>Made MediaStreamTrack cloning explicit.</li>

      <li>Removed takePhoto() and friends from VideoStreamTrack (we have a
      separate Image Capture Spec).</li>

      <li>Made getUserMedia() error callback mandatory.</li>
    </ol>

    <h2>December 12, 2012</h2>

    <ol>
      <li>Changed error code to be string instead of number.</li>

      <li>Added core of settings proposal allowing for constraint changes after
      stream/track creation.</li>
    </ol>

    <h2>November 15 2012</h2>

    <ol>
      <li>Introduced new representation of tracks in a stream (removed
      MediaStreamTrackList).</li>

      <li>Updated MediaStreamTrack.readyState to use an enum type (instad of
      unsigned short constants).</li>

      <li>Renamed MediaStream.label to MediaStream.id (the definition needs
      some more work).</li>
    </ol>

    <h2>October 1 2012</h2>

    <ol>
      <li>Limited the track kind values to "audio" and "video" only (could
      previously be user defined as well).</li>

      <li>Made MediaStream extend EventTarget.</li>

      <li>Simplified the MediaStream constructor.</li>
    </ol>

    <h2>June 23 2012</h2>

    <ol>
      <li>Rename title to "Media Capture and Streams".</li>

      <li>Update document to comply with HTML5.</li>

      <li>Update image describing a MediaStream.</li>

      <li>Add known issues and various other editorial changes.</li>
    </ol>

    <h2>June 22 2012</h2>

    <ol>
      <li>Update wording for constraints algorithm.</li>
    </ol>

    <h2>June 19 2012</h2>

    <ol>
      <li>Added "Media Streams as Media Elements section".</li>
    </ol>

    <h2>June 12 2012</h2>

    <ol>
      <li>Switch to respec v3.</li>
    </ol>

    <h2>June 5 2012</h2>

    <ol>
      <li>Added non-normative section "Implementation Suggestions".</li>

      <li>Removed stray whitespace.</li>
    </ol>

    <h2>June 1 2012</h2>

    <ol>
      <li>Added media constraint algorithm.</li>
    </ol>

    <h2>Apr 23 2012</h2>

    <ol>
      <li>Remove MediaStreamRecorder.</li>
    </ol>

    <h2>Apr 20 2012</h2>

    <ol>
      <li>Add definitions of MediaStreams and related objects.</li>
    </ol>

    <h2>Dec 21 2011</h2>

    <ol>
      <li>Changed to make wanted media opt in (rather than opt out). Minor
      edits.</li>
    </ol>

    <h2>Nov 29 2011</h2>

    <ol>
      <li>Changed examples to use MediaStreamOptions objects rather than
      strings. Minor edits.</li>
    </ol>

    <h2>Nov 15 2011</h2>

    <ol>
      <li>Removed MediaStream stuff. Refers to webrtc 1.0 spec for that part
      instead.</li>
    </ol>

    <h2>Nov 9 2011</h2>

    <ol>
      <li>Created first version by copying the webrtc spec and ripping out
      stuff. Put it on github.</li>
    </ol>
  </section>

  <section class="appendix">
    <h2>Acknowledgements</h2>

    <p>The editors wish to thank the Working Group chairs and Team Contact,
    Harald Alvestrand, Stefan HÃ¥kansson, and Dominique HazaÃ«l-Massieux, for
    their support. Substantial text in this specification was provided by many
    people including 
    <!-- tag 1 to reduce merge conflicts when adding names to list  -->
     Jim Barnett, <!-- tag 2 --> Harald Alvestrand, <!-- tag 3 --> Travis
    Leithead, <!-- tag 4 --> <!-- tag 5 --> <!-- tag 6 --> <!-- tag 7 -->
     <!-- tag 8 --> <!-- tag 9 --> and Stefan HÃ¥kansson.</p>
  </section>
</body>
</html>
