<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<!--
   To publish this document, see instructions in README
   -->
<html lang="en-us" xml:lang="en-us" xmlns="http://www.w3.org/1999/xhtml"
      xmlns:ns="http://www.w3.org/1999/xhtml">
  <head>
    <link href="getusermedia.css" rel="stylesheet" type="text/css" />

    <title>Media Capture and Streams</title>

    <meta content="text/html; charset=utf-8" http-equiv="Content-Type" />

    <script class="remove"
    src="http://www.w3.org/Tools/respec/respec-w3c-common"
    type="text/javascript"> // &lt;!-- keep this comment --&gt; // </script>

    <script class="remove" src="getusermedia.js" type="text/javascript"> //
    &lt;!-- keep this comment --&gt; // </script>
  </head>

  <body>
    <section id="abstract">
      <p>This document defines a set of JavaScript APIs that allow local
      media, including audio and video, to be requested from a platform.</p>
    </section>

    <section id="sotd">
      <p>This document is not complete. It is subject to major changes and,
      while early experimentations are encouraged, it is therefore not
      intended for implementation. The API is based on preliminary work done
      in the WHATWG.</p>
    </section>

    <section class="informative" id="intro">
      <h2>Introduction</h2>

      <p>Access to multimedia streams (video, audio, or both) from local
      devices (video cameras, microphones, Web cams) can have a number of
      uses, such as real-time communication, recording, and surveillance.</p>

      <p>This document defines the APIs used to get access to local devices
      that can generate multimedia stream data. This document also defines the
      MediaStream API by which JavaScript is able to manipulate the stream
      data or otherwise process it.</p>
    </section>

    <section id="conformance">
      <p>This specification defines conformance criteria that apply to a
      single product: the <dfn>user agent</dfn> that implements the interfaces
      that it contains.</p>

      <p>Conformance requirements phrased as algorithms or specific steps may
      be implemented in any manner, so long as the end result is equivalent.
      (In particular, the algorithms defined in this specification are
      intended to be easy to follow, and not intended to be performant.)</p>

      <p>Implementations that use ECMAScript to implement the APIs defined in
      this specification must implement them in a manner consistent with the
      ECMAScript Bindings defined in the Web IDL specification [[!WEBIDL]], as
      this specification uses that specification and terminology.</p>
    </section>

    <section>
      <h2>Terminology</h2>

      <dl>
        <dt>
          <i>HTML Terms:</i>
        </dt>

        <dd>
          <p>The <code>
              <a
              href="http://dev.w3.org/html5/spec/webappapis.html#eventhandler">EventHandler</a>
            </code> interface represents a callback used for event handlers as
          defined in [[!HTML5]].</p>

          <p>The concepts <dfn>
              <a
              href="http://dev.w3.org/html5/spec/webappapis.html#queue-a-task">queue
              a task</a>
            </dfn> and <dfn>
              <a
              href="http://dev.w3.org/html5/spec/webappapis.html#fire-a-simple-event">fires
              a simple event</a>
            </dfn> are defined in [[!HTML5]].</p>

          <p>The terms <dfn>
              <a
              href="http://dev.w3.org/html5/spec/webappapis.html#event-handlers">event
              handlers</a>
            </dfn> and <dfn>
              <a
              href="http://dev.w3.org/html5/spec/webappapis.html#event-handler-event-type">
              event handler event types</a>
            </dfn> are defined in [[!HTML5]].</p>
        </dd>

        <dt>
          <dfn>source</dfn>
        </dt>

        <dd>
          <p>A source is the "thing" providing the source of a media stream
          track. The source is the broadcaster of the media itself. A source
          can be a physical webcam, microphone, local video or audio file from
          the user's hard drive, network resource, or static image.</p>

          <p>Other than the source identifier (defined in
            <code><a>MediaDeviceInfo</a>.deviceId</code>),
          other bits of source identity are
          <strong>never</strong> directly available to the application until
          the user agent connects a source to a track. Once a source has been
          "released" to the application (either via a permissions UI,
          pre-configured allow-list, or some other release mechanism) the
          application will be able discover additional source-specific
          capabilities.</p>

          <p>Sources <strong>do not</strong> have constraints -- tracks have
          constraints. When a source is connected to a track, it must,
          possibly in combination with UA processing (e.g., downsampling),
          conform to the constraints present on that track (or set of
          tracks).</p>

          <p>Sources are released (un-attached) from a track when the
          track is ended for any reason.</p>

          <p>On the <code>
              <a>MediaStreamTrack</a>
            </code> object, sources are represented by a <code>
              <a>sourceType</a>
            </code> attribute. The behavior of APIs associated with the
          source's capabilities and settings change depending on the source
          type.</p>

          <p>Sources have <code>
              <a>capabilities</a>
            </code> and <code>
              <a>settings</a>
            </code>. The capabilities and settings are "owned" by the source
          and are common to any (multiple) tracks that happen to be using the
          same source (e.g., if two different track objects bound to the same
          source ask for the same capability or setting information, they will
          get back the same answer).</p>
        </dd>

        <dt> <a>Setting</a> (Source Setting) </dt>

        <dd>
          <p>A setting refers to the immediate, current value of the source's
          (optionally constrained) capabilities. Settings are always
          read-only.</p>

          <p>A source's settings can change dynamically over time due to
          environmental conditions, sink configurations, or constraint
          changes. A source's settings must always conform to the current set
          of mandatory constraints that all of the tracks it is bound to have
          defined, and should do its best to conform to the set of optional
          constraints specified.</p>

          <p>Although settings are a property of the source, they are only
          exposed to the application through the tracks attached to the
          source. The <a>ConstrainablePattern</a> interface provides this
          exposure.</p>
        </dd>

        <dt>
          <a>Capabilities</a>
        </dt>

        <dd>
          <p>Source capabilities are the intrinsic "features" of a source
          object. For each source setting, there is a corresponding capability
          that describes whether it is supported by the source and if so, what
          the range of supported values are. As with settings, capabilities
          are exposed to the application via the <a>ConstrainablePattern</a>
          interface.</p>

          <p>The values of the supported capabilities must be normalized to
          the ranges and enumerated types defined in this specification.</p>

          <p>A <a>getCapabilities()</a> call on a track returns the same
          underlying per-source capabilities for all tracks connected to the
          source.</p>

          <p>Source capabilities are effectively constant. Applications should
          be able to depend on a specific source having the same capabilities
          for any session.</p>
        </dd>

        <dt>
          <dfn>Constraints</dfn>
        </dt>

        <dd>
          <p>Constraints are an optional track feature for restricting the
          range of allowed variability on a source. Without provided track
          constraints, implementations are free to select a source's settings
          from the full ranges of its supported capabilities, and to adjust
          those settings at any time for any reason.</p>

          <p>Constraints are exposed on tracks via the
          <a>ConstrainablePattern</a> interface, which includes an API for
          dynamically changing constraints. Note that <a>getUserMedia()</a>
          also permits an initial set of constraints to be applied when the
          track is first obtained.</p>

          <p>It is possible for two tracks that share a unique source to apply
          contradictory constraints. The <a>ConstrainablePattern</a> interface
          supports the calling of an error handler when the conflicting
          constraint is requested.</p>

          <p>A correspondingly-named constraint exists for each corresponding
          source setting name and capability name. In general, user agents
          will have more flexibility to optimize the media streaming
          experience the fewer constraints are applied, so application authors
          are strongly encouraged to use mandatory constraints sparingly.</p>
        </dd>

        <dt>
          <code>RTCPeerConnection</code>
        </dt>

        <dd><dfn>
            <code>RTCPeerConnection</code>
          </dfn> is defined in [[!WEBRTC10]].</dd>
      </dl>
    </section>

    <section id="stream-api">
      <h2>MediaStream API</h2>

      <section>
        <h2>Introduction</h2>

        <p>The two main components in the MediaStream API are the <code>
            <a>MediaStreamTrack</a>
          </code> and the <code>
            <a>MediaStream</a>
          </code> interfaces. The <code>
            <a>MediaStreamTrack</a>
          </code> object represents media originating from a single media
        source in the user agent, e.g. video from a web camera. A <code>
            <a>MediaStream</a>
          </code> is used group several <code>
            <a>MediaStreamTrack</a>
          </code> objects into one unit that can be rendered in a media
        element or recorded.</p>

        <p>Each <code>
            <a>MediaStream</a>
          </code> can contain zero or more <code>
            <a>MediaStreamTrack</a>
          </code> objects. All tracks in a <code>
            <a>MediaStream</a>
          </code> are intended to be synchronized when rendered. Different
        <code>
            <a>MediaStream</a>
          </code> objects do not need to be synchronized.</p>

        <p class="note">While the intent is to synchronize tracks, it could be
        better in some circumstances to permit tracks to lose
        synchronization.In particular, when tracks are remotely sourced and
        real-time [[!WEBRTC10]], it can be better to allow loss of
        synchronization than to accumulate delays or risk glitches and other
        artifacts. Implementations are expected to understand the implications
        of choices regarding synchronization of playback and the effect that
        these have on user perception.</p>

        <p>A <code>
            <a>MediaStreamTrack</a>
          </code> represents content comprising one or more channels, where
        the channels have a defined well known relationship to each other
        (such as a stereo or 5.1 audio signal). A channel is the smallest unit
        considered in this API specification.</p>

        <p>
          <img alt="A MediaStream" src="images/media-stream.png" width="418" />
        </p>

        <p>A <code>
            <a>MediaStream</a>
          </code> object has an input and an output that represent the
        combined input and output of all the object's tracks. The output of
        the <code>
            <a>MediaStream</a>
          </code> controls how the object is rendered, e.g., what is saved if
        the object is recorded to a file or what is displayed if the object is
        used in a <code>video</code> element.</p>

        <p>A new <code>
            <a>MediaStream</a>
          </code> object can be created from accessible media sources (that
        does not require any additional permissions) using the <code>
            <a href="#dom-mediastream">MediaStream()</a>
          </code> constructor. The constructor argument can either be an
        existing <code>
            <a>MediaStream</a>
          </code> object, in which case all the tracks of the given stream are
        added to the new <code>
            <a>MediaStream</a>
          </code> object, or an array of <code>
            <a>MediaStreamTrack</a>
          </code> objects. The latter form makes it possible to compose a
        stream from different source streams.</p>

        <p>Both <code>
            <a>MediaStream</a>
          </code> and <code>
            <a>MediaStreamTrack</a>
          </code> objects can be cloned. This allows for greater control since
        the separate instances can be manipulated and <a
        title="consumer">consumed</a> individually. A cloned <code>
            <a>MediaStream</a>
          </code> contains clones of all member tracks from the original
        stream.</p>

        <p>When a <code>
            <a>MediaStream</a>
          </code> object is being generated from a local file (as opposed to a
        live audio/video source), the user agent SHOULD stream the data from
        the file in real time, not all at once. The <code>MediaStream</code>
        object is also used in contexts outside <code>getUserMedia</code>,
        such as [[!WEBRTC10]]. In both cases, ensuring a realtime stream
        reduces the ease with which pages can distinguish live video from
        pre-recorded video, which can help protect the user's privacy.</p>
      </section>

      <section>
        <h2>MediaStream</h2>

        <p>The <dfn id="dom-mediastream">
            <code>MediaStream()</code>
          </dfn> constructor composes a new stream out of existing tracks. It
        takes an optional argument of type <code>
            <a>MediaStream</a>
          </code> or an array of <code>
            <a>MediaStreamTrack</a>
          </code> objects. <dfn id="mediastream-constructor">When the
        constructor is invoked</dfn>, the UA must run the following steps:</p>

        <ol>
          <li>
            <p>Let <var>stream</var> be a newly constructed <code>
                <a>MediaStream</a>
              </code> object.</p>
          </li>

          <li>
            <p>Initialize <var>stream's</var> <code>
                <a href="#dom-mediastream-id">id</a>
              </code> attribute to a newly generated value.</p>
          </li>

          <li>
            <p>If the constructor's argument is present, run the sub steps
            that corresponds to the argument type.</p>

            <ul>
              <li>
                <p><code>Array</code> of <code>
                    <a>MediaStreamTrack</a>
                  </code> objects:</p>

                <p>Run the following sub steps for each <code>
                    <a>MediaStreamTrack</a>
                  </code> in the array:</p>

                <ol>
                  <li>
                    <p><em>Add track</em>: Let <var>track</var> be the <code>
                        <a>MediaStreamTrack</a>
                      </code> about to be processed.</p>
                  </li>

                  <li>
                    <p>Add <var>track</var> to <var>stream</var>'s <a
                    href="#track-set">track set</a>.</p>
                  </li>
                </ol>
              </li>

              <li>
                <p><code>
                    <a>MediaStream</a>
                  </code>:</p>

                <p>Run the sub steps labeled <em>Add track</em> (above) for
                every <code>
                    <a>MediaStreamTrack</a>
                  </code> in the argument stream's <a href="#track-set">track
                set</a>.</p>
              </li>
            </ul>
          </li>

          <li>
            <p>If <var>stream</var>'s <a href="#track-set">track set</a> is
            empty or only contains ended tracks, set <var>stream</var>'s <code>
                <a href="#dom-mediastream-active">active</a>
              </code> attribute to <code>false</code>, otherwise set it to
            <code>true</code>.</p>
          </li>

          <li>
            <p>Return <var>stream</var>.</p>
          </li>
        </ol>

        <p>The tracks of a <code>
            <a>MediaStream</a>
          </code> are stored in a <dfn id="track-set">track set</dfn>. The
        track set MUST contain the <code>
            <a>MediaStreamTrack</a>
          </code> objects that correspond to the tracks of the stream. The
        relative order of the tracks in the set is user agent defined and the
        API will never put any requirements on the order. The proper way to
        find a specific <code>
            <a>MediaStreamTrack</a>
          </code> object in the set is to look it up by its <code>
            <a href="#dom-mediastreamtrack-id">id</a>
          </code>.</p>

        <p>An object that reads data from the output of a <code>
            <a>MediaStream</a>
          </code> is referred to as a <code>
            <a>MediaStream</a>
          </code> <dfn>consumer</dfn>. The list of <code>
            <a>MediaStream</a>
          </code> consumers currently include the media elements [[HTML5]],
        <code>RTCPeerConnection</code> [[WEBRTC10]],
        <code>MediaRecorder</code> [[mediastream-recording]] and
        <code>ImageCapture</code> [[image-capture]].</p>

        <p class="note"><code>
            <a>MediaStream</a>
          </code> consumers must be able to handle tracks being added and
        removed. This behavior is specified per consumer.</p>

        <p>A <code>
            <a>MediaStream</a>
          </code> object is said to be <dfn
        id="stream-inactive">MediaStream.inactive</dfn> when it does not have
        any tracks or all tracks belonging to the stream have <a
        href="#track-ended">ended</a>. Otherwise the stream is active. A <code>
            <a>MediaStream</a>
          </code> can start its life as inactive if it is constructed without
        any tracks.</p>

        <p>When a <code>
            <a>MediaStream</a>
          </code> goes from being active to inactive, the user agent MUST
        queue a task that sets the object's <code>
            <a href="#dom-mediastream-active">active</a>
          </code> attribute to <code>false</code> and fire a simple event
        named <code>
            <a href="#event-mediastream-inactive">inactive</a>
          </code> at the object. When a <code>
            <a>MediaStream</a>
          </code> goes from being inactive to active, the user agent MUST
        queue a task that sets the object's <code>
            <a href="#dom-mediastream-active">active</a>
          </code> attribute to <code>true</code> and fire a simple event named
        <code>
            <a href="#event-mediastream-active">active</a>
          </code> at the object.</p>

        <p>If the stream's activity status changed due to a user request, the
        task source for this <span title="concept-task">task</span> is the
        user interaction task source. Otherwise the task source for this <span
        title="concept-task">task</span> is the networking task source.</p>

        <dl class="idl" title="interface MediaStream : EventTarget">
          <dt>Constructor()</dt>

          <dd> See the <a href="#mediastream-constructor">MediaStream
          constructor algorithm</a> </dd>

          <dt>Constructor(MediaStream stream)</dt>

          <dd> See the <a href="#mediastream-constructor">MediaStream
          constructor algorithm</a> </dd>

          <dt>Constructor(sequence&lt;MediaStreamTrack&gt; tracks)</dt>

          <dd> See the <a href="#mediastream-constructor">MediaStream
          constructor algorithm</a> </dd>

          <dt>readonly attribute DOMString id</dt>

          <dd>
            <p>When a <code>
                <a>MediaStream</a>
              </code> object is created, the user agent MUST generate an
            identifier string, and MUST initialize the object's <code>
                <a href="#dom-mediastream-id">id</a>
              </code> attribute to that string. A good practice is to use an
            UUID, which is 36 characters long in its canonical form.</p>

            <p>The <dfn id="dom-mediastream-id">
                <code>id</code>
              </dfn> attribute MUST return the value to which it was
            initialized when the object was created.</p>
          </dd>

          <dt>sequence&lt;MediaStreamTrack&gt; getAudioTracks()</dt>

          <dd>
            <p>Returns a sequence of <code>
                <a>MediaStreamTrack</a>
              </code> objects representing the audio tracks in this
            stream.</p>

            <p>The <dfn id="dom-mediastream-getaudiotracks">
                <code>getAudioTracks()</code>
              </dfn> method MUST return a sequence that represents a snapshot
            of all the <code>
                <a>MediaStreamTrack</a>
              </code> objects in this stream's <a href="#track-set">track
            set</a> whose <code>
                <a href="#dom-mediastreamtrack-kind">kind</a>
              </code> is equal to "<code>audio</code>". The conversion from
            the <a href="#track-set">track set</a> to the sequence is user
            agent defined and the order does not have to stable between
            calls.</p>
          </dd>

          <dt>sequence&lt;MediaStreamTrack&gt; getVideoTracks()</dt>

          <dd>
            <p>Returns a sequence of <code>
                <a>MediaStreamTrack</a>
              </code> objects representing the video tracks in this
            stream.</p>

            <p>The <dfn id="dom-mediastream-getvideotracks">
                <code>getVideoTracks()</code>
              </dfn> method MUST return a sequence that represents a snapshot
            of all the <code>
                <a>MediaStreamTrack</a>
              </code> objects in this stream's <a href="#track-set">track
            set</a> whose <code>
                <a href="#dom-mediastreamtrack-kind">kind</a>
              </code> is equal to "<code>video</code>". The conversion from
            the <a href="#track-set">track set</a> to the sequence is user
            agent defined and the order does not have to stable between
            calls.</p>
          </dd>

          <dt>sequence&lt;MediaStreamTrack&gt; getTracks()</dt>

          <dd>
            <p>Returns a sequence of <code>
                <a>MediaStreamTrack</a>
              </code> objects representing all the tracks in this stream.</p>

            <p>The <dfn id="dom-mediastream-gettracks">
                <code>getTracks()</code>
              </dfn> method MUST return a sequence that represents a snapshot
            of all the <code>
                <a>MediaStreamTrack</a>
              </code> objects in this stream's <a href="#track-set">track
            set</a>, regardless of kind. The conversion from the <a
            href="#track-set">track set</a> to the sequence is user agent
            defined and the order does not have to stable between calls.</p>
          </dd>

          <dt>MediaStreamTrack? getTrackById(DOMString trackId)</dt>

          <dd>
            <p>The <dfn id="dom-mediastream-gettrackbyid">
                <code>getTrackById()</code>
              </dfn> method MUST return the first <code>
                <a>MediaStreamTrack</a>
              </code> object in this stream's <a href="#track-set">track
            set</a> whose <code>
                <a href="#dom-mediastreamtrack-id">id</a>
              </code> is equal to <var>trackId</var>. The method MUST return
            null if no track matches the <var>trackId</var> argument.</p>
          </dd>

          <dt>void addTrack(MediaStreamTrack track)</dt>

          <dd>
            <p>Adds the given <code>
                <a>MediaStreamTrack</a>
              </code> to this <code>
                <a>MediaStream</a>
              </code>.</p>

            <p>When the <dfn id="dom-mediastream-addtrack">
                <code>addTrack()</code>
              </dfn> method is invoked, the user agent MUST run the following
            steps:</p>

            <ol>
              <li>
                <p>Let <var>track</var> be the <code>
                    <a>MediaStreamTrack</a>
                  </code> argument and <var>stream</var> this <code>
                    <a>MediaStream</a>
                  </code> object.</p>
              </li>

              <li>
                <p>If <var>track</var> is already in <var>stream's</var> <a
                href="#track-set">track set</a>, then abort these steps.</p>
              </li>

              <li>
                <p>Add <var>track</var> to <var>stream</var>'s <a
                href="#track-set">track set</a>.</p>
              </li>
            </ol>
          </dd>

          <dt>void removeTrack(MediaStreamTrack track)</dt>

          <dd>
            <p>Removes the given <code>
                <a>MediaStreamTrack</a>
              </code> from this <code>
                <a>MediaStream</a>
              </code>.</p>

            <p>When the <dfn id="dom-mediastream-removetrack">
                <code>removeTrack()</code>
              </dfn> method is invoked, the user agent MUST remove the track,
            indicated by the method's argument, from the stream's <a
            href="#track-set">track set</a>, if present.</p>
          </dd>

          <dt>MediaStream clone()</dt>

          <dd>
            <p>Clones the given <code>
                <a>MediaStream</a>
              </code> and all its tracks.</p>

            <p>When the <dfn id="dom-mediastream-clone">
                <code>MediaStream.clone()</code>
              </dfn> method is invoked, the user agent MUST run the following
            steps:</p>

            <ol>
              <li>
                <p>Let <var>streamClone</var> be a newly constructed <code>
                    <a>MediaStream</a>
                  </code> object.</p>
              </li>

              <li>
                <p>Initialize <var>streamClone</var>'s <code>
                    <a href="#dom-mediastream-id">id</a>
                  </code> attribute to a newly generated value.</p>
              </li>

              <li>
                <p>Let <var>clonedTracks</var> be a list that contains the
                result of running <code>
                    <a
                    href="#dom-mediastreamtrack-clone">MediaStreamTrack.clone()</a>
                  </code> on all the tracks in the stream on which this method
                was called. </p>
              </li>

              <li>
                <p>Let <var>clonedTracks</var> be <var>streamClone</var>'s <a
                href="#track-set">track set</a>.</p>
              </li>

              <li>Return <var>streamClone</var>.</li>
            </ol>
          </dd>

          <dt>readonly attribute boolean active</dt>

          <dd>
            <p>The <dfn id="dom-mediastream-active">
                <code>MediaStream.active</code>
              </dfn> attribute returns true if the <code>
                <a>MediaStream</a>
              </code> is active (see <a href="#stream-inactive">inactive</a>),
            and false otherwise.</p>

            <p>When a <code>
                <a>MediaStream</a>
              </code> object is created, its <code>
                <a href="#dom-mediastream-active">active</a>
              </code> attribute MUST be set to true, unless stated otherwise
            (for example by the <code>
                <a href="#dom-mediastream">MediaStream()</a>
              </code> constructor algorithm).</p>
          </dd>

          <dt>attribute EventHandler onactive</dt>

          <dd>This event handler, of type <code>
              <a href="#event-mediastream-active">active</a>
            </code>, MUST be supported by all objects implementing the <code>
              <a>MediaStream</a>
            </code> interface.</dd>

          <dt>attribute EventHandler oninactive</dt>

          <dd>This event handler, of type <code>
              <a href="#event-mediastream-inactive">inactive</a>
            </code>, MUST be supported by all objects implementing the <code>
              <a>MediaStream</a>
            </code> interface.</dd>

          <dt>attribute EventHandler onaddtrack</dt>

          <dd>This event handler, of type <code>
              <a href="#event-mediastream-addtrack">addtrack</a>
            </code>, MUST be supported by all objects implementing the <code>
              <a>MediaStream</a>
            </code> interface.</dd>

          <dt>attribute EventHandler onremovetrack</dt>

          <dd>This event handler, of type <code>
              <a href="#event-mediastream-removetrack">removetrack</a>
            </code>, MUST be supported by all objects implementing the <code>
              <a>MediaStream</a>
            </code> interface.</dd>
        </dl>
      </section>

      <section>
        <h2>MediaStreamTrack</h2>

        <p>A <code>
            <a>MediaStreamTrack</a>
          </code> object represents a media source in the user agent. Several
        <code>
            <a>MediaStreamTrack</a>
          </code> objects can represent the same media source, e.g., when the
        user chooses the same camera in the UI shown by two consecutive calls
        to <code>
            <a href="#dom-mediadevices-getusermedia">getUserMedia()</a>
          </code> .</p>

        <p>The data from a <code>
            <a>MediaStreamTrack</a>
          </code> object does not necessarily have a canonical binary form;
        for example, it could just be "the video currently coming from the
        user's video camera". This allows user agents to manipulate media in
        whatever fashion is most suitable on the user's platform.</p>

        <p>A script can indicate that a track no longer needs its source with
        the <code>
            <a href="#dom-mediastreamtrack-stop">MediaStreamTrack.stop()</a>
          </code> method. When all tracks using a source have been stopped,
        the given permission for that source is revoked and the source is <dfn
        id="source-stopped">stopped</dfn>. If the data is being generated from
        a live source (e.g., a microphone or camera), then the user agent
        SHOULD remove any active "on-air" indicator for that source. If the
        data is being generated from a prerecorded source (e.g. a video file),
        any remaining content in the file is ignored. An implementation may
        use a per source reference count to keep track of source usage, but
        the specifics are out of scope for this specification.</p>

        <p>If there is no stored permission to use that source, the UA SHOULD
        also remove the "permission granted" indicator for the source.</p>

        <section>
          <h3>Life-cycle and Media Flow</h3>

          <h4>Life-cycle</h4>

          <p>A <code>
              <a>MediaStreamTrack</a>
            </code> has two stages in its life-cycle: <code>live</code> and
          <code>ended</code>. A newly created <code>
              <a>MediaStreamTrack</a>
            </code> can be in any stage depending on how it was created. For
          example, cloning an ended track results in a new ended track. The
          current stage is reflected by the object's <code>
              <a href="#dom-mediastreamtrack-readystate">readyState</a>
            </code> attribute.</p>

          <p>In the <code>live</code> state, the track is active and media is
          available for use by consumers (but may be replaced by
          zero-information-content if the <code>
              <a>MediaStreamTrack</a>
            </code> is <a href="#track-muted">muted</a> or <a
          href="#track-enabled">enabled</a>, see below).</p>

          <p>A muted or disabled <code>
              <a>MediaStreamTrack</a>
            </code> renders either silence (audio), black frames (video), or a
          zero-information-content equivalent. For example, a video element
          sourced by a muted or disabled <code>
              <a>MediaStreamTrack</a>
            </code> (contained within a <code>
              <a>MediaStream</a>
            </code>), is playing but the rendered content is the muted output.
          When all tracks connected to a source are muted or disabled, the
          "on-air" or "recording" indicator for that source can be turned off;
          when the track is no longer muted or disabled, it MUST be turned
          back on.</p>

          <p>The muted/unmuted state of a track reflects if the source
          provides any media at this moment. The enabled/disabled state is
          under application control and determines if the track outputs media
          (to its consumers). Hence, media from the source only flows when a
          <code>
              <a>MediaStreamTrack</a>
            </code> object is both unmuted and enabled.</p>

          <p>A <code>
              <a>MediaStreamTrack</a>
            </code> is <a href="#track-muted">muted</a> when the source is
          temporarily unable to provide the track with data. A track can be
          muted by a user. Often this action is outside the control of the
          application. This could be as a result of the user hitting a
          hardware switch, or toggling a control in the operating system or
          browser chrome. A track can also be muted by the user agent.</p>

          <p>Applications are able to <a href="#track-enabled">enable</a> or
          disable a <code>
              <a>MediaStreamTrack</a>
            </code> to prevent it from rendering media from the source. A
          muted track will however, regardless of the enabled state, render
          silence and blackness. A disabled track is logically equivalent to a
          muted track, from a consumer point of view.</p>

          <p>For a newly created <code>
              <a>MediaStreamTrack</a>
            </code> object, the following applies. The track is always enabled
          unless stated otherwise (for example when cloned) and the muted
          state reflects the state of the source at the time the track is
          created.</p>

          <p>A <code>
              <a>MediaStreamTrack</a>
            </code> object is said to <em>end</em> when the source of the
          track is disconnected or exhausted.</p>

          <p>A <code>
              <a>MediaStreamTrack</a>
            </code> can be <dfn id="track-detached">detached</dfn> from its
          source. It means that the track is no longer dependent on the source
          for media data. If no other <code>
              <a>MediaStreamTrack</a>
            </code> is using the same source, the source will be <a
          href="#source-stopped">stopped</a>. <code>
              <a>MediaStreamTrack</a>
            </code> attributes such as <code>
              <a href="#dom-mediastreamtrack-kind">kind</a>
            </code> and <code>
              <a href="#dom-mediastreamtrack-label">label</a>
            </code> MUST not change values when the source is detached.</p>

          <p>When a <code>
              <a>MediaStreamTrack</a>
            </code> object ends for any reason (e.g., because the user
          rescinds the permission for the page to use the local camera, or
          because the data comes from a finite file and the file's end has
          been reached and the user has not requested that it be looped, or
          because the application invoked the <code>
              <a href="#dom-mediastreamtrack-stop">stop()</a>
            </code> method on the <code>
              <a>MediaStreamTrack</a>
            </code> object, or because the UA has instructed the track to end
          for any reason) it is said to be <dfn
          id="track-ended">ended</dfn>.</p>

          <p>When a <code>
              <a>MediaStreamTrack</a>
            </code> <var>track</var> ends for any reason other than the <code>
              <a href="#dom-mediastreamtrack-stop">stop()</a>
            </code> method being invoked, the user agent MUST queue a task
          that runs the following steps:</p>

          <ol>
            <li>
              <p>If the <var>track's</var> <code>
                  <a href="#dom-mediastreamtrack-readystate">readyState</a>
                </code> attribute has the value <code>ended</code> already,
              then abort these steps.</p>
            </li>

            <li>
              <p>Set <var>track's</var> <code>
                  <a href="#dom-mediastreamtrack-readystate">readyState</a>
                </code> attribute to <code>ended</code>.</p>
            </li>

            <li>
              <p><a href="#track-detached">Detach</a> <var>track's</var>
              source.</p>
            </li>

            <li>
              <p>Fire a simple event named <code>
                  <a href="#event-mediastreamtrack-ended">ended</a>
                </code> at the object.</p>
            </li>
          </ol>

          <p>If the end of the stream was reached due to a user request, the
          event source for this event is the user interaction event
          source.</p>

          <h4>Media Flow</h4>

          <p>There are two concepts related to the media flow for a
          <code>live</code> <code>
              <a>MediaStreamTrack</a>
            </code>: muted or not, and enabled or disabled.</p>

          <p><dfn id="track-muted">Muted</dfn> refers to the input to the
          <code>
              <a>MediaStreamTrack</a>
            </code>. If live samples are not made available to the <code>
              <a>MediaStreamTrack</a>
            </code> it is muted.</p>

          <p>Muted is out of control for the application, but can be observed
          by the application by reading the <code>
              <a href="#dom-mediastreamtrack-muted">muted</a>
            </code> attribute and listening to the associated events <code>
              <a href="#event-mediastreamtrack-mute">mute</a>
            </code> and <code>
              <a href="#event-mediastreamtrack-unmute">unmute</a>
            </code>.There can be several reasons for a <code>
              <a>MediaStreamTrack</a>
            </code> to be muted: the user pushing a physical mute button on
          the microphone, the user toggling a control in the operating system,
          the user clicking a mute button in the browser chrome, the UA (on
          behalf of the user) mutes, etc.</p>

          <p><dfn id="track-enabled">Enabled/disabled</dfn> on the other hand
          is available to application to control (and observe) via the <code>
              <a href="#dom-mediastreamtrack-enabled">enabled</a>
            </code> attribute.</p>

          <p>The result for the consumer is the same in the meaning that
          whenever <code>
              <a>MediaStreamTrack</a>
            </code> is muted or disabled (or both) the consumer gets
          zero-information-content, which means silence for audio and black
          frames for video. In other words, media from the source only flows
          when a <code>
              <a>MediaStreamTrack</a>
            </code> object is both unmuted and enabled. For example, a video
          element sourced by a muted or disabled <code>
              <a>MediaStreamTrack</a>
            </code> (contained in a <code>
              <a>MediaStream</a>
            </code>), is playing but rendering blackness.</p>

          <p>For a newly created <code>
              <a>MediaStreamTrack</a>
            </code> object, the following applies: the track is always enabled
          unless stated otherwise (for example when cloned) and the muted
          state reflects the state of the source at the time the track is
          created.</p>
        </section>

        <section>
          <h3>Tracks and Constraints</h3>

          <p>Constraints are set on tracks and may affect sources.</p>

          <p>Whether <code>
              <a>Constraints</a>
            </code> were provided at track initialization time or need to be
          established later at runtime, the APIs defined in the
          <a>ConstrainablePattern</a> Interface allow the retrieval and
          manipulation of the constraints currently established on a
          track.</p>

          <p>Each track maintains an internal version of the <code>
              <a>Constraints</a>
            </code> structure, namely a mandatory set of constraints (no
          duplicates), and an optional ordered list of individual constraint
          objects (may contain duplicates). The internal stored constraint
          structure is exposed to the application by the <code>
              <a>constraints</a>
            </code> attribute, and may be modified by the <code>
              <a>applyConstraints()</a>
            </code> method.</p>

          <p>When <code>
              <a>applyConstraints()</a>
            </code> is called, a user agent MUST queue a task to evaluate
          those changes when the task queue is next serviced. Similarly, if
          the <a>
              <code>sourceType</code>
            </a> changes, then the user agent MUST perform the same actions to
          re-evaluate the constraints of each track affected by that source
          change.</p>

          <p>If the <code>
              <a>MediaStreamError</a>
            </code> event named <code><a>overconstrained</a></code> is thrown, the track MUST be
          muted until either new satisfiable constraints are applied or the
          existing constraints become satisfiable.</p>
        </section>

        <section id="media-stream-track-interface-definition">
          <h3>Interface Definition</h3>

          <dl class="idl" title="interface MediaStreamTrack : EventTarget">
            <dt>readonly attribute DOMString kind</dt>

            <dd>
              <p>The <dfn id="dom-mediastreamtrack-kind">
                  <code>MediaStreamTrack.kind</code>
                </dfn> attribute MUST return the string "<code>audio</code>"
              if the object represents an audio track or "<code>video</code>"
              if object represents a video track.</p>
            </dd>

            <dt>readonly attribute DOMString id</dt>

            <dd>
              <p>Unless a <code>
                  <a>MediaStreamTrack</a>
                </code> object is created as a part a of special purpose
              algorithm that specifies how the track id must be initialized,
              the user agent MUST generate an identifier string and initialize
              the object's <code>
                  <a href="#dom-mediastreamtrack-id">id</a>
                </code> attribute to that string. See <code>
                  <a href="#dom-mediastream-id">MediaStream.id</a>
                </code> for guidelines on how to generate such an
              identifier.</p>

              <p>An example of an algorithm that specifies how the track id
              must be initialized is the algorithm to represent an incoming
              network component with a <code>
                  <a>MediaStreamTrack</a>
                </code> object. [[!WEBRTC10]]</p>

              <p><dfn id="dom-mediastreamtrack-id">
                  <code>MediaStreamTrack.id</code>
                </dfn> attribute MUST return the value to which it was
              initialized when the object was created.</p>
            </dd>

            <dt>readonly attribute DOMString label</dt>

            <dd>
              <p>User agents MAY label audio and video sources (e.g.,
              "Internal microphone" or "External USB Webcam"). The <dfn
                  id="dom-mediastreamtrack-label">
                  <code>MediaStreamTrack.label</code>
                </dfn> attribute MUST return the label of the object's
              corresponding source, if any. If the corresponding source has or
              had no label, the attribute MUST instead return the empty
              string.</p>
            </dd>

            <dt>attribute boolean enabled</dt>

            <dd>
              <p>The <dfn id="dom-mediastreamtrack-enabled">
                  <code>MediaStreamTrack.enabled</code>
                </dfn> attribute controls the <code>
                  <a href="#track-enabled">enabled</a>
                </code> state for the object.</p>

              <p>On getting, the attribute MUST return the last value to which
              it was set. On setting, it MUST be set to the new value,
              regardless if the <code>
                  <a>MediaStreamTrack</a>
                </code> object has been <a href="#track-detached">detached</a>
              from its source or not.</p>

              <p class="note">Thus, after a <code>
                  <a>MediaStreamTrack</a>
                </code> is detached from its source, its <code>
                  <a href="#dom-mediastreamtrack-enabled">enabled</a>
                </code> attribute still changes value when set; it just
              doesn't do anything with that new value.</p>
            </dd>

            <dt>readonly attribute boolean muted</dt>

            <dd>
              <p>The <dfn id="dom-mediastreamtrack-muted">
                  <code>MediaStreamTrack.muted</code>
                </dfn> attribute MUST return <code>true</code> if the track is
              <a href="#track-muted">muted</a>, and <code>false</code>
              otherwise.</p>
            </dd>

            <dt>attribute EventHandler onmute</dt>

            <dd>This event handler, of type <code>
                <a href="#event-mediastreamtrack-mute">mute</a>
              </code>, MUST be supported by all objects implementing the <code>
                <a>MediaStreamTrack</a>
              </code> interface.</dd>

            <dt>attribute EventHandler onunmute</dt>

            <dd>This event handler, of type <code>
                <a href="#event-mediastreamtrack-unmute">unmute</a>
              </code>, MUST be supported by all objects implementing the <code>
                <a>MediaStreamTrack</a>
              </code> interface.</dd>

            <dt>readonly attribute boolean _readonly</dt>

            <dd>If the track (audio or video) is backed by a read-only source
            such as a file, or the track source is a local microphone or
            camera, but is shared so that constraints applied to the track
            cannot modify the source's settings, the <dfn
                id="dom-mediastreamtrack-readonly">
                <code>readonly</code>
              </dfn> attribute MUST return the value <code>true</code>.
            Otherwise, it must return the value <code>false</code>.</dd>

            <dt>readonly attribute boolean remote</dt>

            <dd>If the track is sourced by a non-local source, the <dfn
                id="dom-mediastreamtrack-remote">
                <code>remote</code>
              </dfn> attribute MUST return the value <code>true</code>.
            Otherwise, it must return the value <code>false</code>.</dd>

            <dt>readonly attribute MediaStreamTrackState readyState</dt>

            <dd>
              <p>The <dfn id="dom-mediastreamtrack-readystate">
                  <code>readyState</code>
                </dfn> attribute represents the state of the track. It MUST
              return the value to which the user agent last set it.</p>
            </dd>

            <dt>attribute EventHandler onended</dt>

            <dd>This event handler, of type <code>
                <a href="#event-mediastreamtrack-ended">ended</a>
              </code>, MUST be supported by all objects implementing the <code>
                <a>MediaStreamTrack</a>
              </code> interface.</dd>

            <dt>MediaStreamTrack clone()</dt>

            <dd>
              <p>Clones the given <code>
                  <a>MediaStreamTrack</a>
                </code>.</p>

              <p>When the <dfn id="dom-mediastreamtrack-clone">
                  <code>MediaStreamTrack.clone()</code>
                </dfn> method is invoked, the user agent MUST run the
              following steps:</p>

              <ol>
                <li>
                  <p>Let <var>trackClone</var> be a newly constructed <code>
                      <a>MediaStreamTrack</a>
                    </code> object.</p>
                </li>

                <li>
                  <p>Initialize <var>trackClone</var>'s <code>
                      <a href="#dom-mediastreamtrack-id">id</a>
                    </code> attribute to a newly generated value.</p>
                </li>

                <li>
                  <p>Let <var>trackClone</var> inherit this track's underlying
                  source, <code>
                      <a href="#dom-mediastreamtrack-kind">kind</a>
                    </code>, <code>
                      <a href="#dom-mediastreamtrack-label">label</a>
                    </code>, <code>
                      <a
                      href="#dom-mediastreamtrack-readystate">readyState</a>
                    </code>, and <code>
                      <a href="#dom-mediastreamtrack-enabled">enabled</a>
                    </code> attributes, as well as its currently active
                  constraints.</p>
                </li>

                <li>
                  <p>Return <var>trackClone</var>.</p>
                </li>
              </ol>
            </dd>

            <dt>void stop ()</dt>

            <dd>
              <p>When a <code>
                  <a>MediaStreamTrack</a>
                </code> object's <dfn id="dom-mediastreamtrack-stop">
                  <code>stop()</code>
                </dfn> method is invoked, the user agent MUST run following
              steps:</p>

              <ol>
                <li>
                  <p>Let <var>track</var> be the current <code>
                      <a>MediaStreamTrack</a>
                    </code> object.</p>
                </li>

                <li>
                  <p>If <var>track</var> is sourced by a non-local source,
                  then abort these steps.</p>
                </li>

                <li>
                  <p>Set <var>track's</var> <code>
                      <a
                      href="#dom-mediastreamtrack-readystate">readyState</a>
                    </code> attribute to <code>ended</code>.</p>
                </li>

                <li>
                  <p><a href="#track-detached">Detach</a> <var>track's</var>
                  source.</p>
                </li>
              </ol>

              <p>The task source for the <span
              title="concept-task">tasks</span> queued for the <code>
                  <a href="#dom-mediastreamtrack-stop">stop()</a>
                </code> method is the DOM manipulation task source.</p>
            </dd>

            <dt>Capabilities getCapabilities()</dt>

            <dd>
              <p>See <a href="#constrainable-interface">ConstrainablePattern
              Interface</a> for the definition of this method.</p>
            </dd>

            <dt>MediaTrackConstraints getConstraints()</dt>

            <dd>See <a href="#constrainable-interface">ConstrainablePattern
            Interface</a> for the definition of this method. </dd>

            <dt>Settings getSettings()</dt>

            <dd>See <a href="#constrainable-interface">ConstrainablePattern
            Interface</a> for the definition of this method. </dd>

            <dt>void applyConstraints()</dt>

            <dd> <dl class="parameters">
                <dt>MediaTrackConstraints constraints</dt>

                <dd>A new constraint structure to apply to this object.</dd>

                <dt>VoidFunction successCallback</dt>

                <dd>Called if the required constraints can be satisfied.</dd>

                <dt>ConstraintErrorCallback errorCallback</dt>

                <dd>Called if the required constraints cannot be
                satisfied.</dd>
              </dl> See <a
            href="#constrainable-interface">ConstrainablePattern Interface</a>
            for the definition of this method.</dd>

            <dt>attribute EventHandler onoverconstrained</dt>

            <dd>
              <p>See <a href="#constrainable-interface">ConstrainablePattern
              Interface</a> for the definition of this event handler.</p>
            </dd>
          </dl>

          <dl class="idl" title="enum MediaStreamTrackState">
            <dt>live</dt>

            <dd>
              <p>The track is active (the track's underlying media source is
              making a best-effort attempt to provide data in real time).</p>

              <p>The output of a track in the <code>live</code> state can be
              switched on and off with the <code>
                  <a href="#dom-mediastreamtrack-enabled">enabled</a>
                </code> attribute.</p>
            </dd>

            <dt>ended</dt>

            <dd>
              <p>The track has <a href="#track-ended">ended</a> (the track's
              underlying media source is no longer providing data, and will
              never provide more data for this track). Once a track enters
              this state, it never exits it.</p>

              <p>For example, a video track in a <code>
                  <a>MediaStream</a>
                </code> ends if the user unplugs the USB web camera that acts
              as the track's media source.</p>
            </dd>
          </dl>
        </section>

        <section>
          <h2>Track Source Types</h2>

          <dl class="idl" title="enum SourceTypeEnum">
            <dt>camera</dt>

            <dd>A valid source type only for video <code>
                <a>MediaStreamTrack</a>
              </code>s. The source is a local video-producing camera
            source.</dd>

            <dt>microphone</dt>

            <dd>A valid source type only for audio <code>
                <a>MediaStreamTrack</a>
              </code>s. The source is a local audio-producing microphone
            source.</dd>
          </dl>
        </section>

        <section id="media-track-constraints">
          <h2>MediaTrackConstraints</h2>

          <dl class="idl"
              title="dictionary MediaTrackConstraints : MediaTrackConstraintSet">
            <dt>sequence&lt;MediaTrackConstraintSet&gt; advanced</dt>

            <dd>See <a href="#constraints">Constraints and ConstraintSet</a>
            for the definition of this element.</dd>
          </dl>

          <dl class="idl" title="dictionary MediaTrackConstraintSet">
            <dt>ConstrainLong width</dt>

            <dd />

            <dt>ConstrainLong height</dt>

            <dd />

            <dt>ConstrainDouble aspectRatio</dt>

            <dd />

            <dt>ConstrainDouble frameRate</dt>

            <dd />

            <dt>ConstrainDouble volume</dt>

            <dd />

            <dt>ConstrainLong sampleRate</dt>

            <dd />

            <dt>ConstrainLong sampleSize</dt>

            <dd />

            <dt>boolean echoCancellation</dt>

            <dd />

            <dt>ConstrainDOMString sourceId</dt>

            <dd />

            <dt>DOMString groupId</dt>

            <dd />
          </dl>
        </section>
      </section>

      <section>
        <h3>MediaStreamTrackEvent</h3>

        <p>The <code>
            <a href="#event-mediastream-addtrack">addtrack</a>
          </code> and <code title="event-MediaStreamTracklist-removetrack">
            <a href="#event-mediastream-removetrack">removetrack</a>
          </code> events use the <code>
            <a>MediaStreamTrackEvent</a>
          </code> interface.</p>

        <p><dfn title="Fire a track event">Firing a track event named
        <var>e</var></dfn> with a <code>
            <a>MediaStreamTrack</a>
          </code> <var>track</var> means that an event with the name
        <var>e</var>, which does not bubble (except where otherwise stated)
        and is not cancelable (except where otherwise stated), and which uses
        the <code>
            <a>MediaStreamTrackEvent</a>
          </code> interface with the <code>
            <a href="#dom-mediastreamtrackevent-track">track</a>
          </code> attribute set to <var>track</var>, MUST be created and
        dispatched at the given target.</p>

        <dl class="idl" data-merge="MediaStreamTrackEventInit"
            title="interface MediaStreamTrackEvent : Event">
          <dt>Constructor(DOMString type, MediaStreamTrackEventInit
          eventInitDict)</dt>

          <dd>
            <p>Constructs a new <code>
                <a>MediaStreamTrackEvent</a>
              </code>.</p>
          </dd>

          <dt>readonly attribute MediaStreamTrack track</dt>

          <dd>
            <p>The <dfn id="dom-mediastreamtrackevent-track">
                <code>track</code>
              </dfn> attribute represents the <code>
                <a>MediaStreamTrack</a>
              </code> object associated with the event.</p>
          </dd>
        </dl>

        <dl class="idl"
            title="dictionary MediaStreamTrackEventInit : EventInit">
          <dt>MediaStreamTrack track</dt>
        </dl>
      </section>
    </section>

    <section class="informative">
      <h2>The model: sources, sinks, constraints, and settings</h2>

      <p>Browsers provide a media pipeline from sources to sinks. In a
      browser, sinks are the &lt;img&gt;, &lt;video&gt; and &lt;audio&gt;
      tags. Traditional sources include streamed content, files, and web
      resources. The media produced by these sources typically does not change
      over time - these sources can be considered to be static.</p>

      <p>The sinks that display these sources to the user (the actual tags
      themselves) have a variety of controls for manipulating the source
      content. For example, an &lt;img&gt; tag scales down a huge source image
      of 1600x1200 pixels to fit in a rectangle defined with
      <code>width="400"</code> and <code>height="300"</code>.</p>

      <p>The getUserMedia API adds dynamic sources such as microphones and
      cameras - the characteristics of these sources can change in response to
      application needs. These sources can be considered to be dynamic in
      nature. A &lt;video&gt; element that displays media from a dynamic
      source can either perform scaling or it can feed back information along
      the media pipeline and have the source produce content more suitable for
      display.</p>

      <div class="note">
        <p><strong>Note:</strong> This sort of feedback loop is obviously just
        enabling an "optimization", but it's a non-trivial gain. This
        optimization can save battery, allow for less network congestion,
        etc...</p>
      </div>

      <p>Note that <code>MediaStream</code> sinks (such as
      <code>&lt;video&gt;</code>, <code>&lt;audio&gt;</code>, and even
      <code>RTCPeerConnection</code>) will continue to have mechanisms to
      further transform the source stream beyond that which the
      <a>Settings</a>, <a>Capabilities</a>, and <a>Constraints</a> described
      in this specification offer. (The sink transformation options, including
      those of <code>RTCPeerConnection</code>, are outside the scope of this
      specification.)</p>

      <p>The act of changing or applying a track constraint may affect the
      <code>
          <a>settings</a>
        </code> of all tracks sharing that source and consequently all
      down-level sinks that are using that source. Many sinks may be able to
      take these changes in stride, such as the <code>&lt;video&gt;</code>
      element or <code>RTCPeerConnection</code>. Others like the Recorder API
      may fail as a result of a source setting change.</p>

      <p>The <code>RTCPeerConnection</code> is an interesting object because
      it acts simultaneously as both a sink <strong>and</strong> a source for
      over-the-network streams. As a sink, it has source transformational
      capabilities (e.g., lowering bit-rates, scaling-up or down resolutions,
      adjusting frame-rates), and as a source it could have its own settings
      changed by a track source (though in this specification sources with the
      <code>
          <a>remote</a>
        </code> attribute set to true do not consider the current constraints
      applied to a track).</p>

      <p>To illustrate how changes to a given source impact various sinks,
      consider the following example. This example only uses width and height,
      but the same principles apply to any of the <a>Settings</a> exposed in
      this specification. In the first figure a home client has obtained a
      video source from its local video camera. The source's width and height
      settings are 800 pixels by 600 pixels, respectively. Three <code>
          <a>MediaStream</a>
        </code> objects on the home client contain tracks that use this same
      <code>
          <a>sourceId</a>
        </code>. The three media streams are connected to three different
      sinks: a <code>&lt;video&gt;</code> element (A), another
      <code>&lt;video&gt;</code> element (B), and a peer connection (C). The
      peer connection is streaming the source video to an away client. On the
      away client there are two media streams with tracks that use the peer
      connection as a source. These two media streams are connected to two
      <code>&lt;video&gt;</code> element sinks (Y and Z).</p>

      <img alt="Changing media stream source effects: before the requested change"
           src="images/change_states_before.png" />

      <p>Note that at this moment, all of the sinks on the home client must
      apply a transformation to the original source's provided dimension
      settings. A is scaling the video up (resulting in loss of quality), B is
      scaling the video down, and C is also scaling the video up slightly for
      sending over the network. On the away client, sink Y is scaling the
      video way down, while sink Z is not applying any scaling.</p>

      <p>Using the <a>ConstrainablePattern</a> interface, one of the tracks
      requests a higher resolution (1920 by 1200 pixels) from the home
      client's video source.</p>

      <img alt="Changing media stream source     effects: after the requested change"
           src="images/change_states_after.png" />

      <p>Note that the source change immediately affects all of the tracks and
      sinks on the home client, but does not impact any of the sinks (or
      sources) on the away client. With the increase in the home client source
      video's dimensions, sink A no longer has to perform any scaling, while
      sink B must scale down even further than before. Sink C (the peer
      connection) must now scale down the video in order to keep the
      transmission constant to the away client.</p>

      <p>While not shown, an equally valid settings change request could be
      made of the away client video source (the peer connection on the away
      client's side). This would not only impact sink Y and Z in the same
      manner as before, but could lead to re-negotiation with the peer
      connection on the home client in order to alter the transformation that
      it is applying to the home client's video source. Such a change is NOT
      REQUIRED to change anything related to sink A or B or the home client's
      video source.</p>

      <p>Note that this specification does not define a mechanism by which a
      change to the away client's video source could automatically trigger a
      change to the home client's video source. Implementations may choose to
      make such source-to-sink optimizations as long as they only do so within
      the constraints established by the application, as the next example
      demonstrates.</p>

      <p>It is fairly obvious that changes to a given source will impact sink
      consumers. However, in some situations changes to a given sink may also
      be cause for implementations to adjust a source's settings. This is
      illustrated in the following figures. In the first figure below, the
      home client's video source is sending a video stream sized at 1920 by
      1200 pixels. The video source is also unconstrained, such that the exact
      source dimensions are flexible as far as the application is concerned.
      Two <code>
          <a>MediaStream</a>
        </code> objects contain tracks with the same <code>
          <a>sourceId</a>
        </code>, and those <code>
          <a>MediaStream</a>
        </code>s are connected to two different <code>&lt;video&gt;</code>
      element sinks A and B. Sink A has been sized to
      <code>width="1920"</code> and <code>height="1200"</code> and is
      displaying the source's video content without any transformations. Sink
      B has been sized smaller and, as a result, is scaling the video down to
      fit its rectangle of 320 pixels across by 200 pixels down.</p>

      <img alt="Changing media stream sinks may affect sources: before the requested change"
           src="images/change_states_before2.png" />

      <p>When the application changes sink A to a smaller dimension (from 1920
      to 1024 pixels wide and from 1200 to 768 pixels tall), the browser's
      media pipeline may recognize that none of its sinks require the higher
      source resolution, and needless work is being done both on the part of
      the source and on sink A. In such a case and without any other
      constraints forcing the source to continue producing the higher
      resolution video, the media pipeline MAY change the source
      resolution:</p>

      <img alt="Changing media stream sinks may affect sources: after the requested change"
           src="images/change_states_after2.png" />

      <p>In the above figure, the home client's video source resolution was
      changed to the greater of that from sinkA and from sinkB in order to
      optimize playback. While not shown above, the same behavior could apply
      to peer connections and other sinks.</p>

      <p>It is possible that <a>constraints</a> can be applied to a track
      which a source is unable to satisfy, either because the source itself
      cannot satisfy the constraint or because the source is already
      satisfying a conflicting constraint. When this happens, the <code>
          <a>applyConstraints()</a>
        </code> call will fail and call the user-provided
      <a>ConstraintErrorCallback</a>, without applying any of the new
      constraints. Since no change in constraints occurs in this case, there
      is also no required change to the source itself as a result of this
      condition. Here is an example of this behavior.</p>

      <p>In this example, two media streams each have a video track that share
      the same source. The first track initially has no constraints applied.
      It is connected to sink N. Sink N has a width and height of 800 by 600
      pixels and is scaling down the source's resolution of 1024 by 768 to
      fit. The other track has a mandatory constraint forcing off the source's
      fill light; it is connected to sink P. Sink P has a width and height
      equal to that of the source.</p>

      <p>
        <img alt="Overconstrained application"
             src="images/overconstrained_apply.png" />
      </p>

      <p>Now, the first track adds a mandatory constraint that the fill light
      should be forced on. At this point, both mandatory constraints cannot be
      satisfied by the source (the fill light cannot be simultaneously on and
      off at the same time). Since this state was caused by the first track's
      attempt to apply a conflicting constraint, the constraint application
      fails and there is no change in the source's settings or the constraints
      on either track.</p>

      <p>Let's look at a slightly different situation starting from the same
      point. In this case, instead of the first track attempting to apply a
      conflicting constraint, the user physically locks the camera into a mode
      where the fill light is on. At this point the source can no longer
      satisfy the second track's mandatory constraint that the fill light be
      off. The second track is transitioned into the muted state and receives
      an <a>overconstrained</a> event. At the same time, the source notes that
      its remaining active sink only requires a resolution of 800 by 600 and
      so it adjusts its resolution down to match (this is an optional
      optimization that the user agent is allowed to make given the
      situation).</p>

      <p>
        <img alt="Overconstrained occurrence"
             src="images/overconstrained_occurrence.png" />
      </p>

      <p>At this point, it is the responsibility of the application to address
      the problem that led to the overconstrained situation, perhaps by
      removing the fill light mandatory constraint on the second track or by
      closing the second track altogether and informing the user</p>
    </section>

    <section>
      <h2>MediaStreams as Media Elements</h2>

      <p>A <code>MediaStream</code> may be assigned to media elements as
      defined in <a
      href="http://www.w3.org/TR/html5/embedded-content-0.html#media-elements">HTML5</a>
      [[HTML5]] A <code>MediaStream</code> is not preloadable or seekable and
      represents a simple, potentially infinite, linear media timeline. The
      timeline starts at 0 and increments linearly in real time as long as the
      <code>MediaStream</code> is playing. The timeline does not increment
      when the <code>MediaStream</code> is paused.</p>

      <section>
        <h3>Direct Assignment to Media Elements</h3>

        <p>UAs that support this specification MUST support the following
        partial interface, which allows a MediaStream to be assigned directly
        to a media element.</p>

        <dl class="idl" title="partial interface HTMLMediaElement">
          <dt>attribute MediaStream? srcObject</dt>

          <dd>
            <p>Holds the MediaStream that provides media for this element.
            This attribute overrides both the <code>src</code> attribute and
            any &lt;source&gt; elements. Specifically, if
            <code>srcObject</code> is specified, the UA MUST use it as the
            source of media, even if the <code>src</code> attribute is also
            set or &lt;source&gt; children are present. If the value of
            <code>srcObject</code> is replaced or set to null the UA MUST
            re-run the <a
            href="http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
            media element load algorithm</a></p>
          </dd>
        </dl>

        <p class="issue">We may want to allow direct assignment of other types
        as well</p>
      </section>

      <section>
        <h3>Loading and Playing a MediaStream in a Media Element</h3>

        <p>The UA runs the <a
        href="http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
        media element load algorithm</a> to obtain media for the media element
        to display. As defined in the [[HTML5]] specification, this algorithm
        has two basic phases: <a
        href="http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-algorithm">
        resource selection algorithm</a> chooses the resource to play and
        resolves its URI. Then the <a
        href="http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-resource">
        resource fetch phase</a> loads the resource. Both these phases are
        potentially simplified when using a MediaStream. First of all,
        <code>srcObject</code> takes priority over other means of specifying
        the resource, and it provides the object itself rather than a URI.
        Therefore, there is no need to run the resource selection algorithm.
        Secondly, when the UA reaches the resource fetch algorithm with a
        MediaStream, the MediaStream is a local object so there's nothing to
        fetch. Therefore, the following modifications/restrictions to the <a
        href="http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
        media element load algorithm</a> apply:</p>

        <ul>
          <li>
            <p>Whenever the user agent runs the <a
            href="http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
            media element load algorithm</a>, if <code>srcObject</code> is
            specified, the UA must immediately go to the <a
            href="http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-resource">
            resource fetch phase</a> of the algorithm.</p>
          </li>

          <li>
            <p>Whenever the user agent runs the <a
            href="http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
            media element load algorithm</a>, reaches the <a
            href="http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-resource">
            resource fetch phase</a> of this algorithm, and determines that
            the media resource in question is a MediaStream, it MUST
            immediately abort the <a
            href="http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-algorithm">
            resource selection algorithm</a>, setting the <a
                href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-readystate">
                <code>media.readyState</code>
              </a> to HAVE_NOTHING if media is not yet available and to
            HAVE_ENOUGH_DATA once it is.</p>
          </li>

          <li>
            <p>For each <code>
                <a>MediaStreamTrack</a>
              </code> in the <code>
                <a>MediaStream</a>
              </code>, including those that are added after the UA enters the
            <a
            href="http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
            media element load algorithm</a>, the UA MUST create a
            corresponding <code>
                <a
                href="http://www.w3.org/TR/html5/embedded-content-0.html#audiotrack">AudioTrack</a>
              </code> or <code>
                <a
                href="http://www.w3.org/TR/html5/embedded-content-0.html#videotrack">VideoTrack</a>
              </code> as defined in [[HTML5]]. Since the order in the <code>
                <a>MediaStream</a>
              </code>'s <a href="#track-set">track set</a> is undefined, no
            requirements are put how the <code>
                <a
                href="http://www.w3.org/TR/html5/embedded-content-0.html#audiotracklist">AudioTrackList</a>
              </code> and <code>
                <a
                href="http://www.w3.org/TR/html5/embedded-content-0.html#videotracklist">VideoTrackList</a>
              </code> are ordered.</p>

            <p>The properties of the <code>AudioTrack</code> and
            <code>VideoTrack</code> objects MUST be initialized as follows.
            Let</p>

            <ul>
              <li>
                <p><code>AudioTrack.id</code> and <code>VideoTrack.id</code>
                have the value of the corresponding <code>
                    <a href="#dom-mediastreamtrack-id">MediaStreamTrack.id</a>
                  </code> attribute</p>
              </li>

              <li>
                <p><code>AudioTrack.kind</code> and
                <code>VideoTrack.kind</code> be <code>"main"</code></p>
              </li>

              <li>
                <p><code>AudioTrack.label</code> and
                <code>VideoTrack.label</code> have the value of the
                corresponding <code>
                    <a
                    href="#dom-mediastreamtrack-label">MediaStreamTrack.label</a>
                  </code> attribute</p>
              </li>

              <li>
                <p><code>AudioTrack.language</code> and
                <code>VideoTrack.language</code> be the empty string</p>
              </li>
            </ul>

            <p>Let the media resource, represented by the <code>
                <a>MediaStream</a>
              </code> object, indicate to the <a
            href="http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
            media element load algorithm</a> that all audio tracks and all
            live video tracks (represented by a <code>
                <a>MediaStreamTrack</a>
              </code> with the <code>
                <a>readyState</a>
              </code> attribute set to <code>live</code>) should be enabled.
            This allows the media element load algorithm to set
            <code>AudioTrack.enabled</code>, <code>VideoTrack.selected</code>
            and <code>VideoTrackList.selectedIndex</code> accordingly.</p>

            <p>(Note that since the MediaStream is potentially endless, the UA
            does not exit the <a
            href="http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
            media element load algorithm</a> until the MediaStream moves from
            the active to the <a href="#stream-inactive">inactive</a>
            state.)</p>
          </li>

          <li>
            <p>If a <code>
                <a>MediaStreamTrack</a>
              </code> is removed from a <code>
                <a>MediaStream</a>
              </code>, played by a media element, the corresponding
            <code>AudioTrack</code> or <code>VideoTrack</code> MUST be removed
            as well.</p>
          </li>

          <li>
            <p>The UA MUST NOT buffer data from a MediaStream. When playing,
            the UA MUST always play the current data from the stream.</p>
          </li>

          <li>
            <p>When the MediaStream is moves from the active to the <a
            href="#stream-inactive">inactive</a> state, the UA MUST raise an
            <a
            href="http://www.w3.org/TR/html5/embedded-content-0.html#event-media-ended">
            ended</a> event on the media element and set its <a
            href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-ended">ended</a>
            attribute to <code>true</code>. Note that once <a
            href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-ended">ended</a>
            equals <code>true</code> the media element will not play media
            even if new Tracks are added to the MediaStream (causing it to
            return to the active state) unless <code>autoplay</code> is
            <code>true</code> or the JavaScript restarts the element, e.g., by
            calling <a
            href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-play">play()</a>.</p>
          </li>
        </ul>
      </section>

      <section>
        <h3>Media Element Attributes when Playing a MediaStream</h3>

        <p>The nature of the <code>MediaStream</code> places certain
        restrictions on the behavior and attribute values of the associated
        media element and on the operations that can be performed on it, as
        shown below:</p>

        <table class="simple">
          <caption> Legal values for the properties of a media element bound
          to a MediaStream </caption>

          <thead>
            <tr>
              <th scope="col">Attribute Name</th>

              <th scope="col">Attribute Type</th>

              <th scope="col">Valid Values When Using a MediaStream</th>

              <th scope="col">Additional considerations</th>
            </tr>
          </thead>

          <tbody>
            <tr>
              <td>
                <a class="externalDFN"
                   href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-currentsrc">
                  <code>currentSrc</code>
                </a>
              </td>

              <td>
                <code>DOMString</code>
              </td>

              <td>the empty string</td>

              <td>When <code>srcObject</code> is specified the UA MUST set
              this to the empty string.</td>
            </tr>

            <tr>
              <td>
                <a class="externalDFN"
                   href="http://www.w3.org/TR/html5/embedded-content-0.html#attr-media-preload">
                  <code>preload</code>
                </a>
              </td>

              <td>
                <code>DOMString</code>
              </td>

              <td>
                <code>none</code>
              </td>

              <td>A MediaStream cannot be preloaded.</td>
            </tr>

            <tr>
              <td>
                <a class="externalDFN"
                   href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-buffered">
                  <code>buffered</code>
                </a>
              </td>

              <td>
                <a class="externalDFN"
                   href="http://www.w3.org/TR/html5/embedded-content-0.html#timeranges">
                  <code>TimeRanges</code>
                </a>
              </td>

              <td><code>buffered.length</code> MUST return
              <code>0</code>.</td>

              <td>A MediaStream cannot be preloaded. Therefore, the amount
              buffered is always an empty TimeRange.</td>
            </tr>

            <tr>
              <td>
                <a class="externalDFN"
                   href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-networkstate">
                  <code>networkState</code>
                </a>
              </td>

              <td>
                <code>unsigned short</code>
              </td>

              <td>NETWORK_IDLE</td>

              <td>The media element does not fetch the MediaStream so there is
              no network traffic.</td>
            </tr>

            <tr>
              <td>
                <a class="externalDFN"
                   href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-readystate">
                  <code>readyState</code>
                </a>
              </td>

              <td>
                <code>unsigned short</code>
              </td>

              <td>HAVE_NOTHING, HAVE_ENOUGH_DATA</td>

              <td>A <code>
                  <a>MediaStream</a>
                </code> may be created before there is any data available, for
              example when a stream is received from a remote peer. The value
              of the <code>readyState</code> of the media element MUST be
              HAVE_NOTHING before the first media arrives and HAVE_ENOUGH_DATA
              once the first media has arrived.</td>
            </tr>

            <tr>
              <td>
                <a class="externalDFN"
                   href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-currenttime">
                  <code>currentTime</code>
                </a>
              </td>

              <td>
                <code>double</code>
              </td>

              <td>Any positive integer. The initial value is 0 and the values
              increments linearly in real time whenever the stream is
              playing.</td>

              <td>The value is the current stream position, in seconds. On any
              attempt to set this attribute, the user agent must throw an
              <code>InvalidStateError</code> exception.</td>
            </tr>

            <tr>
              <td>
                <a class="externalDFN"
                   href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-duration">
                  <code>duration</code>
                </a>
              </td>

              <td>
                <code>unrestricted double</code>
              </td>

              <td>Infinity</td>

              <td>A MediaStream does not have a pre-defined duration.</td>
            </tr>

            <tr>
              <td>
                <a class="externalDFN"
                   href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-seeking">
                  <code>seeking</code>
                </a>
              </td>

              <td>
                <code>boolean</code>
              </td>

              <td>false</td>

              <td>A MediaStream is not seekable. Therefore, this attribute
              MUST always have the value <code>false</code>.</td>
            </tr>

            <tr>
              <td>
                <a class="externalDFN"
                   href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-defaultplaybackrate">
                  <code>defaultPlaybackRate</code>
                </a>
              </td>

              <td>
                <code>double</code>
              </td>

              <td>1.0</td>

              <td>A MediaStream is not seekable. Therefore, this attribute
              MUST always have the value <code>1.0</code> and any attempt to
              alter it MUST fail.</td>
            </tr>

            <tr>
              <td>
                <a class="externalDFN"
                   href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-playbackrate">
                  <code>playbackRate</code>
                </a>
              </td>

              <td>
                <code>double</code>
              </td>

              <td>1.0</td>

              <td>A MediaStream is not seekable. Therefore, this attribute
              MUST always have the value <code>1.0</code> and any attempt to
              alter it MUST fail.</td>
            </tr>

            <tr>
              <td>
                <a class="externalDFN"
                   href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-played">
                  <code>played</code>
                </a>
              </td>

              <td>
                <a class="externalDFN"
                   href="http://www.w3.org/TR/html5/embedded-content-0.html#timeranges">
                  <code>TimeRanges</code>
                </a>
              </td>

              <td> <code>played.length</code> MUST return
              <code>1</code>.<br /> <code>played.start(0)</code> MUST return
              <code>0</code>.<br /> <code>played.end(0)</code> MUST return the
              last known <a class="externalDFN"
                  href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-currenttime">
                  <code>currentTime</code>
                </a>. </td>

              <td>A MediaStream's timeline always consists of a single range,
              starting at 0 and extending up to the currentTime.</td>
            </tr>

            <tr>
              <td>
                <a class="externalDFN"
                   href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-seekable">
                  <code>seekable</code>
                </a>
              </td>

              <td>
                <a class="externalDFN"
                   href="http://www.w3.org/TR/html5/embedded-content-0.html#timeranges">
                  <code>TimeRanges</code>
                </a>
              </td>

              <td> <code>seekable.length</code> MUST return <code>0</code>.
              </td>

              <td>A MediaStream is not seekable.</td>
            </tr>

            <tr>
              <td>
                <a class="externalDFN"
                   href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-startdate">
                  <code>startDate</code>
                </a>
              </td>

              <td>
                <code>Date</code>
              </td>

              <td>Not-a-Number (NaN)</td>

              <td>A MediaStream does not specify a timeline offset.</td>
            </tr>

            <tr>
              <td>
                <a class="externalDFN"
                   href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-loop">
                  <code>loop</code>
                </a>
              </td>

              <td>
                <code>boolean</code>
              </td>

              <td>true, false</td>

              <td>Setting the <code>loop</code> attribute has no effect since
              a <code>
                  <a>MediaStream</a>
                </code> has no defined end and therefore cannot be
              looped.</td>
            </tr>
          </tbody>
        </table>
      </section>
    </section>

    <section>
      <h2>Error Handling</h2>

      <section>
        <h3>MediaStreamError</h3>
        <p>All errors defined in this specification implement the following
          interface:</p>

        <dl class="idl" title="[NoInterfaceObject] interface MediaStreamError">
          <dt>readonly attribute DOMString name</dt>

          <dd>
            <p>The name of the error</p>
          </dd>

          <dt>readonly attribute DOMString? message</dt>

          <dd>A UA-dependent string offering extra human-readable information
            about the error.</dd>

          <dt>readonly attribute DOMString? constraintName</dt>

          <dd>
            <p>This attribute is only used for some types of errors. For <code>
                <a>MediaStreamError</a>
              </code> with a name of <code>ConstraintNotSatisfiedError</code> or of <code>OverconstrainedError</code>,
              this attribute MUST be set to the name of the constraint that caused
              the error.</p>
          </dd>
        </dl>

        <div class="note">We may make MediaStreamError inherit from
          DOMError once the definition of DOMError is stable. </div>

        <div class="issue">Do we want to allow the constraintName
          attribute to contain multiple constraint names? In many cases the error
          is raised as soon as a single unsatisfied mandatory constraint is found,
          but in others it may be possible to determine that multiple constraints
          are not satisfied. </div>

        <p>The following interface is defined for cases when a MediaStreamError
          is raised as an event:</p>

        <dl class="idl" data-merge="MediaStreamErrorEventInit"
            title="interface MediaStreamErrorEvent : Event">
          <dt>Constructor(DOMString type, MediaStreamErrorEventInit
            eventInitDict)</dt>

          <dd>TODO</dd>

          <dt>readonly attribute MediaStreamError error</dt>

          <dd>TODO</dd>
        </dl>

        <dl class="idl" title="dictionary MediaStreamErrorEventInit : EventInit">
          <dt>MediaStreamError error</dt>

          <dd>
            <p>TODO</p>
          </dd>
        </dl>
      </section>
      <section>
        <h3>Error names</h3>
        <p>The table below lists the error names defined in this specification.</p>
        <table>
          <caption><code><a>MediaStreamError</a></code> names</caption>
          <thead>
            <tr>
              <th>Name</th>
              <th>Description</th>
              <th>Note</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <th><code><dfn>NotSupportedError</dfn></code></th>
              <td>The operation is not supported.</td>
              <td>Same as defined in [[DOM4]]</td>
            </tr>
            <tr>
              <th><code><dfn>PermissionDeniedError</dfn></code></th>
              <td>The user did not grant permission for the operation.</td>
              <td></td>
            </tr>
            <tr>
              <th><code><dfn>ConstraintNotSatisfiedError</dfn></code></th>
              <td>One of the mandatory <a>Constraints</a> could not be satisfied.</td>
              <td>The <code>constraintName</code> attribute gets set to the name of the constraint that caused the error</td>
            </tr>
            <tr>
              <th><code><dfn>OverconstrainedError</dfn></code></th>
              <td>Due to changes in the environment, one or more mandatory constraints can no longer be satisfied..</td>
              <td>The <code>constraintName</code> attribute gets set to the name of the constraint that caused the error</td>
            </tr>
            <tr>
              <th><code><dfn>NotFoundError</dfn></code></th>
              <td>The object can not be found here.</td>
              <td>Same as defined in [[DOM4]]</td>
            </tr>
            <tr>
              <th><code><dfn>AbortError</dfn></code></th>
              <td>The operation was aborted.</td>
              <td>Same as defined in [[DOM4]]</td>
            </tr>
            <tr>
              <th><code><dfn>SourceUnavailableError</dfn></code></th>
              <td>The source of the MediaStream could not be accessed due to a hardware error (e.g. lock from another process).</td>
              <td></td>
            </tr>
          </tbody>
        </table>
      </section>
    </section>

    <section class="informative">
      <h2>Event summary</h2>

      <p>The following event fires on <code>
          <a>MediaStream</a>
        </code> objects:</p>

      <table>
        <tr>
          <th>Event name</th>

          <th>Interface</th>

          <th>Fired when...</th>
        </tr>

        <tbody>
          <tr>
            <td>
              <dfn id="event-mediastream-active">
                <code>active</code>
              </dfn>
            </td>

            <td>
              <code>Event</code>
            </td>

            <td> The <code>
                <a>MediaStream</a>
              </code> became active (see <a
            href="#stream-inactive">inactive</a>). </td>
          </tr>

          <tr>
            <td>
              <dfn id="event-mediastream-inactive">
                <code>inactive</code>
              </dfn>
            </td>

            <td>
              <code>Event</code>
            </td>

            <td> The <code>
                <a>MediaStream</a>
              </code> became <a href="#stream-inactive">inactive</a>. </td>
          </tr>

          <tr>
            <td>
              <dfn id="event-mediastream-addtrack">
                <code>addtrack</code>
              </dfn>
            </td>

            <td>
              <code>
                <a>MediaStreamTrackEvent</a>
              </code>
            </td>

            <td>A new <code>
                <a>MediaStreamTrack</a>
              </code> has been added to this stream. Note that this event is
            not fired when the script directly modifies the tracks of a <code>
                <a>MediaStream</a>
              </code>.</td>
          </tr>

          <tr>
            <td>
              <dfn id="event-mediastream-removetrack">
                <code>removetrack</code>
              </dfn>
            </td>

            <td>
              <code>
                <a>MediaStreamTrackEvent</a>
              </code>
            </td>

            <td>A <code>
                <a>MediaStreamTrack</a>
              </code> has been removed from this stream. Note that this event
            is not fired when the script directly modifies the tracks of a
            <code>
                <a>MediaStream</a>
              </code>.</td>
          </tr>
        </tbody>
      </table>

      <p>The following event fires on <code>
          <a>MediaStreamTrack</a>
        </code> objects:</p>

      <table>
        <tr>
          <th>Event name</th>

          <th>Interface</th>

          <th>Fired when...</th>
        </tr>

        <tbody>
          <tr>
            <td>
              <dfn id="event-mediastreamtrack-mute">
                <code>mute</code>
              </dfn>
            </td>

            <td>
              <code>Event</code>
            </td>

            <td>The <code>
                <a>MediaStreamTrack</a>
              </code> object's source is temporarily unable to provide
            data.</td>
          </tr>

          <tr>
            <td>
              <dfn id="event-mediastreamtrack-unmute">
                <code>unmute</code>
              </dfn>
            </td>

            <td>
              <code>Event</code>
            </td>

            <td>The <code>
                <a>MediaStreamTrack</a>
              </code> object's source is live again after having been
            temporarily unable to provide data.</td>
          </tr>

          <tr>
            <td>
              <dfn id="event-mediastreamtrack-overconstrained">
                <code>overconstrained</code>
              </dfn>
            </td>

            <td>
              <code>MediaStreamErrorEvent</code>
            </td>

            <td>
              <p>This error event fires asynchronously for each affected track
              (when multiple tracks share the same source) after the user
              agent has evaluated the current constraints against a given
              <code>
                  <a>sourceId</a>
                </code> and is not able to configure the source within the
              limitations established by the union of imposed constraints.</p>

              <p>Due to being over-constrained, the user agent must mute each
              affected track.</p>

              <p>The affected track(s) will remain <a
              href="#track-muted">muted</a> until the application adjusts the
              constraints to accommodate the source's capabilities.</p>
            </td>
          </tr>

          <tr>
            <td>
                <code id="event-mediastreamtrack-ended">ended</code>
            </td>

            <td>
              <code>Event</code>
            </td>

            <td>The <code>
                <a>MediaStreamTrack</a>
              </code> object's source will no longer provide any data, either
            because the user revoked the permissions, or because the source
            device has been ejected, or because the remote peer permanently
            stopped sending data.</td>
          </tr>
        </tbody>
      </table>

      <p>The following event fires on <code>
          <a>MediaDevices</a>
        </code> objects:</p>

      <table>
        <tr>
          <th>Event name</th>

          <th>Interface</th>

          <th>Fired when...</th>
        </tr>

        <tbody>
          <tr>
            <td>
              <dfn id="event-mediadevices-devicechange">
                <code>devicechange</code>
              </dfn>
            </td>

            <td>
              <code>Event</code>
            </td>

            <td>The set of media devices, available to the user agent, has
            changed. The current list devices can be retrieved with the <code>
                <a
                href="#dom-mediadevices-enumeratedevices">enumerateDevices()</a>
              </code> method.</td>
          </tr>
        </tbody>
      </table>
    </section>

    <section id="enumerating-devices">
      <h2>Enumerating Local Media Devices</h2>

      <p>This section describes an API that the script can use to query the
      user agent about connected media input and output devices (for example a
      web camera or a headset).</p>

      <section>
        <h3>NavigatorUserMedia</h3>

        <dl class="idl"
            title="[NoInterfaceObject] interface NavigatorUserMedia">
          <dt>readonly attribute MediaDevices mediaDevices</dt>

          <dd>
            <p>Returns the <code>MediaDevices</code> object associated with
            this <code>Navigator</code> object.</p>
          </dd>
        </dl>

        <div class="idl" title="Navigator implements NavigatorUserMedia" />
      </section>

      <section>
        <h3>MediaDevices</h3>

        <p>The <code>MediaDevices</code> object which is the entry point to
        the API used to examine and get access to media devices available to
        the user agent.</p>

        <p>When a new media input or output device is made available, the user
        agent MUST queue a task fires a simple event named <code>
            <a href="#event-mediadevices-devicechange">devicechange</a>
          </code> at the <code>
            <a>MediaDevices</a>
          </code> object.</p>

        <dl class="idl" title="interface MediaDevices : EventTarget">
          <dt>attribute EventHandler ondevicechange</dt>

          <dd>This event handler, of type <code>
              <a href="#event-mediadevices-devicechange">devicechange</a>
            </code>, MUST be supported by all objects implementing the <code>
              <a>MediaDevices</a>
            </code> interface.</dd>

          <dt>void enumerateDevices (MediaDeviceInfoCallback
          resultCallback)</dt>

          <dd>
            <p>Collects information about the user agents available media
            input and output devices. The method MUST only return information
            that the script is authorized to access (TODO expand
            authorized).</p>

            <p>When the <dfn id="dom-mediadevices-enumeratedevices">
                <code>enumerateDevices()</code>
              </dfn> method is called, the user agent must queue a task that
            runs the following steps:</p>

            <ol>
              <li>
                <p>Let <var>resultCallback</var> be the callback indicated by
                the methods first argument.</p>
              </li>

              <li>
                <p>If this method has been called previously within this
                application session, let <var>oldList</var> be the list of
                <code>
                    <a>MediaDeviceInfo</a>
                  </code> objects that was produced at that call
                (<var>resultList</var>); otherwise, let <var>oldList</var> be
                an empty list.</p>
              </li>

              <li>
                <p>Let <var>resultList</var> be an empty list.</p>
              </li>

              <li>
                <p>Probe the user agent for available media devices, and run
                the following sub steps for each discovered device,
                <var>device</var>:</p>

                <ol>
                  <li>
                    <p>If <var>device</var> is represented by a <code>
                        <a>MediaDeviceInfo</a>
                      </code> object in <var>oldList</var>, append that object
                    to <var>resultList</var>, abort these steps and continue
                    with the next device (if any).</p>
                  </li>

                  <li>
                    <p>Let <var>deviceInfo</var> be a new <code>
                        <a>MediaDeviceInfo</a>
                      </code> object to represent <var>device</var>.</p>
                  </li>

                  <li>
                    <p>If <var>device</var> belongs to the same physical
                    device as a device, already represented in
                    <var>oldList</var> or <var>resultList</var>, initialize
                    <var>deviceInfo</var>'s <code>
                        <a href="#widl-MediaDeviceInfo-groupId">groupId</a>
                      </code> member to the <code>
                        <a href="#widl-MediaDeviceInfo-groupId">groupId</a>
                      </code> value of the existing <code>
                        <a>MediaDeviceInfo</a>
                      </code> object. Otherwise, let <var>deviceInfo</var>'s
                    <code>
                        <a href="#widl-MediaDeviceInfo-groupId">groupId</a>
                      </code> member be a newly generated unique
                    identifier</p>
                  </li>

                  <li>
                    <p>Append <var>deviceInfo</var> to
                    <var>resultList</var>.</p>
                  </li>
                </ol>
              </li>

              <li>
                <p>Invoke <var>resultCallback</var> with <var>resultList</var>
                as its argument.</p>
              </li>
            </ol>
          </dd>
        </dl>
      </section>

      <section>
        <h2>Device Info</h2>

        <dl class="idl" title="callback MediaDeviceInfoCallback = void">
          <dt>sequence&lt;MediaDeviceInfo&gt; deviceInfoList</dt>

          <dd>A sequence of <code>
              <a>MediaDeviceInfo</a>
            </code> objects representing the result of a call to <code>
              <a
              href="#dom-mediadevices-enumeratedevices">MediaDevices.enumerateDevices()</a>
            </code> .</dd>
        </dl>

        <div class="note"> The old SourceInfo dictionary used to refer to the
        MediaSourceStates dictionary. That dictionary is no longer available
        when Constrainable is introduced. When Constrainable lands, we should
        see if we can align deviceId, kind and label, below, with the new
        definitions of source capabilities. </div>

        <dl class="idl" title="dictionary MediaDeviceInfo">
          <dt>DOMString deviceId</dt>

          <dd>
            <p>The unique id for the represented device.</p>
            <p>Devices have an identifier which <em class="rfc2119"
          title="must">must</em> be unique to the application (un-guessable by
          another application) and persistent between application sessions
          (e.g., the identifier for a given source device/application must
          stay the same, but not be guessable by another application). Sources
          that must have an identifier are camera and microphone sources;
          local file sources are not required to have an identifier. Source
          identifiers let the application save, identify the availability of,
          and directly request specific sources.</p>

          </dd>

          <dt>MediaDeviceKind kind</dt>

          <dd>
            <p>Describes the kind of the represented device.</p>
          </dd>

          <dt>DOMString label</dt>

          <dd>
            <p>A label describing this device (for example "External USB
            Webcam"). If the device has no associated label, then this
            dictionary member MUST return the empty string.</p>
          </dd>

          <dt>DOMString groupId</dt>

          <dd>
            <p>Returns the group identifier of the represented device. Two
            devices have the same group identifier if they belong to the same
            physical device; for example a headset.</p>
          </dd>
        </dl>

        <dl class="idl" title="enum MediaDeviceKind">
          <dt>audioinput</dt>

          <dd>
            <p>Represents an audio input device; for example a microphone.</p>
          </dd>

          <dt>audiooutput</dt>

          <dd>
            <p>Represents an audio output device; for example a pair of
            headphones.</p>
          </dd>

          <dt>videoinput</dt>

          <dd>
            <p>Represents a video input device; for example a webcam.</p>
          </dd>
        </dl>
      </section>
    </section>

    <section id="local-content">
      <h2>Obtaining local multimedia content</h2>

      <p>This section extends <code>
          <a>NavigatorUserMedia</a>
        </code> and <code>
          <a>MediaDevices</a>
        </code> with APIs to request permission to access media input devices
      available to the user agent.</p>

      <section>
        <h3>NavigatorUserMedia Interface Extensions</h3>

        <div class="note">This method is kept on <code>
            <a>NavigatorUserMedia</a>
          </code> for legacy purposes. See <a
        href="#dom-mediadevices-getusermedia">MediaDevices.getUserMedia()</a>.</div>

        <dl class="idl" title="partial interface NavigatorUserMedia">
          <dt>void getUserMedia(MediaStreamConstraints constraints,
          NavigatorUserMediaSuccessCallback successCallback,
          NavigatorUserMediaErrorCallback errorCallback)</dt>

          <dd>
            <p>See <a
            href="#dom-mediadevices-getusermedia">MediaDevices.getUserMedia()</a>.</p>
          </dd>
        </dl>
      </section>

      <section>
        <h3>MediaDevices Interface Extensions</h3>

        <p>The <code>getSupportedConstraints</code> method is provided to
        allow the application to determine which constraints the User Agent
        recognizes.</p>

        <dl class="idl" title="partial interface MediaDevices">
          <dt>static Dictionary getSupportedConstraints(DOMString kind)</dt>

          <dd>
            <p>Returns a dictionary whose members are the constraint keys
            known to the User Agent for the kind given as argument. A
            supported constraint MUST be represented by a member whose name is
            the constraint name and whose value is <code>true</code>. Any
            constraint names not supported by the User Agent MUST not be
            present in the returned dictionary.</p>
          </dd>

          <dt>void getUserMedia(MediaStreamConstraints constraints,
          NavigatorUserMediaSuccessCallback successCallback,
          NavigatorUserMediaErrorCallback errorCallback)</dt>

          <dd>
            <p>Prompts the user for permission to use their Web cam or other
            video or audio input.</p>

            <p class="issue">(Remove when other issues are removed. This is
            only here to keep the issues from being renumbered)</p>

            <p>The <var>constraints</var> argument is an object of type <code>
                <a>MediaStreamConstraints</a>
              </code>.</p>

            <p>The <var>successCallback</var> will be invoked with a suitable
            <code>
                <a>MediaStream</a>
              </code> object as its argument if the user accepts valid tracks
            as described below.</p>

            <p>The <var>errorCallback</var> will be invoked if there is a
            failure in finding valid tracks or if the user denies permission,
            both as described below.</p>

            <p>When the <dfn id="dom-mediadevices-getusermedia">
                <code>getUserMedia()</code>
              </dfn> method is called, the user agent MUST run the following
            steps:</p>

            <ol>
              <li>
                <p>Let <var>constraints</var> be the method's first
                argument.</p>
              </li>

              <li>
                <p>Let <var>successCallback</var> be the callback indicated by
                the method's second argument.</p>
              </li>

              <li>
                <p>Let <var>errorCallback</var> be the callback indicated by
                the method's third argument.</p>
              </li>

              <li>
                <p>Let <var>requestedMediaTypes</var> be the set of media
                types in <var>constraints</var> with either a dictionary value
                or a value of "true".</p>
              </li>

              <li>
                <p>If <var>requestedMediaTypes</var> is the empty set, let
                <var>error</var> be a new <code>
                    <a>MediaStreamError</a>
                  </code> object whose <code>
                    <a>name</a>
                  </code> attribute has the value
                <code>NotSupportedError</code> and jump to the step labeled
                <em>Error Task</em> below.</p>
              </li>

              <li>
                <p>Let <var>finalSet</var> be an (initially) empty set.</p>
              </li>

              <li>
                <p>If <var>successCallback</var> is null, abort these
                steps.</p>
              </li>

              <!-- we could throw an exception instead (that's
   why the method doesn't return until later: so that we can add an
   exception here, or for /options/ below, without changing the
   algorithm) -->

              <!--
            <li>
              <p>For each member of the <code><a>MediaStreamOptions</a></code>
              dictionary create a local representation and set it to false.</p>
            </li>

            <li>
              <p>For each property in <var>options</var> that is present and
              set to true, let the corresponding local representation be
              true.</p>
            </li>

            <li>
              <p>If none of the local representations of the
              <code><a>MediaStreamOptions</a></code> dictionary members is set
              to true, then throw a <code>NOT_SUPPORTED_ERR</code> exception
              and abort these steps.</p>
            </li>
-->

              <li>
                <p>For each media type <var>T</var> in
                <var>requestedMediaTypes</var>,</p>

                <ol>
                  <li>
                    <p>Let <var>candidateSet</var> be all possible tracks of
                    media type <var>T</var> that the browser could return.</p>
                  </li>

                  <li>
                   <p>If <var>candidateSet</var> is the empty set,
                   let <var>error</var> be a
                   new <code><a>MediaStreamError</a> </code> object
                   whose <code><a>name</a></code> attribute has the
                   value <code>NotFoundError</code> and jump to the
                   step labeled <em>Error Task</em> below.</p>
                  </li>

                  <li>If the value of the <var>T</var> entry of
                  <var>constraints</var> is "true", jump to the step labeled
                  <em>final</em> below. Otherwise, continue with <var>CS</var>
                  set to the value of the <var>T</var> entry of
                  <var>constraints</var>.</li>

                  <li>
                    <p>For each required ('min', 'max', or 'exact') constraint
                    provided for a constraint name in <var>CS</var>,</p>

                    <ol>
                      <li>
                        <p>If the constraint is not supported by the browser,
                        jump to the step labeled <em>Constraint Failure</em>
                        below.</p>
                      </li>

                      <li>
                        <p>Remove from the <var>candidateSet</var> any track
                        that cannot satisfy the value given for the constraint
                        in <var>CS</var>, if any.</p>
                      </li>

                      <li>
                        <p>If the <var>candidateSet</var> no longer contains
                        at least one track, jump to the step labeled
                        <em>Constraint Failure</em> below. Otherwise, continue
                        with the next required constraint.</p>
                      </li>
                    </ol>
                  </li>

                  <li>
                    <p>Let the <var>secondPassSet</var> be the current
                    contents of the <var>candidateSet</var>. Note that unknown
                    properties are discarded by WebIDL, which means that
                    unknown/unsupported required constraints will silently
                    disappear. To avoid this being a surprise, application
                    authors are expected to first use the
                    <code>getSupportedConstraints()</code> method as shown in
                    the Examples.</p>
                  </li>

                  <li>
                    <p>For each constraint key-value pair in the "advanced"
                    sequence of <var>CS</var>, in order,</p>

                    <ol>
                      <li>
                        <p>If the constraint is not supported by the browser,
                        skip it and continue with the next constraint.</p>
                      </li>

                      <li>
                        <p>Remove from the <var>secondPassSet</var> any tracks
                        that cannot satisfy the value given for the
                        constraint.</p>
                      </li>

                      <li>
                        <p>If the <var>secondPassSet</var> is now empty, let
                        the <var>secondPassSet</var> be the current contents
                        of the <var>candidateSet</var>. Otherwise, let the
                        <var>candidateSet</var> be the current contents of the
                        <var>secondPassSet</var>.</p>
                      </li>
                    </ol>
                  </li>

                  <li>
                    <p>Let the <var>thirdPassSet</var> be the current contents
                    of the <var>candidateSet</var>.</p>
                  </li>

                  <li>
                    <p>For all non-required ('ideal' or bare-value)
                    constraints in <var>CS</var>, identify the maximum number
                    of such constraint pairs that could be satisfied by at
                    least one track in <var>thirdPassSet</var>.</p>
                  </li>

                  <li>
                    <p>The decision of which of these non-required constraints
                    to satisfy is completely up to the user agent, as long as
                    the number of constraints satisfied matches the number in
                    the previous step.</p>
                  </li>

                  <li>
                    <p>For the non-required constraints the user agent has
                    decided to satisfy, remove from the
                    <var>thirdPassSet</var> any tracks that cannot satisfy
                    those constraints.</p>
                  </li>

                  <li>
                    <p>If the <var>thirdPassSet</var> is now empty, let the
                    <var>thirdPassSet</var> be the current contents of the
                    <var>candidateSet</var>. Otherwise, let the
                    <var>candidateSet</var> be the current contents of the
                    <var>thirdPassSet</var>.</p>
                  </li>

                  <li>
                    <p><em>Final:</em> Add the tracks in the
                    <var>candidateSet</var> to the <var>finalSet</var>.</p>
                  </li>
                </ol>
              </li>

              <li>
                <p>Return, and run the remaining steps asynchronously.</p>
              </li>

              <li>
                <p>Optionally, e.g., based on a previously-established user
                preference, for security reasons, or due to platform
                limitations, jump to the step labeled <em>Permission
                Failure</em> below.</p>
              </li>

              <li>
                <p>Prompt the user in a user agent specific manner for
                permission to provide the entry script's origin with a <code>
                    <a>MediaStream</a>
                  </code> object representing a media stream.</p>

                <p>The provided media MUST include precisely one track of each
                media type in requestedMediaTypes from the
                <var>finalSet</var>. The decision of which tracks to choose
                from the <var>finalSet</var> is completely up to the user
                agent and may be determined by asking the user. Once selected,
                the source of a <code>
                    <a>MediaStreamTrack</a>
                  </code> MUST not change.</p>

                <p class="issue">Define the event that should be raised when
                the user agent changes its choice of track.</p>

                <p>User agents are encouraged to default to using the user's
                primary or system default camera and/or microphone (when
                possible) to generate the media stream. User agents MAY allow
                users to use any media source, including pre-recorded media
                files.</p>

                <p>If the user grants permission to use local recording
                devices, user agents are encouraged to include a prominent
                indicator that the devices are "hot" (i.e. an "on-air" or
                "recording" indicator), as well as a "device accessible"
                indicator indicating that the page has been granted access to
                the source.</p>

                <p>If the user denies permission, jump to the step labeled
                <em>Permission Failure</em> below. If the user never responds,
                this algorithm stalls on this step.</p>

		<p>If the user grants permission but a hardware error
		such as an OS/program/webpage lock prevents access,
		jump to the step labeled <em>Unavailable Failure</em>
		below.</p>

		<p>If the user grants permission but device access
		fails for any reason other than those listed above,
		jump to the step labeled <em>General Failure</em>
		below.</p>
              </li>

              <li>
                <p>Let <var>stream</var> be the <code>
                    <a>MediaStream</a>
                  </code> object for which the user granted permission.</p>
              </li>

              <li>
                <p>Queue a task to invoke <var>successCallback</var> with
                <var>stream</var> as its argument.</p>
              </li>

              <li>
                <p>Abort these steps.</p>
              </li>

              <li>
                <p><em>Permission Failure</em>: Let <var>error</var> be a new
                <code>
                    <a>MediaStreamError</a>
                  </code> object whose <code>
                    <a>name</a>
                  </code> attribute has the value
                <code>PermissionDeniedError</code> and jump to the step
                labeled <em>Error Task</em> below.</p>
              </li>

              <li>
                <p><em>Constraint Failure</em>: Let <var>error</var> be a new
                <code>
                    <a>MediaStreamError</a>
                  </code> object whose <code>
                    <a>name</a>
                  </code> attribute has the value
                <code>ConstraintNotSatisfiedError</code> and whose <code>
                    <a
                    href="#widl-MediaStreamError-constraintName">constraintName</a>
                  </code> attribute is set to the name of the constraint that
                caused the error.</p>
              </li>

              <li>
                <p><em>Unavailable Failure</em>: Let <var>error</var> be a new
                <code>
                    <a>MediaStreamError</a>
                  </code> object whose <code>
                    <a>name</a>
                  </code> attribute has the value
                <code>SourceUnavailableError</code> and jump to the step
                labeled <em>Error Task</em> below.</p>
              </li>

              <li>
                <p><em>General Failure</em>: Let <var>error</var> be a new
                <code>
                    <a>MediaStreamError</a>
                  </code> object whose <code>
                    <a>name</a>
                  </code> attribute has the value
                <code>AbortError</code> and jump to the step
                labeled <em>Error Task</em> below.</p>
              </li>

              <li>
                <p><em>Error Task:</em> Queue a task to invoke
                <var>errorCallback</var> with <var>error</var> as its
                argument.</p>
              </li>

              <li style="list-style: none; display: inline">
                <p>The task source for these <span
                title="concept-task">tasks</span> is the user interaction task
                source.</p>
              </li>
            </ol>
          </dd>
        </dl>
      </section>

      <section>
        <h2>MediaStreamConstraints</h2>

        <p>The <code>MediaStreamConstraints</code> dictionary is used to
        instruct the UA what sort of <a>MediaStreamTrack</a>s to include in
        the <a>MediaStream</a> returned by <a>getUserMedia()</a>.</p>

        <dl class="idl" title="dictionary MediaStreamConstraints">
          <!--        <dt>boolean audio</dt>

        <dd>Set to true if an audio track is requested, default is false</dd>

        <dt>boolean video</dt>

        <dd>Set to true if a video track is requested, default is false</dd>
-->

          <dt>(boolean or MediaTrackConstraints) video = false</dt>

          <dd>
            <p>If <code>true</code>, it requests that the returned
            <a>MediaStream</a> contain a video track. If a <a>Constraints</a>
            structure is provided, it further specifies the nature and
            settings of the video Track. If <code>false</code>, the
            <a>MediaStream</a> MUST not contain a video Track.</p>
          </dd>

          <dt>(boolean or MediaTrackConstraints) audio = false</dt>

          <dd>
            <p>If <code>true</code>, it requests that the returned
            <a>MediaStream</a> contain an audio track. If a <a>Constraints</a>
            structure is provided, it further specifies the nature and
            settings of the audio Track. If <code>false</code>, the
            <a>MediaStream</a> MUST not contain an audio Track.</p>
          </dd>
        </dl>
      </section>

      <section>
        <h2>NavigatorUserMediaSuccessCallback</h2>

        <dl class="idl"
            title="callback NavigatorUserMediaSuccessCallback = void">
          <dt>MediaStream stream</dt>

          <dd>
            <p class="issue">Add explanation of handleEvent</p>
          </dd>
        </dl>
      </section>

      <section>
        <h2>NavigatorUserMediaErrorCallback</h2>

        <dl class="idl"
            title="callback NavigatorUserMediaErrorCallback = void">
          <dt>MediaStreamError error</dt>

          <dd>
            <p class="issue">Add explanation of handleEvent</p>
          </dd>
        </dl>
      </section>

      <section class="informative">
        <h2>Implementation Suggestions</h2>

        <div class="practice">
          <span class="practicelab" id="resource-reservation">Resource
          reservation</span>

          <p class="practicedesc">The user agent is encouraged to reserve
          resources when it has determined that a given call to <a
          href="#dom-mediadevices-getusermedia">getUserMedia()</a> will
          succeed. It is preferable to reserve the resource prior to invoking
          the success callback provided by the web page. Subsequent calls to
          <a href="#dom-mediadevices-getusermedia">getUserMedia()</a> (in this
          page or any other) should treat the resource that was previously
          allocated, as well as resources held by other applications, as busy.
          Resources marked as busy should not be provided as sources to the
          current web page, unless specified by the user. Optionally, the user
          agent may choose to provide a stream sourced from a busy source but
          only to a page whose origin matches the owner of the original stream
          that is keeping the source busy.</p>

          <p class="practicedesc">This document recommends that in the
          permission grant dialog or device selection interace (if one
          is present), the user be allowed to select any available
          hardware as a source for the stream requested by the page
          (provided the resource is able to fulfill mandatory
          constraints, if any were specified).  Although not
          specifically recommended as best practice, note that some
          user agents may support the ability to substitute a video or
          audio source with local files and other media. A file picker
          may be used to provide this functionality to the user.</p>

          <p class="practicedesc">This document also recommends that the user
          be shown all resources that are currently busy as a result of prior
          calls to <a href="#dom-mediadevices-getusermedia">getUserMedia()</a>
          (in this page or any other page that is still alive) and be allowed
          to terminate that stream and utilize the resource for the current
          page instead. If possible in the current operating environment, it
          is also suggested that resources currently held by other
          applications be presented and treated in the same manner. If the
          user chooses this option, the track corresponding to the resource
          that was provided to the page whose stream was affected must be
          removed.</p>
        </div>

        <div class="practice">
          <span class="practicelab" id="handling-devices">Handling multiple
          devices</span>

          <p class="practicedesc">A <a>MediaStream</a> may contain more than
          one video and audio track. This makes it possible to include video
          from two or more webcams in a single stream object, for example.
          However, the current API does not allow a page to express a need for
          multiple video streams from independent sources.</p>

          <p class="practicedesc">It is recommended for multiple calls to <a
          href="#dom-mediadevices-getusermedia">getUserMedia()</a> from the
          same page be allowed as a way for pages to request multiple,
          discrete, video or audio streams.</p>

          <p class="practicedesc">A single call to <a
          href="#dom-mediadevices-getusermedia">getUserMedia()</a> will always
          return a stream with either zero or one audio tracks, and either
          zero or one video tracks. If a script calls <a
          href="#dom-mediadevices-getusermedia">getUserMedia()</a> multiple
          times before reaching a stable state, this document advises the UI
          designer that the permission dialogs should be merged, so that the
          user can give permission for the use of multiple cameras and/or
          media sources in one dialog interaction. The constraints on each
          getUserMedia call can be used to decide which stream gets which
          media sources.</p>
        </div>
      </section>
    </section>

    <section id="constrainable-interface">
      <h2>Constrainable Pattern</h2>

      <p>The Constrainable pattern allows its consumers to inspect and adjust
      the properties of the object that implements it. It is broken out as a
      separate set of definitions so that it can be referred to by other
      specifications. The core concept is that of a Capability, which consists
      of a property or feature of an object and the set of its possible
      values, which may be specified either as a range or as an enumeration.
      For example, a camera might be capable of framerates (a property)
      between 20 and 50 frames per second (a range) and may be able to be
      positioned (a property) facing towards the user, away from the user, or
      to the left or right of the user (an enumerated set.) The application
      can examine a ConstrainablePattern object's set of Capabilities via the
      <code>getCapabilities()</code> accessor.</p>

      <p>The application can select the (range of) values it wants for an
      object's Capabilities by means of basic and/or advanced ConstraintSets
      and the <code>applyConstraints()</code> method. A ConstraintSet consists
      of the names of one or more properties of the object plus the desired
      value (or a range of desired values) for each of them. Each of those
      property/value pairs can be considered to be an individual constraint.
      For example, the application may set a ConstraintSet containing two
      constraints, the first stating that the framerate of a camera be between
      30 and 40 frames per second (a range) and the second that the camera
      should be facing the user (a specific value). How the individual
      constraints interact depends on whether and how they are given in the
      basic Constraint structure, which is a ConstraintSet with an additional
      'advanced' property, or whether they are in a ConstraintSet in the
      advanced list. The behavior is as follows: all 'min', 'max', and 'exact'
      constraints in the basic Constraint structure are together treated as
      the 'required' set, and if it is not possible to satisfy simultaneously
      all of those individual constraints for tho indicated property names,
      the UA MUST call the <code>errorCallback</code>. Otherwise, it must
      apply the required constraints. Next, it will consider any
      ConstraintSets given in the 'advanced' list, in the order in which they
      are specified, and will try to satisfy/apply each complete ConstraintSet
      (i.e., all constraints in the ConstraintSet together), but will skip a
      ConstraintSet if and only if it cannot satisfy/apply it in its entirety.
      Next, the UA MUST attempt to apply, individually, any 'ideal' constraint
      or a constraint given as a bare value for the property. Of these
      properties, it MUST satisfy the largest number that it can, in any
      order. Finally, the UA MUST call the <code>successCallback</code>.</p>

      <p>Important note: If JavaScript applications using this API want the
      attributes in the constraints to be used by the browser, the JavaScript
      code has to first check, via <code>getSupportedConstraints()</code>,
      that all the named properties that are used are supported by the
      browser. The reason for this is that WebIDL drops any unsupported names
      from the dictionary holding the constraints, so the browser does not see
      them and the unsupported names end up being silently ignored. This will
      cause confusing programming errors as the JavaScript code will be
      setting constraints but the browser will be ignoring them. Browsers that
      support (recognize) the name of a required constraint but cannot satisfy
      it will generate an error, while browsers that do not support the given
      name of the constraint will not generate an error. </p>

      <p class="issue">The definition and behavior of 'ideal', along with that
      of bare values in the basic constraint structure (which are assumed to
      mean 'ideal'), have not yet been agreed upon, or even thoroughly
      discussed.</p>

      <p>The following examples may help to understand how constraints work.
      The first shows a basic Constraint structure. Three constraints are
      given, each of which the UA will attempt to satisfy individually.
      Depending upon the resolutions available for this camera, it is possible
      that not all three constraints can be satisfied at the same time. If so,
      the user agent will satisfy two if it can, or only one if not even two
      constraints can be satisfied together. Note that if not all three can be
      satisfied simultaneously, it is possible that there is more than one
      combination of two constraints that could be satisfied. If so, the user
      agent will choose.</p>

      <pre class="example highlight" xml:space="preserve">
var supports = navigator.mediaDevices.getSupportedConstraints("video");
if(!supports["aspectRatio"]) {
  // Treat like an error.
}
 var constraints =
  {
    width: 1280,
    height: 720,
    aspectRatio: 1.5
  };
</pre>

      <p>This next example adds a small bit of complexity. The ideal values
      are still given for width and height, but this time with minimum
      requirements on each as well that must be satisfied. If it cannot
      satisfy either the width or height minimum it will call the
      <code>errorCallback</code>. Otherwise, it will try to satisfy the width,
      height, and aspectRatio target values as well and then call the
      <code>successCallback</code>.</p>

      <pre class="example highlight" xml:space="preserve">
var supports = navigator.mediaDevices.getSupportedConstraints("video");
if(!supports["aspectRatio"]) {
  // Treat like an error.
}
 var constraints =
  {
    width: {min: 640, ideal: 1280},
    height: {min: 480, ideal: 720},
    aspectRatio: 1.5
  };
</pre>

      <p>This example illustrates the full control possible with the
      Constraints structure by adding the 'advanced' property. In this case,
      the user agent behaves the same way with respect to the required
      constraints, but before attempting to satisfy the ideal values it will
      process the 'advanced' list. In this example the 'advanced' list
      contains two ConstraintSets. The first specifies width and height
      constraints, and the second specifies an aspectRatio constraint. Note
      that in the advanced list, these bare values are treated as 'exact'
      values. This example represents the following: "I need my video to be at
      least 640 pixels wide and at least 480 pixels high. My preference is for
      precisely 1920x1280, but if you can't give me that, give me an
      aspectRatio of 4x3 if at all possible. If even that is not possible,
      give me a resolution as close to 1280x720 as possieble."</p>

      <pre class="example highlight" xml:space="preserve">
var supports = navigator.mediaDevices.getSupportedConstraints("video");
if(!supports["width"] || !supports["height"]) {
  // Treat like an error.
}
 var constraints =
  {
    width: {min: 640, ideal: 1280},
    height: {min: 480, ideal: 720},
    advanced: [{width: 1920, height: 1280},
               {aspectRatio: 1.3333333333}]
  };
</pre>

      <p>The ordering of advanced ConstraintSets is significant. In the
      preceding example it is impossible to satisfy both the 1920x1280
      ConstraintSet and the 4x3 aspect ratio ConstraintSet at the same time.
      Since the 1920x1280 occurs first in the list, the user agent will
      attempt to satisfy it first. Application authors can therefore implement
      a backoff strategy by specifying multiple optional ConstraintSets for
      the same property. For example, an application might specify three
      optional ConstraintSets, the first asking for a framerate greater than
      500, the second asking for a framerate greater than 400, and the third
      asking for one greater than 300. If the UA is capable of setting a
      framerate greater than 500, it will (and the subsequent two
      ConstraintSets will be trivially satisfied.) However, if the UA cannot
      set the framerate above 500, it will skip that ConstraintSet and attempt
      to set the framerate above 400. If that fails, it will then try to set
      it above 300. If the UA cannot satisfy any of the three ConstraintSets,
      it will set the framerate to any value it can get. If the developer
      wanted to insist on 300 as a lower bound, he could provide that as a
      'min' value in the basic ConstraintSet. In that case, the UA would fail
      altogether if it couldn't get a value over 300, but would choose a value
      over 500 if possible, then try for a value over 400.</p>

      <p>Note that, unlike basic constraints, the constraints within a
      ConstraintSet in the advanced list must be satisfied together or skipped
      together. Thus, {width: 1920, height: 1280} is a request for that
      specific resolution, not a request for that width or that height. One
      can think of the basic constraints as requesting an or (non-exclusive)
      of the individual constraints, while each advanced ConstraintSet is
      requesting an and of the individual constraints in the ConstraintSet. An
      application may inspect the full set of Constraints currently in effect
      via the <code>getConstraints()</code> accessor.</p>

      <p>The specific value that the UA chooses for a Capability is referred
      to as a Setting. For example, if the application applies a ConstraintSet
      specifying that the framerate must be at least 30 frames per second, and
      no greater than 40, the Setting can be any intermediate value, e.g., 32,
      35, or 37 frames per second. The application can query the current
      settings of the object's Capabilities via the <code>
          <a>getSettings()</a>
        </code> accessor.</p>

      <section>
        <h2>Interface Definition</h2>

        <p>Due to the limitations of the interface definition language used in
        this specification, it is not possible for other interfaces to inherit
        or implement ConstrainablePattern. Therefore the WebIDL definitions
        given are only templates to be copied. Each interface that wishes to
        make use of the functionality defined here will have to provide its
        own copy of the WebIDL for the functions and interfaces given here.
        However it can refer to the semantics defined here, which will not
        change. See <a
        href="#media-stream-track-interface-definition">MediaStreamTrack
        Interface Definition</a> for an example of this.</p>

        <dl class="idl"
            title="[NoInterfaceObject] interface       ConstrainablePattern">
          <dt>Capabilities getCapabilities()</dt>

          <dd>
            <p>The <dfn>getCapabilities()</dfn> method returns the dictionary
            of the capabilities that the object supports.</p>

            <div class="note">
              <p>It is possible that the underlying hardware may not exactly
              map to the range defined in the registry entry. Where this is
              possible, the entry <em class="rfc2119"
              title="should">should</em> define how to translate and scale the
              hardware's setting onto the values defined in the entry. For
              example, suppose that a registry entry defines a hypothetical
              fluxCapacitance capability that is defined to be the range from
              -10 (min) to 10 (max), but there are common hardware devices
              that support only values of "off" "medium" and "full". The
              registry entry might specify that for such hardware, the user
              agent should map the range value of -10 to "off", 10 to "full",
              and 0 to "medium". It might also indicate that given a
              ConstraintSet imposing a strict value of 3, the user agent
              should attempt to set the value of "medium" on the hardware, and
              and that <code>
                  <a>getSettings()</a>
                </code> should return a fluxCapacitance of 0, since that is
              the value defined as corresponding to "medium".</p>
            </div>
          </dd>

          <dt>Constraints getConstraints()</dt>

          <dd>The <dfn>getConstraints</dfn> method returns the Constraints
          that were the argument to the last successful call of
          <code>applyConstraints()</code>, maintaining the order in which they
          were specified. Note that some of the optional ConstraintSets
          returned may not be currently satisfied. To check which
          ConstraintSets are currently in effect, the application should use
          <code>getSettings</code>. </dd>

          <dt>Settings getSettings()</dt>

          <dd>The <dfn>getSettings()</dfn> method returns the current settings
          of all the properties of the object, whether they are platform
          defaults or have been set by <code>applyConstraints()</code>. Note
          that the actual setting of a property <em class="rfc2119"
          title="must">must</em> be a single value. </dd>

          <dt>void applyConstraints()</dt>

          <dd>
            <dl class="parameters">
              <dt>Constraints constraints</dt>

              <dd>A new constraint structure to apply to this object.</dd>

              <dt>VoidFunction successCallback</dt>

              <dd>Called if the required constraints can be satisfied.</dd>

              <dt>ConstraintErrorCallback errorCallback</dt>

              <dd>Called if the required constraints cannot be satisfied.</dd>
            </dl>

            <p>The <dfn>applyConstraints()</dfn> algorithm for applying
            constraints is stated below. Here are some preliminary definitions
            that are used in the statement of the algorithm:</p>

            <ul>
              <li>We refer to each element of a ConstraintSet (other than the
              special term 'advanced') as a 'constraint' since it is intended
              to constrain the corresponding Capability of the
              ConstrainablePattern object to a value that is within the range
              or list of values it specifies.</li>

              <li>We refer to the "effective Capability" C of an object O as
              the possibly proper subset of the possible values of C (as
              returned by getCapabilities) taking into consideration
              environmental limitations and/or restrictions placed by other
              constraints. For example given a ConstraintSet that constrains
              Capabilities aspectRatio, height and width, the values assigned
              to any two of the Capabilities limit the effective Capability of
              the third. The set of effective Capabilities may be platform
              dependent. For example, on a resource-limited device it may not
              be possible to set Capabilities C1 and C2 both to 'high', while
              on another less limited device, this may be possible.</li>

              <li>A set of values for the Capabilities of an object O satisfy
              ConstraintSet CS if each value a) is in the range of the
              corresponding effective Capability of O, and b) is in the range
              or list of values specified by the corresponding constraint in
              CS, if there is one, and c) there is no constraint in CS that
              does not correspond to a Capability of O. (Note that although
              this definition ignores the difference between required and
              optional ConstraintSets, the algorithm below distinguishes
              between them.)</li>

              <li>A set of ConstraintSets CS1...CSn (n &gt;= 1) can be
              satisfied by an object O if it is possible to choose a sequence
              of values for the Capabilities of O that satisfy CS1...CSn
              simultaneously.</li>

              <li>To apply a set of ConstraintSet CS1...CSn to object O is to
              choose such a sequence of values that satisfy CS1...CSn and
              assign them as the settings for the properties of O.</li>
            </ul>

            <p>When <code>applyConstraints</code> is called, the UA <em
            class="rfc2119" title="must">must</em> queue a task to run the
            following steps:</p>

            <ol>
              <li>let <var>newContraints</var> be the argument to this
              function. Each constraint <em class="rfc2119"
              title="must">must</em> specify one or more values (or a range of
              values) for its property. A property <em class="rfc2119"
              title="may">may</em> appear more than once in the list of
              'advanced' ConstraintSets. Let <var>requiredConstraints</var> be
              the set of 'min', 'max', and 'exact' constraints appearing in
              <var>newConstraints</var>. Let <var>unorderedConstraints</var>
              be all the other constraints in <var>newConstraints</var>. Note
              that 'advanced' is not a member of either of these sets since it
              represents meta-information about constraints. In the following
              we treat <var>requiredConstraints</var> and
              <var>unorderedConstraints</var> as ConstraintSets. Note that
              unknown properties are discarded by WebIDL, which means that
              unknown/unsupported required constraints will silently
              disappear. To avoid this being a surprise, application authors
              are expected to first use the
              <code>getSupportedConstraints()</code> method as shown in the
              Examples below.</li>

              <li>Let <var>object</var> be the ConstrainablePattern object on
              which this method was called. Let <var>copy</var> be an
              unconstrained copy of <var>object</var> (i.e., <var>copy</var>
              should behave as if it were <var>object</var> with all
              ConstraintSets removed.)</li>

              <li>If <var>requiredConstraints</var> is non-null and cannot be
              satisfied by <var>copy</var>, call the
              <code>errorCallback</code>, passing it a new
              <code>MediaStreamError</code> with name
              <code>ConstraintNotSatisfied</code> and
              <code>constraintName</code> set to any of the required
              constraints that could not be satisfied, and return.
              <var>existingConstraints</var> remain in effect in this
              case.</li>

              <li>Let <var>successfulConstraints</var> be a list of
              ConstraintSets, initially containing only
              <var>requiredConstraints</var>. Iterate over the 'advanced'
              ConstraintSets in <var>newConstraints</var> in the order in
              which they were specified. For each ConstraintSet, if it and
              <var>successfulConstraints</var> together can be satisfied by
              <var>copy</var>, append it to the rear of
              <var>successfulConstraints</var>. Otherwise, skip it. </li>

              <li>In a single operation, remove <var>existingConstraints</var>
              from <var>object</var>, apply <var>successfulConstraints</var>,
              then apply the largest subset of <var>unorderedConstraints</var>
              that can be satisifed. (If more than one 'largest subset' can be
              satisfied, the UA is free to select which 'largest subset' it
              chooses.) Finally fire the <code>successCallback</code>. From
              this point on until applyConstraints() is called successfully
              again, getConstraints() <em class="rfc2119"
              title="must">must</em> return the <var>newConstraints</var> that
              were passed as an argument to this call. </li>
            </ol>

            <p>The UA <em class="rfc2119" title="may">may</em> choose new
            settings for the Capabilities of the object at any time. When it
            does so it <em class="rfc2119" title="must">must</em> attempt to
            satisfy the current Constraints, in the manner described in the
            algorithm above. </p>

            <p class="issue">The definition of how multiple
            unorderedConstraints are to be satisfied together is still very
            much under discussion. Also, please see issue 6 about 'ideal' not
            yet being defined.</p>
          </dd>

          <dt>attribute EventHandler onoverconstrained</dt>

          <dd>This event handler, of type <code>
              <a
              href="#event-constrainable-overconstrained">overconstrained</a>
            </code>, <em class="rfc2119" title="must">must</em> be supported
          by all objects implementing the <code>
              <a>ConstrainablePattern</a>
            </code> pattern. <p>The UA <em class="rfc2119"
          title="must">must</em> raise a <code>MediaStreamErrorEvent</code>
          named "overconstrained" if changing circumstances at runtime result
          in it no longer being able to satisfy the
          <var>requiredConstraints</var> from the currently valid Constraints.
          This MediaStreamErrorEvent <em class="rfc2119"
          title="must">must</em> contain a MediaStreamError whose
          <code>name</code> is <code>OverconstrainedError</code>, and whose
          <code>constraintName</code> attribute is set to one of the
          <var>requiredConstraints</var> that can no longer be satisfied. The
          <code>message</code> attribute of the MediaStreamError SHOULD
          contain a string that is useful for debugging. The conditions under
          which this error might occur are platform and application-specific.
          For example, the user might physically manipulate a camera in a way
          that makes it impossible to provide a resolution that satisfies the
          constraints. The UA MAY take other actions as a result of the
          overconstrained situation.</p> </dd>
        </dl>

        <section>
          <h3>applyConstraints Failure Callback</h3>

          <section>
            <section>
              <h4>ConstraintErrorCallback</h4>

              <dl class="idl" title="callback ConstraintErrorCallback = void">
                <dt>MediaStreamError error</dt>

                <dd>An <code>MediaStreamError</code> holding a required
                constraint that could not be satisfied.</dd>
              </dl>
            </section>
          </section>
        </section>

        <p>An example of Constraints that could be passed into <code>
            <a>applyConstraints()</a>
          </code> or returned as a value of <code>
            <a>constraints</a>
          </code> is below. It uses the properties defined in <a
        href="#sec-track-properties">the Track property registry</a>.</p>

        <pre class="example highlight" xml:space="preserve">
var supports = navigator.mediaDevices.getSupportedConstraints("video");
if(!supports["facingMode"]) {
  // Treat like an error.
}
var constraints = {
  "width": {
    "min": 640
  },
  "height": {
    "min": 480
  },
  "advanced": [{
      "width": 650
    }, {
      "width": {
        "min": 650
      }
    }, {
      "frameRate": 60
    }, {
      "width": {
        "max": 800
      }
    }, {
      "facingMode": "user"
    }]
};
</pre>

        <p>Here is another example, specifically for a video track where I
        must have a particular camera and have separate preferences for the
        width and height:</p>

        <pre class="example highlight" xml:space="preserve">
var supports = navigator.mediaDevices.getSupportedConstraints("video");
if(!supports["sourceId"]) {
  // Treat like an error.
}
var constraints = {
  sourceId: {"exact": "20983-20o198-109283-098-09812"},
  advanced: [{
      width: {
        min: 800,
        max: 1200
      }
    }, {
      height: {
        min: 600
      }
    }]
};
</pre>

        <p>And here's one for an audio track:</p>

        <pre class="example highlight" xml:space="preserve">
var supports = navigator.mediaDevices.getSupportedConstraints("audio");
if(!supports["sourceId"] || !supports["gain"]) {
  // Treat like an error.
}
var constraints = {
  advanced: [{
      sourceId: "64815-wi3c89-1839dk-x82-392aa"
    }, {
      gain: 0.5
    }]
};
</pre>

        <p>Here's an example of use of ideal:</p>

        <pre class="example highlight" xml:space="preserve">
var supports = navigator.mediaDevices.getSupportedConstraints("video");
if(!supports["aspectRatio"] || !supports["facingMode"]) {
  // Treat like an error.
}
navigator.mediaDevices.getUserMedia({
  "video": {
    "width": {"min": 320, "ideal": 1280, "max": 1920},
    "height": {"min": 240, "ideal": 720, "max": 1080},
    "framerate": 30,     // Shorthand for ideal.
    // "facingMode": "environment" would be optional.
    "facingMode": {"exact": "environment"}
  }}, ...);
</pre>

        <p>Here's an example of "I want 720p, but I can accept up to 1080p and
        down to VGA.":</p>

        <pre class="example highlight" xml:space="preserve">
var supports = navigator.mediaDevices.getSupportedConstraints("video");
if(!supports["width"] || !supports["height"]) {
  // Treat like an error.
}
navigator.mediaDevices.getUserMedia({"video": {
  "width": {"min": 640, "ideal": 1280, "max": 1920},
  "height": {"min": 480, "ideal": 720, "max": 1080},
}}, ...);
</pre>

        <p>Here's an example of "I want a front-facing camera and it must be
        VGA.":</p>

        <pre class="example highlight" xml:space="preserve">
var supports = navigator.mediaDevices.getSupportedConstraints("video");
if(supports["facingMode"]) {
  navigator.mediaDevices.getUserMedia({"video": {
    "facingMode": {"exact": "user"},
    "width": {"exact": 640},
    "height": {"exact": 480}
  }}, ...);
}
</pre>
      </section>

      <section id="registry">
        <h2>The Property Registry</h2>

        <p>There is a single <a href="#sec-iana">IANA registry</a> that
        defines the constrainable properties of all objects that implement the
        Constrainable pattern. The registry entries <em class="rfc2119"
        title="must">must</em> contain the name of each property along with
        its set of legal values. The registry entries for MediaStreamTrack are
        defined <a href="#sec-constraints">below</a>. The syntax for the
        specification of the set of legal values depends on the type of the
        values. In addition to the standard atomic types (boolean, long,
        double, DOMString), legal values include lists of any of the atomic
        types, plus min-max ranges, as defined below.</p>


        <p>List values <em class="rfc2119" title="must">must</em> be
        interpreted as disjunctions. For example, if a property 'facingMode'
        for a camera is defined as having legal values ["left", "right",
        "user", "environment"], this means that 'facingMode' can have the
        value "left", the value "right", the value "environment" or the value
        "user". Similarly <a>Constraints</a> restricting 'facingMode' to
        ["user", "left", "right"] would mean that the UA should select a
        camera (or point the camera, if that is possible) so that "facingMode"
        is either "user", "left", or "right". This Constraint would thus
        request that the camera not be facing away from the user, but would
        allow the UA to choose among the other directions.</p>

        <dl class="idl" title="dictionary ConstrainDoubleRange">
          <dt>double max</dt>

          <dd>The maximum legal value of this property.</dd>

          <dt>double min</dt>

          <dd>The minimum value of this Property.</dd>

          <dt>double exact</dt>

          <dd>The exact required value for this property.</dd>

          <dt>double ideal</dt>

          <dd>The ideal (target) value for this property.</dd>
        </dl>

        <dl class="idl" title="dictionary ConstrainLongRange">
          <dt>long max</dt>

          <dd>The maximum legal value of this property.</dd>

          <dt>long min</dt>

          <dd>The minimum value of this property.</dd>

          <dt>long exact</dt>

          <dd>The exact required value for this property.</dd>

          <dt>long ideal</dt>

          <dd>The ideal (target) value for this property.</dd>
        </dl>

        <dl class="idl" title="dictionary ConstrainDOMStringParameters">
          <dt>(DOMString or sequence&lt;DOMString&gt;&gt;) exact</dt>

          <dd>The exact required value for this property.</dd>

          <dt>(DOMString or sequence&lt;DOMString&gt;&gt;) ideal</dt>

          <dd>The ideal (target) value for this property.</dd>
        </dl>

        <dl class="idl"
            title="typedef (Long or ConstrainLongRange) ConstrainLong" />

        <dl class="idl"
            title="typedef (Double or ConstrainDoubleRange) ConstrainDouble" />

        <dl class="idl"
            title="typedef (DOMString or sequence&lt;DOMString&gt; or ConstrainDOMStringParameters) ConstrainDOMString" />
      </section>

      <section id="capabilities">
        <h3>Capabilities</h3>

        <p><dfn>Capabilities</dfn> are a dictionary containing one or more
        key-value pairs, where each key <em class="rfc2119"
        title="must">must</em> be a constrainable property defined in the
        registry, and each value <em class="rfc2119" title="should">must</em>
        be a subset of the set of values defined for that property in the
        registry. The exact syntax of the value expression depends on the type
        of the property, and its type is as defined in the Values column of
        the registry. The Capabilities dictionary specifies the subset of the
        constrainable properties and values from the registry that the UA
        supports. Note that a UA <em class="rfc2119" title="may">may</em>
        support only a subset of the properties that are defined in the
        registry, and <em class="rfc2119" title="may">may</em> support a
        subset of the set values for those properties that it does support.
        Note that Capabilities are returned from the UA to the application,
        and cannot be specified by the application. However, the application
        can control the Settings that the UA chooses for Capabilities by means
        of Constraints.</p>

        <p>An example of a Capabilities dictionary is shown below. This
        example is not very realistic in that a browser would actually be
        required to support more settings that just these.</p>

        <pre class="example highlight" xml:space="preserve">
{
  "frameRate": {
    "min": 1.0,
    "max": 60.0
  },
  "facingMode": ["user", "environment"]
}
</pre>
      </section>

      <section id="settings">
        <h3>
          <dfn>Settings</dfn>
        </h3>

        <p>A <dfn>Setting</dfn> is a dictionary containing one or more
        key-value pairs. It <em class="rfc2119" title="must">must</em> contain
        each key returned in <code>getCapabilities()</code>. There <em
        class="rfc2119" title="must">must</em> be a single value for each key
        and the value <em class="rfc2119" title="must">must</em> a member of
        the set defined for that property by <code>capabilities()</code>. The
        <code>Settings</code> dictionary contains the actual values that the
        UA has chosen for the object's Capabilities. The exact syntax of the
        value depends on the type of the property.</p>

        <p>A conforming user-agent <em class="rfc2119"
        title="must">must</em> support all the setting names defined in this
        spec.</p>

        <p>An example of a Setting dictionary is shown below. This example is
        not very realistic in that a browser would actually be required to
        support more settings that just these.</p>

        <pre class="example highlight" xml:space="preserve">
{
  "frameRate": 30.0,
  "facingMode": "user"
}
</pre>
      </section>

      <section id="constraints">
        <h3>
          <dfn>Constraints and ConstraintSet</dfn>
        </h3>

        <p>Due to the limitiations of WebIDL, interfaces implementing the
        Constrainable Pattern cannnot simply subclass Constraints and
        ConstraintSet as they are defined here. Instead they must provide
        their own definitions that follow this pattern. See <a
        href="#media-track-constraints"> MediaTrackConstraints</a> for an
        example of this.</p>

        <dl class="idl" title="typedef Dictionary ConstraintSet" />

        <p>Each member of a ConstraintSet corresponds to a Capability and
        specifies a subset of its legal values. Applying a ConstraintSet
        instructs that UA to restrict the setting of the corresponding
        Capabilities to the specified values or ranges of values. A given
        property MAY occur both in the basic Constraints set and in the
        advanced ConstraintSets list, and MAY occur at most once in each
        ConstraintSet in the advanced list.</p>

        <dl class="idl" title="dictionary Constraints : ConstraintSet">
          <dt>sequence&lt;ConstraintSet&gt; advanced</dt>

          <dd>
            <p>The list of ConstraintSets that the UA <em class="rfc2119"
            title="should">must</em> attempt to satisfy, in order, skipping
            only those that cannot be satisfied. The order of these
            ConstraintSets is significant. In particular, when they are passed
            as an argument to <code>applyConstraints</code>, the UA <em
            class="rfc2119" title="must">must</em> try to satisfy them in the
            order that is specified. Thus if optional ConstraintSets C1 and C2
            can be satisfied individually, but not together, then whichever of
            C1 and C2 is first in this list will be satisfied, and the other
            will not. The UA <em class="rfc2119" title="must">must</em>
            attempt to satisfy all optional ConstraintSets in the list, even
            if some cannot be satisfied. Thus, in the preceding example, if
            optional constraint C3 is specified after C1 and C2, the UA will
            attempt to satisfy C3 even though C2 cannot be satisfied. Note
            that a given property name may occur only once in each
            ConstraintSet but may occur in more than one ConstraintSet.</p>
          </dd>
        </dl>
      </section>
    </section>

    <section>
      <h2>Examples</h2>

      <div>
        <p>This sample code exposes a button. When clicked, the button is
        disabled and the user is prompted to offer a stream. The user can
        cause the button to be re-enabled by providing a stream (e.g., giving
        the page access to the local camera) and then disabling the stream
        (e.g., revoking that access).</p>

        <pre class="example highlight" xml:space="preserve">
&lt;input type="button" value="Start" onclick="start()" id="startBtn"&gt;
&lt;script&gt;
 var startBtn = document.getElementById('startBtn');

 function start() {
     navigator.mediaDevices.getUserMedia({
         audio: true,
         video: true
     }, gotStream, logError);
     startBtn.disabled = true;
 }

 function gotStream(stream) {
     stream.oninactive = function () {
         startBtn.disabled = false;
     };
 }

 function logError(error) {
     log(error.name + ": " + error.message);
 }
&lt;/script&gt;
</pre>
      </div>

      <!-- Put back when we define MediaStreamRecorder
    <div>

      <p>This example allows people to record a short audio message and upload
      it to the server. This example even shows rudimentary error handling.</p>

      <pre xml:space="preserve" class="example highlight">
&lt;input type="button" value="Start" onclick="msgRecord()" id="recBtn"&gt;
&lt;input type="button" value="Stop" onclick="msgStop()" id="stopBtn" disabled&gt;
&lt;p id="status"&gt;To start recording, press the Start button.&lt;/p&gt;
&lt;script&gt;
 var recBtn = document.getElementById('recBtn');
 var stopBtn = document.getElementById('stopBtn');

 function report(s) {
     document.getElementById('status').textContent = s;
 }

 function msgRecord() {
     report('Attempting to access microphone...');
     navigator.getUserMedia({
         audio: true
     }, gotStream, noStream);
     recBtn.disabled = true;
 }
 var msgStream, msgStreamRecorder;

 function gotStream(stream) {
     report('Recording... To stop, press the Stop button.');
     msgStream = stream;
     msgStreamRecorder = stream.record();
     stopBtn.disabled = false;
     stream.oninactive = function () {
         msgStop();
     }
 }

 function msgStop() {
     report('Creating file...');
     stopBtn.disabled = true;
     msgStream.oninactive = null;
     msgStream.stop();
     msgStreamRecorder.getRecordedData(msgSave);
 }

 function msgSave(blob) {
     report('Uploading file...');
     var x = new XMLHttpRequest();
     x.open('POST', 'uploadMessage');
     x.send(blob);
     x.onload = function () {
         report('Done! To record a new message, press the Start button.');
         recBtn.disabled = false;
     };
     x.onerror = function () {
         report('Failed to upload message. To try recording a message again, press the Start button.');
         recBtn.disabled = false;
     };
 }

 function noStream() {
     report('Could not obtain access to your microphone. To try again, press the Start button.');
     recBtn.disabled = false;
 }
&lt;/script&gt;
</pre>
    </div>-->

      <div>
        <p>This example allows people to take photos of themselves from the
        local video camera. Note that the Image Capture
        specification [[image-capture]] provides a simpler way to accomplish this.</p>

        <pre class="example highlight" xml:space="preserve">
&lt;article&gt;
 &lt;style scoped&gt;
  video { transform: scaleX(-1); }
  p { text-align: center; }
 &lt;/style&gt;
 &lt;h1&gt;Snapshot Kiosk&lt;/h1&gt;
 &lt;section id="splash"&gt;
  &lt;p id="errorMessage"&gt;Loading...&lt;/p&gt;
 &lt;/section&gt;
 &lt;section id="app" hidden&gt;
  &lt;p&gt;&lt;video id="monitor" autoplay&gt;&lt;/video&gt; &lt;canvas id="photo"&gt;&lt;/canvas&gt;
  &lt;p&gt;&lt;input type=button value="&amp;#x1F4F7;" onclick="snapshot()"&gt;
 &lt;/section&gt;
 &lt;script&gt;
 navigator.mediaDevices.getUserMedia({
     video: true
 }, gotStream, noStream);
 var video = document.getElementById('monitor');
 var canvas = document.getElementById('photo');

 function gotStream(stream) {
     video.srcObject = stream;
     stream.oninactive = noStream;
     video.onloadedmetadata = function () {
         canvas.width = video.videoWidth;
         canvas.height = video.videoHeight;
         document.getElementById('splash').hidden = true;
         document.getElementById('app').hidden = false;
     };
 }

 function noStream() {
     document.getElementById('errorMessage').textContent = 'No camera available.';
 }

 function snapshot() {
     canvas.getContext('2d').drawImage(video, 0, 0);
 }
 &lt;/script&gt;
&lt;/article&gt;
</pre>
      </div>
    </section>

    <section>
      <h1>Privacy and Security Considerations</h1>

      <p>This section is non-normative; it specifies no new behaviour, but
      instead summarizes information already present in other parts of the
      specification.</p>

      <p>This document extends the Web platform with the ability to manage
      input devices for media - in this iteration, microphones and cameras. It
      also allows the manipulation of audio output devices (speakers and
      headphones).</p>

      <p>Without authorization (to the “drive-by web”), it offers the ability
      to tell how many devices there are of each class. The identifiers for
      the devices are designed to not be useful for a fingerprint that can
      track the user between origins, but the number of devices adds to the
      fingerprint surface.</p>

      <p>When authorization is given, this document describes how to get
      access to, and use, media data from the devices mentioned. This data may
      be sensitive; advice is given that indicators should be supplied to
      indicate that devices are in use, but both the nature of authorization
      and the indicators of in-use devices are platform decisions.</p>

      <p>Authorization may be given on a case-by-case basis, or be persistent.
      In the case of a case-by-case authorization, it is important that the
      user be able to say “no” in a way that prevents the UI from blocking
      user interaction until permission is given - either by offering a way to
      say a “persistent NO” or by not using a modal permissions dialog.</p>

      <p>It is possible to use constraints so that the failure of a
      getUserMedia call will return information about devices on the system
      without prompting the user, which increases the surface available for
      fingerprinting. The UA should consider limiting the rate at which failed
      getUserMedia calls are allowed in order to limit this additional
      surface.</p>

      <p>In the case of persistent authorization, it is important that it’s
      easy to find the list of granted permissions and revoke permissions that
      the user wishes to revoke.</p>

      <p>Once permission has been granted, the UA should make two things
      readily apparent to the user: <ul>
          <li>That the page has access to the devices for which permission is
          given</li>

          <li>Whether or not any of the devices are presently recording ("on
          air") indicator</li>
        </ul> </p>
    </section>

    <section>
      <h1 id="sec-iana">IANA Registrations</h1>

      <section>
        <h2 id="sec-track-properties">Track Property Registrations</h2>

        <p>IANA is requested to register the following properties as specified
        in [[!RTCWEB-CONSTRAINTS]]:</p>

        <p>The following constraint names are defined to apply to both video
        and audio <code>
            <a>MediaStreamTrack</a>
          </code> objects:</p>

        <table class="simple">
          <thead>
            <tr>
              <th>Property Name</th>

              <th>Values</th>

              <th>Notes</th>
            </tr>
          </thead>

          <tbody>
            <tr id="def-constraint-sourceType">
              <td>
                <dfn>sourceType</dfn>
              </td>

              <td>
                <a>
                  <code>SourceTypeEnum</code>
                </a>
              </td>

              <td> The type of the source of the <a>MediaStreamTrack</a>. Note
              that the setting of this property is uniquely determined by the
              source that is attached to the Track. In particular,
              getCapabilities() will return only a single value for
              sourceID/Type. This property can therefore be used for initial
              media selection with getUserMedia(). However is not useful for
              subsequent media control with applyConstraints, since any
              attempt to set a different value will result in an unsatisfiable
              ConstraintSet. </td>
            </tr>

            <tr id="def-constraint-sourceId">
              <td>
                <dfn>sourceId</dfn>
              </td>

              <td>DOMString</td>

              <td>The application-unique identifier for this source. The same
              identifier MUST be valid between sessions of this application,
              but MUST also be different for other applications. Some sort of
              GUID is recommended for the identifier. Note that the setting of
              this property is uniquely determined by the source that is
              attached to the Track. In particular, getCapabilities() will
              return only a single value for sourceID/Type. This property can
              therefore be used for initial media selection with
              getUserMedia(). However is not useful for subsequent media
              control with applyConstraints, since any attempt to set a
              different value will result in an unsatisfiable ConstraintSet.
              </td>
            </tr>

            <tr id="def-constraint-groupId">
              <td>
                <dfn>groupId</dfn>
              </td>

              <td>DOMString</td>

              <td>The group identifier for this source. Two devices have the
              same group identifier if they belong to the same physical
              device; for example the audio input and output devices of a
              headset.</td>
            </tr>
          </tbody>
        </table>

        <p>The following properties are defined to apply only to video <code>
            <a>MediaStreamTrack</a>
          </code> objects:</p>

        <table class="simple">
          <thead>
            <tr>
              <th>Property Name</th>

              <th>Values</th>

              <th>Notes</th>
            </tr>
          </thead>

          <tbody>
            <tr id="def-constraint-width">
              <td>
                <dfn>width</dfn>
              </td>

              <td>
                <code><a>ConstrainLong</a></code>
              </td>

              <td>The width or width range, in pixels, of the video source. As
              a capability, the range should span the video source's pre-set
              width values with min being the smallest width and max being the
              largest width.</td>
            </tr>

            <tr id="def-constraint-height">
              <td>
                <dfn>height</dfn>
              </td>

              <td>
                <code><a>ConstrainLong</a></code>
              </td>

              <td>The height or height range, in pixels, of the video source.
              As a capability, the range should span the video source's
              pre-set height values with min being the smallest height and max
              being the largest height.</td>
            </tr>

            <tr id="def-constraint-frameRate">
              <td>
                <dfn>frameRate</dfn>
              </td>

              <td>
                <code><a>ConstrainDouble</a></code>
              </td>

              <td>The exact desired frame rate (frames per second) or
              frameRate range of the video source. If the source does not
              natively provide a frameRate, or the frameRate cannot be
              determined from the source stream, then this value MUST refer to
              the user agent's vsync display rate.</td>
            </tr>

            <tr id="def-constraint-aspect">
              <td>
                <dfn>aspectRatio</dfn>
              </td>

              <td>
                <code><a>ConstrainDouble</a></code>
              </td>

              <td>The exact aspect ratio (width in pixels divided by height in
              pixels), represented as a double rounded to the tenth decimal
              place.</td>
            </tr>

            <tr id="def-constraint-facingMode">
              <td>
                <dfn>facingMode</dfn>
              </td>

              <td>
                <a>
                  <code>ConstrainDOMString</code>
                </a>
              </td>

              <td>The members of the enum describe the directions that the
              camera can face, as seen from the user's perspective. Valid
              values for the strings in the ConstrainDOMString are the values
              of <code>enum VideoFacingModeEnum</code>.</td>
            </tr>
          </tbody>
        </table>

        <dl class="idl" title="enum VideoFacingModeEnum">
          <dt>user</dt>

          <dd>The source is facing toward the user (a self-view camera).</dd>

          <dt>environment</dt>

          <dd>The source is facing away from the user (viewing the
          environment).</dd>

          <dt>left</dt>

          <dd>The source is facing to the left of the user.</dd>

          <dt>right</dt>

          <dd>The source is facing to the right of the user.</dd>

          <dt>other</dt>

          <dd>For future expansion. User agents MAY coerse unknown strings to this value.</dd>
        </dl>

        <p>Below is an illustration of the video facing modes in relation to
        the user.<br /> <img
        alt="Illustration of video facing modes in relation to user"
        src="images/camera-names-exp.svg" style="width:40%" /></p>

        <p>The following properties are defined to apply only to audio <code>
            <a>MediaStreamTrack</a>
          </code> objects:</p>

        <table class="simple">
          <thead>
            <tr>
              <th>Property Name</th>

              <th>Values</th>

              <th>Notes</th>
            </tr>
          </thead>

          <tbody>
            <tr id="def-constraint-volume">
              <td>volume</td>

              <td>
                <code><a>ConstrainDouble</a></code>
              </td>

              <td>The volume or volume range of the audio source, as a
              percentage. A volume of 0.0 is silence, while a volume of 1.0 is
              the maximum supported volume. Note that any ConstraintSet that
              specifies values outside of this range can never be
              satisfied.</td>
            </tr>

            <tr id="def-constraint-sampleRate">
              <td>sampleRate</td>

              <td>
                <code><a>ConstrainLong</a></code>
              </td>

              <td>The sample rate in samples per second for the audio
              data.</td>
            </tr>

            <tr id="def-constraint-sampleSize">
              <td>sampleSize</td>

              <td>
                <code><a>ConstrainLong</a></code>
              </td>

              <td>The linear sample size in bits. This constraint can only be
              satisfied for audio devices that produce linear samples. </td>
            </tr>

            <tr id="def-constraint-echoCancellation">
              <td> echoCancellation </td>

              <td>
                <code>boolean</code>
              </td>

              <td> When one or more audio streams is being played in the
              processes of various microphones, it is often desirable to attempt
              to remove the sound being played from the input signals recorded
              by the microphones. This is referred to echo cancellation. There
              are cases where it is not needed and it is desirable to turn it
              off so that no audio artifacts are introduced. This allows
              applications to control this behavior. </td>
            </tr>
          </tbody>
        </table>

        <div class="note"> Open Issue: volume seems like better as double, or
        even better as double in dB. what value is it set at if one wants it
        half as loud? </div>

        <dl />
      </section>
    </section>

    <section>
      <h2>Change Log</h2>

      <p>This section will be removed before publication.</p>

      <h2>Changes since August 17, 2014</h2>
      <ol>
        <li>Bug 25988: Need a list of MediaStreamError "name" values</li>

        <li>Bug 26623: Use commonest spelling of "cancellation"</li>

        <li>Bug 25767: Missing Ref to Image Capture spec</li>

        <li>Bug 22271: Terminology section should not have conformance
        requirements</li>
      </ol>

      <h2>Changes since July 4, 2014</h2>

      <ol>
        <li>Bug 22251: Added new NotFoundError, AbortError,
        SourceUnavailable errors to gUM call.</li>
        <li>Bug 25786: User agent allowance of files to be substituted
        for any input device is now permitted but not listed as best
        practice, i.e., no longer specifically recommended.</li>
      </ol>

      <h2>Changes since June 19, 2014</h2>

      <ol>
        <li>Bug 22354: Added privacy and security section.</li>

        <li>Bug 25784: "on air" indication is underspecified - separated
        "access granted" and "on air" indicators.</li>

        <li>Bug 26192: add onoverconstrained to MediaStreamTrack</li>

        <li>Bug 25776: add groupID to MediaTrackConstraintSet</li>

        <li>Bug 25780: Clarify step 3 of MediaStream.clone</li>

        <li>Bug 25804: Change 'remote' attribute definition</li>

        <li>Bug 25650: In getUserMedia algorithm if user denies permission
        spec is wrongly redirecting to Constraint Failure.</li>

        <li>Bug 25605: Definition of MediaStreamTrackEvent is not
        complete</li>

        <li>Bug 25651: All the links in spec should redirect to specified
        contents without failure.</li>

        <li>Bug 25725: getUserMedia constraints should be non-nullable</li>

        <li>Bug 25763: does the ID really have to be exaclty 36 char
        long?</li>

        <li>Bug 24934: invalid definition for the “seekable” attribute when
        MediaStream is set to srcObject.</li>

        <li>Removed MediaStreamTrack new state (sourceType none removed as a
        consequence) (as discussed in bug 25787).</li>

        <li>Bug 25801: Remove getNativeSettings()</li>
      </ol>

      <h2>Changes since May 7, 2014</h2>

      <ol>
        <li>Clarified that skipping of optional/advanced ConstraintSets is
        only permitted if they cannot be satisfied, not merely because the
        user agent wishes to.</li>

        <li>Bug 25855: Clarification about conformance requirements phrased as
        algorithms</li>

        <li>Bug 25803: Mark section entitled "The model: sources, sinks,
        constraints, and settings" as non-normative</li>

        <li>Bug 24015: Add callback to indicate when available media devices
        change (introduced Navigator.mediaDevices)</li>

        <li>Bug 25860: make sure we have a bug to have a getTracks that gives
        you all the tracks</li>

        <li>Bug 25884: applied constraint syntax consensus as realized in June
        9 WG email from Peter Thatcher.</li>

        <li>Moved getSupportedConstraints() method to MediaDevices
        object.</li>

        <li>Added stricter requirements on the getSupportedConstraints()
        return value.</li>

        <li>Added issue note in Constrainable Pattern section that ideal is
        not yet defined.</li>

        <li>Added issue note for applyConstraints that how multiple
        unorderedConstraints are to be satisfied together is not yet
        defined.</li>

        <li>Added informative notes that WebIDL discards unknown required
        properties and that application authors need to use the
        <code>getSupportedConstraints()</code> method.</li>

        <li>Cleaned up the MediaStream API intro section (mainly MediaStream
        behavior that have moved to MediaStreamTrack).</li>

        <li>The concept of MediaStreamTrack with a detachable source is now
        used throughout the spec (removed language saying that a MST could be
        disassociated from its track).</li>

        <li>Moved peerIdentity related text to WebRTC.</li>
      </ol>

      <h2>Changes since March 21, 2014</h2>

      <ol>
        <li>New webIDL for Constrainable and Constraints.</li>

        <li>Bug 24931: changed MediaError to MediaStreamError.</li>

        <li>Bug 23817: Redundant TOC headers 8.1 &amp; 9.1</li>

        <li>Bug 25230: readyState attribute must be inherited while cloning a
        MediaStreamTrack</li>

        <li>Bug 25249: Source should be detached when a MediaStreamTrack stops
        for any reason other than stop</li>

        <li>Updated Event Summary section to match the spec regarding
        MediaStreamTrack.stop() (as discussed in bug 25248)</li>

        <li>Made the MediaStream() constructor behave like addTrack() WRT
        adding ended tracks (as discussed in bug 25250).</li>

        <li>Bug 25262: MediaStream Constructor algorithm must also check for
        MediaStreamTracks "ended" state while initializing "active"
        state.</li>

        <li>Bug 25276: Initialization for VideoTrack.selected attribute is
        missing while specifying steps for "Loading and Playing a MediaStream
        in a Media Element"</li>

        <li>Changed syntax of constraints to use 'require' and 'advanced' and
        support non-required, non-advanced constraints.</li>

        <li>Bug 25360: MediaStreamTrack should not be considered as ended just
        because remote peer stopped sending data.</li>

        <li>Bug 25275: VideoTrackList.selectedIndex initialization conflicts
        with HTML5 spec, "if no track is selected".</li>

        <li>Removed mentioning of MediaStream received from other peer (as
        discussed in bug 25361).</li>

        <li>Bug 22263: Clarify synchronization of tracks in a MediaStream</li>

        <li>Bug 25441: Overconstrained muted state should not link with
        MediaStreamTrack.readyState</li>
      </ol>

      <h2>Changes since February 18, 2014</h2>

      <ol>
        <li>Bug 24928: Remove MediaStream state check from addTrack()
        algorithm. </li>

        <li>Bug 24930: Remove MediaStream state check from the removeTrack()
        algorithm.</li>

        <li>Added native settings to tracks.</li>

        <li>Removed videoMediaStreamTrack and audioMediaStreamTrack since they
        are no longer necessary.</li>
      </ol>

      <h2>Changes since December 25, 2013</h2>

      <ol>
        <li>Make optional constraints a list of ConstraintSets. Make
        ConstraintSet an object.</li>

        <li>Remove noaccess, move peerIdentity</li>

        <li>Add constraints for sampleRate, sampleSize, and
        echoCancellation.</li>

        <li>Aligned text in remainder of document with Constrainable
        changes.</li>

        <li>Removed statements that constraints are not applied to read-only
        sources</li>
      </ol>

      <h2>Changes since November 5, 2013</h2>

      <ol>
        <li>ACTION-25: Switch mediastream.inactive to mediastream.active.</li>

        <li>ACTION-26: Rewrite stop to only detach the track's source.</li>

        <li>Bug 22338: Arbitrary changing of tracks.</li>

        <li>Bug 23125: Use double rather than float.</li>

        <li>Bug 22712: VideoFacingMode enum needs an illustration.</li>

        <li>Moved constraints into a separate Constrainable interface.</li>

        <li>Created a separate section on error handling.</li>
      </ol>

      <h2>Changes since October 17, 2013</h2>

      <ol>
        <li>Bug 23263: Add output device enumeration to GetSources</li>

        <li>Introduced the Constrainable interface.</li>

        <li>Change consensus note on constraints in IANA section.</li>

        <li>Removed createObjectURL.</li>

        <li>Bug 22209: Should not use MUST requirements on values provided by
        the developer.</li>
      </ol>

      <h2>Changes since August 24, 2013</h2>

      <ol>
        <li>Bug 22269: Renamed getSourceInfos() to getSources() and made the
        result async.</li>

        <li>Bug 22229: Editorial input</li>

        <li>Bug 22243: Clarify readonly track</li>

        <li>Bug 22259: Disabled mediastreamtrack and state of media
        element</li>

        <li>Bug 22226: Remove check of same source from MediaStream
        constructor algorithm</li>

        <li>Replaced ended with inactive for MediaStream (resolves bug
        21618).</li>

        <li>Bug 22264: MediaStream.ended set to true on creation</li>

        <li>Bug 22272: Permission revocation via MediaStreamTrack.stop()</li>

        <li>Bug 22248: Relationship between MediaStreamTrack and HTML5
        VideoTrack/AudioTrack after MediaStream assignment</li>

        <li>Bug 22247: Setting loop attribute on a media element reading from
        a MediaStream</li>
      </ol>

      <h2>Changes since July 4, 2013</h2>

      <ol>
        <li>Bug 21967: Added paragraph on MediaStreamTrack enabled state and
        updated cloning algorithm.</li>

        <li>Bug 22210: Make getUserMedia() algorithm use all numbered
        items.</li>

        <li>Bug 22250: Fixed accidentally overridden error.</li>

        <li>Bug 22211: Added async error when no valid media type is
        requested.</li>

        <li>Bug 22216: Made NavigatorUserMediaError extend DOMError.</li>

        <li>Bug 22249: Throw on attempts to set currentTime on media elements
        playing MediaStream objects.</li>

        <li>Bug 22246: Made media.buffered have length 0.</li>

        <li>Bug 22692: Updated media element to use HAVE_NOTHING state before
        media arrives on the played MediaStream and HAVE_ENOUGH_DATA as soon
        as media arrives.</li>
      </ol>

      <h2>May 29, 2013</h2>

      <ol>
        <li>Bug 22252: fixed usage of MUST in MediaStream() constructor
        description.</li>

        <li>Bug 22215: made MediaStream.ended readonly.</li>

        <li>Bug 21967: clarified MediaStreamTrack.enabled state initial
        value.</li>

        <li>Added aspectRatio constraint, capability, and state.</li>

        <li>Updated usage of MediaStreams in media elements.</li>
      </ol>

      <h2>May 15, 2013</h2>

      <ol>
        <li>Added explanatory section for constraints, capabilities, and
        states.</li>

        <li>Added VideoFacingModeEnum (including left and right options).</li>

        <li>Added getSourceInfos() and SourceInfo dictionary.</li>

        <li>Added isolated streams.</li>
      </ol>

      <h2>April 29, 2013</h2>

      <ol>
        <li>Removed remaining photo APIs and references (since we have a
        separate Image Capture Spec).</li>
      </ol>

      <h2>March 20, 2013</h2>

      <ol>
        <li>Added readonly and remote attributes to MediaStreamTrack</li>

        <li>Removed getConstraint(), setConstraint(), appendConstraint(), and
        prependConstraint().</li>

        <li>Added source states. Added states() method on tracks. Moved
        sourceType and sourceId to be states.</li>

        <li>Added source capabilities. Added capabilities() method on
        tracks.</li>

        <li>Added clarifying text about MediaStreamTrack lifecycle and
        mediaflow.</li>

        <li>Made MediaStreamTrack cloning explicit.</li>

        <li>Removed takePhoto() and friends from VideoStreamTrack (we have a
        separate Image Capture Spec).</li>

        <li>Made getUserMedia() error callback mandatory.</li>
      </ol>

      <h2>December 12, 2012</h2>

      <ol>
        <li>Changed error code to be string instead of number.</li>

        <li>Added core of settings proposal allowing for constraint changes
        after stream/track creation.</li>
      </ol>

      <h2>November 15 2012</h2>

      <ol>
        <li>Introduced new representation of tracks in a stream (removed
        MediaStreamTrackList).</li>

        <li>Updated MediaStreamTrack.readyState to use an enum type (instad of
        unsigned short constants).</li>

        <li>Renamed MediaStream.label to MediaStream.id (the definition needs
        some more work).</li>
      </ol>

      <h2>October 1 2012</h2>

      <ol>
        <li>Limited the track kind values to "audio" and "video" only (could
        previously be user defined as well).</li>

        <li>Made MediaStream extend EventTarget.</li>

        <li>Simplified the MediaStream constructor.</li>
      </ol>

      <h2>June 23 2012</h2>

      <ol>
        <li>Rename title to "Media Capture and Streams".</li>

        <li>Update document to comply with HTML5.</li>

        <li>Update image describing a MediaStream.</li>

        <li>Add known issues and various other editorial changes.</li>
      </ol>

      <h2>June 22 2012</h2>

      <ol>
        <li>Update wording for constraints algorithm.</li>
      </ol>

      <h2>June 19 2012</h2>

      <ol>
        <li>Added "Media Streams as Media Elements section".</li>
      </ol>

      <h2>June 12 2012</h2>

      <ol>
        <li>Switch to respec v3.</li>
      </ol>

      <h2>June 5 2012</h2>

      <ol>
        <li>Added non-normative section "Implementation Suggestions".</li>

        <li>Removed stray whitespace.</li>
      </ol>

      <h2>June 1 2012</h2>

      <ol>
        <li>Added media constraint algorithm.</li>
      </ol>

      <h2>Apr 23 2012</h2>

      <ol>
        <li>Remove MediaStreamRecorder.</li>
      </ol>

      <h2>Apr 20 2012</h2>

      <ol>
        <li>Add definitions of MediaStreams and related objects.</li>
      </ol>

      <h2>Dec 21 2011</h2>

      <ol>
        <li>Changed to make wanted media opt in (rather than opt out). Minor
        edits.</li>
      </ol>

      <h2>Nov 29 2011</h2>

      <ol>
        <li>Changed examples to use MediaStreamOptions objects rather than
        strings. Minor edits.</li>
      </ol>

      <h2>Nov 15 2011</h2>

      <ol>
        <li>Removed MediaStream stuff. Refers to webrtc 1.0 spec for that part
        instead.</li>
      </ol>

      <h2>Nov 9 2011</h2>

      <ol>
        <li>Created first version by copying the webrtc spec and ripping out
        stuff. Put it on github.</li>
      </ol>
    </section>

    <section class="appendix">
      <h2>Acknowledgements</h2>

      <p>The editors wish to thank the Working Group chairs and Team Contact,
      Harald Alvestrand, Stefan Håkansson and Dominique Hazaël-Massieux, for
      their support. Substantial text in this specification was provided by
      many people including <!-- tag 1 to reduce merge conflicts when adding names to list  -->
      Jim Barnett, <!-- tag 2 --> Harald Alvestrand, <!-- tag 3 --> Travis
      Leithead, <!-- tag 4 --> <!-- tag 5 --> <!-- tag 6 --> <!-- tag 7 -->
      <!-- tag 8 --> <!-- tag 9 --> and Stefan Håkansson.</p>
    </section>
  </body>
</html>
